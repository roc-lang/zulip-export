[
    {
        "content": "<p>this is the best analysis I've ever read about the design of strings and \"characters\" - it's long, but great!</p>\n<p><a href=\"https://hsivonen.fi/string-length/\">https://hsivonen.fi/string-length/</a></p>",
        "id": 395426657,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1696689965
    },
    {
        "content": "<p>I did not realize that extended grapheme cluster lengths can change when new versions of unicode are released</p>",
        "id": 395435222,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1696696249
    },
    {
        "content": "<p>that is a strong argument that we should move that concept out of builtins and into a separate package</p>",
        "id": 395435247,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1696696278
    },
    {
        "content": "<p>because otherwise we can't have Str update to new Unicode versions without potentially causing regressions in existing userspace code</p>",
        "id": 395435263,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1696696317
    },
    {
        "content": "<p>which in turn means if you actually use any of those grapheme features, and you want to make sure things don't regress, you'd have to just not upgrade your Roc version (as opposed to declining to upgrade your unicode package version, for example, which is a much tamer choice to make)</p>",
        "id": 395435373,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1696696393
    },
    {
        "content": "<p>here's a more specific design: <a href=\"https://docs.google.com/document/d/1TTYGVKhq0Jy43-j9AIt7B0PiAravloYmOVw9Dd_cAts/edit?usp=sharing\">https://docs.google.com/document/d/1TTYGVKhq0Jy43-j9AIt7B0PiAravloYmOVw9Dd_cAts/edit?usp=sharing</a></p>",
        "id": 396481301,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697194334
    },
    {
        "content": "<p>Looks solid!</p>",
        "id": 396483742,
        "sender_full_name": "Anton",
        "timestamp": 1697195257
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"574142\">@drathier</span> any thoughts on this?</p>",
        "id": 396671060,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697309420
    },
    {
        "content": "<p>Is <code>Str.contains</code> guaranteed to be correct? Could you find an <code>e</code> byte in the second byte of a unicode codepoint? If so, does that mean we have to deal with unicode to do replace or contains correctly?</p>",
        "id": 396671909,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1697310420
    },
    {
        "content": "<p>not in utf8</p>",
        "id": 396672663,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697311324
    },
    {
        "content": "<p>in utf8 that won't be a problem</p>",
        "id": 396672693,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697311344
    },
    {
        "content": "<p>Ah yeah cause they don't support extended ASCII and everything else has a prefix</p>",
        "id": 396673941,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1697312903
    },
    {
        "content": "<p>thanks for tagging me <span class=\"user-mention\" data-user-id=\"281383\">@Richard Feldman</span> , here's a wall of text :)</p>\n<ul>\n<li>\n<p>normalization is tricky<br>\npersonally I always prefer the correctness argument over performance, so I want everything normalized as early as possible, in the same normalization form every time (pick whatever form is the most common, probably one of the compacting forms that encode ä as a single utf8 byte)</p>\n</li>\n<li>\n<p>re grapheme string length<br>\nI'm fairly sure the length only ever decreases, and only for previously unassigned code points? I.e., by default all graphemes are one code point, and then you declare that some are actually larger than one code point. Maybe some characters merge and \"bugfixes\" are made, idk. I'd be happy to make that \"breaking change\" though as I'm very confident that it wouldn't actually break anything in practice. How often do you use and depend on the length of unicode extended grapheme clusters? Overly strict unit tests maybe, idk. You'll probably only see this in practice whenever a new ios release comes out with new fancy emojis, and people start using them against your not-yet-upgraded roc code. I'm assuming you're shipping unicode with the binary here for portability and developer sanity.</p>\n</li>\n<li>\n<p>re what's a good default on the bytes, code unit, code point or grapheme clusters scale<br>\nI'd try to go as far right on that scale as reasonable. Code point minimum, but seriously consider graphemes as the default, as that's what people expect. Nobody thinks of <span aria-label=\"family woman woman girl boy\" class=\"emoji emoji-1f469-200d-1f469-200d-1f467-200d-1f466\" role=\"img\" title=\"family woman woman girl boy\">:family_woman_woman_girl_boy:</span> as anything other than one emoji, assuming your font renders them as a single emoji, and it doesn't feel like a stretch to see fonts adding support for e.g. skin color on the family members. Right now, that single emoji is built from 4 emojis, 7 code points, or 11-25 code units depending on encoding.</p>\n</li>\n</ul>\n<p>I've considered having multiple functions like <code>lengthGraphemes</code>, <code>lengthCodePoints</code>, <code>lengthUtf8Bytes</code> where they differ (names are hard), to spark interest and to get devs to realize that there's a meaningful difference outside of ascii, which includes emojis. Having a <code>length = lengthGraphemes</code> to indicate a good default is also useful. As for the actual default encoding, utf-8 seems like the obvious choice and what everything's standardizing on. It's absolutely reasonable to expose functions that work on utf8 bytes, e.g. for parsers, but I'd hide them away a bit. Purescript for example has exactly three use-cases of code units; two different string parsing libraries, and indices into strings from js \"stdlib/ffi\" functions. We looked through all usages when suggesting a change to the Char type.</p>\n<p>We tried to make grapheme/codepoint/byte indices type-safe in the purescript stdlib when having functions for all of them, but reached the conclusion that it's not possible to be fully type safe here. </p>\n<ul>\n<li>uppercase/lowercase and char types in general<br>\nthese are incredibly hard. On one hand, they're so complex for unicode use-cases that nobody is going to use them correctly. On the other hand, people want to use these all the time, primarily for styling reasons. In html, css can deal with it, but outside of a browser, it's really really hard to get right. I've completely banned the char type in all code bases I'm working in. Even including e.g. \"english speaking uppercase\" is going to break for names and loan-words. \"latin script uppercase\" doesn't get you much further, as it differs per locale (something like a (language,location,culture) tuple). It's going to differ per user, and per device for the same user, and for bilingual text which is super common in non-english speaking countries. My preferred locale is en_SE, for example (us english with iso units, literally english_sweden) but it's not always available, so I'm using 4 different locales on my 4 commonly used devices. It might even differ between browsers on one of my devices; I'd have to check.</li>\n</ul>",
        "id": 397143500,
        "sender_full_name": "drathier",
        "timestamp": 1697559484
    },
    {
        "content": "<p>awesome, thanks for the detailed write-up! <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 397144016,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697559696
    },
    {
        "content": "<p>I hadn't thought about names and loan words...is there any uppercasing function in existence that gets those right? <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 397144172,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697559753
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281383\">Richard Feldman</span> <a href=\"#narrow/stream/383402-API-Design/topic/Str.20and.20.22characters.22/near/397144172\">said</a>:</p>\n<blockquote>\n<p>I hadn't thought about names and loan words...is there any uppercasing function in existence that gets those right? <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>\n</blockquote>\n<p>No, and that's a big problem imo :) To get it right, you have to annotate what parts of the text is following which locale, and absolutely nobody is going to do that work. So much of unicode is assuming text is one language at a time, but afaict, most bilingual people mix languages all the time. </p>\n<p>There's tons of loan words too, and grammar for loan words is hard to get right. Everyone in sweden will agree that it's \"en pokémon/pokémonen\" and \"ett e-mail/(e-)mailet\". Somehow all swedes agree what the grammatical gender of those non-swedish words are, and that we should apply swedish grammar rules to them when used in a swedish sentence. </p>\n<p>Basically, you can't really assume a single locale ever. </p>\n<p>Here's an example sentence from a chat of mine, about an hour ago: \"konstig notis att få out of context\", where the first third of the sentence is implied (\"det där var en\" is missing), the second third is swedish and the last third is english. What locale should that chat use, when languages are mixed within single sentences? When chatting with bilingual and multilingual friends, about 25% of the words I write are in english, about 70% in swedish and about 5% other.</p>",
        "id": 397183943,
        "sender_full_name": "drathier",
        "timestamp": 1697577769
    },
    {
        "content": "<p>I feel like the only sensible way to treat text is to really lock it down to operations that for sure will work.</p>\n<ul>\n<li>concat</li>\n<li>utf8 byte size</li>\n</ul>",
        "id": 397184131,
        "sender_full_name": "drathier",
        "timestamp": 1697577858
    },
    {
        "content": "<p>yeah that's my conclusion too <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 397184162,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697577876
    },
    {
        "content": "<p>and then treat everything else as an advanced use case that requires going to a package outside the stdlib</p>",
        "id": 397184192,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697577898
    },
    {
        "content": "<p>But who's going to use a programming language where super basic stuff like String.length and String.startsWith are missing? :)</p>",
        "id": 397184242,
        "sender_full_name": "drathier",
        "timestamp": 1697577932
    },
    {
        "content": "<p>I feel like Erlang waited 14 years before adding strings to the language for a reason...</p>",
        "id": 397184479,
        "sender_full_name": "drathier",
        "timestamp": 1697578068
    },
    {
        "content": "<p>oh I think starts with is fine</p>",
        "id": 397186971,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697579543
    },
    {
        "content": "<p>er, well that's because I'm ok with not normalizing</p>",
        "id": 397187031,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697579586
    },
    {
        "content": "<p>(although I can totally see the argument for normalizing too - I just think the perf cost crosses a line, especially for equals and hashing)</p>",
        "id": 397187104,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697579641
    },
    {
        "content": "<p>wait, <code>startsWith</code> is only fine if you are normalizing, isn't it? You'd normalize when constructing strings, and keep the contents normalized as you go</p>",
        "id": 397292488,
        "sender_full_name": "drathier",
        "timestamp": 1697628966
    }
]