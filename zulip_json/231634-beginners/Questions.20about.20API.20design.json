[
    {
        "content": "<p>I've been playing with the <a href=\"https://github.com/roc-lang/unicode?tab=readme-ov-file\">unicode package</a>, to add normalization. I've made decent progress on the guts, but I now have some questions about API design, which I really know nothing about. I guess before I go much further I should contact the maintainers of that package, but it seemed worth asking some general questions here.</p>\n<ol>\n<li>\n<p>Internally, I work exclusively with lists of codepoints. Clearly, the library should expose functions that handle <code>String</code>. <strong>But should it also expose functions that deal with codepoint lists?</strong> I can see that users might well prefer <em>not</em> to repeatedly pay the overhead of conversion from/to Utf8. But  the existing part of the package only exposes a single function <code>split</code>, which is only defined for <code>String</code>, and I suppose there is an argument for keeping things minimal. My hunch, though, is that it would be best to expose both kinds of function.</p>\n</li>\n<li>\n<p>Related question. Things can go wrong when converting a utf-8 string to a codepoint list, though it's not going to be common and it's always going to be pathological. So far the library <em>only</em> exposes functions which return a <code>Result</code>, reflecting that risk.</p>\n</li>\n</ol>\n<p>But to me at least, \"Result poisoning\" is a thing (though I think this may run against the grain of Roc in that). There are times when a sane thing to do is to assume that input will be valid and crash  if it isn't. After all <code>Num</code> makes that assumption. It could wrap <em>every</em>   mathematical operation to return a <code>Result</code>, but it accepts that it will  sometimes be better to trust the program to know what it's doing, rather than insist on unwrapping and checking every operation which <em>might</em> in theory fail, even at risk of runtime disaster.</p>\n<p><strong>I would therefore favour exposing \"unsafe\" or \"unchecked\" version of very basic operations, which crashes on failure, as well as a <code>Result</code>  version. Is that wrong?</strong></p>\n<p>If that is to be done (1) <strong>should the \"safe\" version be the default</strong> (so we have, e.g., <code>toNfc : String -&gt; Result String [Utf8ParseError]</code> and <code>toNfcUnchecked : String -&gt; String</code>). Or should the \"unsafe\" version be the default (so we have <code>toNfc : String -&gt; String</code> and <code>toNfcChecked :   String -&gt; Result String [Utf8ParseError</code>). If the default form is  checked, <strong>what is the most idiomatic way of naming the \"non-Result\" version</strong>:<code>Unchecked</code>? <code>Unsafe</code>?</p>\n<p>I lean towards making the unchecked version the default (because I think it's the one people would normally use, for good reason) and naming the checked version <code>to___Checked</code>, which seems consistent with basic functions for numbers. But if so, the same approach should really be taken throughout the whole package.</p>\n<p><strong>How much to expose?</strong> In particular:</p>\n<p>Is there a good reason to expose functions which check whether a string is in a particular normal form? It seems obvious, but I'm not sure  I can really think of a time when a normal user would find that interesting, and the increased efficiency of checking directly rather than testing whether a string is in normal form with <code>if str == toNfc str</code> ... is minimal (since the normalization process does that check efficiently and simply returns the string if it's already normalized). I guess I'm asking: <strong>is it generally  better for a library to expose a <em>minimal</em> set of functions, or should one say \"well, I  have the tool, so I can easily make it available\"?</strong> Is the Roc idiom a \"batteries included\"/\"kitchen sink\" approach--definitely a thing in some libraries I've used in the past--of does it prefer minimalism: only basic functions that users will regularly need?</p>\n<p>In unicode, strings can be normalized into four different forms (NFC, NFD, NFKC, and  NFKD--the details don't matter for present purposes). API question: <strong>is this better?</strong></p>\n<div class=\"codehilite\" data-code-language=\"roc\"><pre><span></span><code> normalize : String, [NFC, NFD, NFKC, NFKD] -&gt; String\n</code></pre></div>\n<p><strong>or this?</strong></p>\n<div class=\"codehilite\" data-code-language=\"roc\"><pre><span></span><code>toNFC : String -&gt; String\ntoNFD : String -&gt; String\n# ...etc\n</code></pre></div>\n<p>or both forms? (A user will usually want to use a single normalization form everywhere, so will probably want to define a function that normalizes \"as expected\" by the particular program.)</p>\n<p>Finally, one particular issue with normalization is that it is not stable when you  concatentate. So if <code>str1</code> is in normal form C and <code>str2</code> is in normal form C, it does not follow that <code>str1</code> + <code>str2</code> will be. Again, there are two options: the user could concatenate the strings with <code>Str.concat</code>, and then normalize, or I could offer a normalized concatenation function. In theory at least I could make that more efficient, but I really wonder whether (in principle) one should  be aiming to expose minor variants on functions which really \"belong\" elsewhere simply for the sake of (speculative) efficiency gains.</p>",
        "id": 484142671,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732445992
    },
    {
        "content": "<p>This is fantastic. Super cool to hear you thinking about this and sharing here. </p>\n<p>I can try and answer some of your questions tomorrow with my 2cents, though I suspect Richard will have thoughts on these. He has given me a lot of guidance with API design, and has thoughts around the roc unicode experience. </p>\n<p>Looking forward to seeing this project develop <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 484143782,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1732447051
    },
    {
        "content": "<p>Well it's developed at least to the point that I <em>appear</em> to be passing the NFC and NFD tests in the Unicode test file (though working with a test file that has nearly 21,000 test cases is its own little bit of fun). I haven't got round to testing the NFKC and NFKD forms yet, but I'm cautiously optimistic, because they add no new algorithms. What I haven't really attempted yet is any sort of testing of speed or optimization, and that may well end up being the road block, so there's a lot of water still to flow under the bridge. I'm also using rather naive data structures (as, to be fair, the Grapheme stuff does). So ...</p>\n<p>What I obviously don't want to do is go miles down a particular API/basic design route and then find that this doesn't fit into what is envisaged for the rest of the library. I'm quite enthusiastic in theory about tackling collation, but that really is a mountain to climb.</p>",
        "id": 484146731,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732449786
    },
    {
        "content": "<p>these are excellent questions! <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span> </p>\n<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/channel/231634-beginners/topic/Questions.20about.20API.20design/near/484142671\">said</a>:</p>\n<blockquote>\n<ol>\n<li>Internally, I work exclusively with lists of codepoints. Clearly, the library should expose functions that handle <code>String</code>. <strong>But should it also expose functions that deal with codepoint lists?</strong> I can see that users might well prefer <em>not</em> to repeatedly pay the overhead of conversion from/to Utf8. But  the existing part of the package only exposes a single function <code>split</code>, which is only defined for <code>String</code>, and I suppose there is an argument for keeping things minimal. My hunch, though, is that it would be best to expose both kinds of function.</li>\n</ol>\n</blockquote>\n<p>I think this is a tough design question because:</p>\n<ul>\n<li>This is a package for advanced use cases, which suggests exposing both.</li>\n<li>In practice, the second-most common way that Unicode code points are used is for creating Unicode libraries like this. The most common way that they are used, by a huge margin, is for creating bugs in applications that should be using something like grapheme clusters instead.</li>\n</ul>\n<p>In other words, arguably exposing it is good for advanced users, but also arguably the advanced users in question are basically just people working on this library, and also arguably exposing it is a footgun.</p>\n<p>I'd say for now let's just default to the <code>Str</code> one. We can always expose more later if there's demand in practice for it outside this library! <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span></p>",
        "id": 484154251,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732456850
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/channel/231634-beginners/topic/Questions.20about.20API.20design/near/484142671\">said</a>:</p>\n<blockquote>\n<p>Things can go wrong when converting a utf-8 string to a codepoint list, though it's not going to be common and it's always going to be pathological. So far the library <em>only</em> exposes functions which return a <code>Result</code>, reflecting that risk.</p>\n<p>But to me at least, \"Result poisoning\" is a thing (though I think this may run against the grain of Roc in that). There are times when a sane thing to do is to assume that input will be valid and crash  if it isn't. After all <code>Num</code> makes that assumption. It could wrap <em>every</em>   mathematical operation to return a <code>Result</code>, but it accepts that it will  sometimes be better to trust the program to know what it's doing, rather than insist on unwrapping and checking every operation which <em>might</em> in theory fail, even at risk of runtime disaster.</p>\n<p><strong>I would therefore favour exposing \"unsafe\" or \"unchecked\" version of very basic operations, which crashes on failure, as well as a <code>Result</code>  version. Is that wrong?</strong></p>\n</blockquote>\n<p>this is a pretty deep topic, but I think <a href=\"https://www.roc-lang.org/tutorial#crashing-for-error-handling\">the tutorial section on crashing</a> is useful here:</p>\n<blockquote>\n<p><code>crash</code> is not for error handling.</p>\n<p>The reason Roc has a <code>crash</code> keyword is for scenarios where it's expected that no error will ever happen (like in <a href=\"https://www.roc-lang.org/tutorial#crashing-in-unreachable-branches\">unreachable branches</a>), or where graceful error handling is infeasible (like running out of memory).</p>\n<p>Errors that are recoverable should be represented using normal Roc types (like <a href=\"https://www.roc-lang.org/builtins/Result\">Result</a>) and then handled without crashing—for example, by having the application report that something went wrong, and then continue running from there.</p>\n</blockquote>",
        "id": 484156391,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732459049
    },
    {
        "content": "<p>in this particular case, I would say:</p>\n<ul>\n<li>If a public API function receives a <code>Str</code> as an argument, it should be assumed to contain only valid UTF-8. (The only way that couldn't happen is if there's a bug in the Roc compiler or in the platform, and it is both of their responsibilities to never put invalid UTF-8 into a <code>Str</code>.) So if you're traversing a <code>Str</code> and encounter invalid UTF-8, I would definitely <code>crash</code> there because that's the \"this branch should be unreachable\" situation.</li>\n<li>If a public API function receives a <code>List U8</code> as an argument, it should be assumed to potentially contain invalid UTF-8, and should therefore return a <code>Result</code>. The way for the caller to prove that these bytes are valid UTF-8 is to convert them to a <code>Str</code> - at which point if they want to avoid a <code>Result</code>, they can just call the function that takes a <code>Str</code>! <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></li>\n</ul>\n<p>So in this package, I would have zero functions with the names \"__Checked\" and \"__Unchecked\" - either it should always return a <code>Result</code>, or it's dealing with <code>Str</code> to UTF-8 and should <code>crash</code> in branches that ought to be unreachable (unless there are bugs in the Roc compiler or in the platform, which packages should assume aren't happening).</p>",
        "id": 484156788,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732459438
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/channel/231634-beginners/topic/Questions.20about.20API.20design/near/484142671\">said</a>:</p>\n<blockquote>\n<p>one particular issue with normalization is that it is not stable when you  concatentate. So if <code>str1</code> is in normal form C and <code>str2</code> is in normal form C, it does not follow that <code>str1</code> + <code>str2</code> will be. Again, there are two options: the user could concatenate the strings with <code>Str.concat</code>, and then normalize, or I could offer a normalized concatenation function. In theory at least I could make that more efficient, but I really wonder whether (in principle) one should  be aiming to expose minor variants on functions which really \"belong\" elsewhere simply for the sake of (speculative) efficiency gains.</p>\n</blockquote>\n<p>I could see an argument for making a <code>NormalStr</code> type (and module) which exposes <code>fromSt</code> and <code>toStr</code> and then also has its own (more efficient) concatenation operations.</p>\n<p>this would also have the benefit of giving users a nice way to write functions that only accept a normalized str, etc. - which can prevent other bugs!</p>",
        "id": 484156918,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732459560
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/stream/231634-beginners/topic/Questions.20about.20API.20design/near/484142671\">said</a>:</p>\n<blockquote>\n<p>Is there a good reason to expose functions which check whether a string is in a particular normal form? It seems obvious, but I'm not sure  I can really think of a time when a normal user would find that interesting, and the increased efficiency of checking directly rather than testing whether a string is in normal form with <code>if str == toNfc str</code> ... is minimal (since the normalization process does that check efficiently and simply returns the string if it's already normalized).</p>\n<p>I guess I'm asking: <strong>is it generally  better for a library to expose a <em>minimal</em> set of functions, or should one say \"well, I  have the tool, so I can easily make it available\"?</strong> Is the Roc idiom a \"batteries included\"/\"kitchen sink\" approach--definitely a thing in some libraries I've used in the past--of does it prefer minimalism: only basic functions that users will regularly need?</p>\n</blockquote>\n<p>I don't think of good API design as being about \"expose a lot\" versus \"expose a little\" - I think it's more important to balance these things:</p>\n<ul>\n<li>performance</li>\n<li>ability to make backwards-compatible changes in the future (exposing ways to access internal details is in tension with this, so I definitely like to avoid exposing details I might want to change later)</li>\n<li>what guarantees the API offers</li>\n<li>how easy it is to learn how to use the API correctly</li>\n</ul>",
        "id": 484158873,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732461478
    },
    {
        "content": "<p>so to me, an argument for not to exposing those functions would be something like \"this isn't something I think people will need, and it might be a footgun in that people might incorrectly reach for it when they'd get better performance if they reached for <code>NormalStr</code> instead\"</p>",
        "id": 484159052,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732461626
    },
    {
        "content": "<p>one technique I've seen in Elm for balancing considerations like this is to have a module named <code>___LowLevel</code> (e.g. <code>CodePointLowLevel</code>) - which can make it clear that \"this isn't something you should reach for normally; rather, it's something you reach for if the regular API doesn't expose any possible way to do the thing you want to do, and you're willing to resort to a (usually less ergonomic but more flexible) lower-level API because you just really need it to be done in that way and there's no other alternative\"</p>",
        "id": 484159278,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732461847
    },
    {
        "content": "<p>that might be a reasonable place to put a function like detecting normalization</p>",
        "id": 484159294,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732461866
    },
    {
        "content": "<p>anyway, thank you for the excellent questions! I really appreciate that you're approaching this in such a careful and thoughtful way. <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 484159469,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732462031
    },
    {
        "content": "<p>That's all incredibly helpful. The implementation of grapheme currently has this note:</p>\n<blockquote>\n<p># TODO DISCUSS<br>\n # I'm not sure if we should return an error here or just crash.<br>\n # A Roc Str should be be valid utf8 and so in theory it should not be possible<br>\n  # for split to have invalid utf8 in it. To be discussed.</p>\n</blockquote>\n<p>It sounds like the sensible option (in the library as a whole) therefore would just be to crash if for any reason it gets invalid utf-8 in a string. Since normalization (assuming we've got so far) is not something that is going to error, there's no particular reason to return a Result. But it would definitely make sense to be consistent in this across the entire library.</p>",
        "id": 484159485,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732462058
    },
    {
        "content": "<p>yeah, makes sense!</p>",
        "id": 484159703,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732462292
    },
    {
        "content": "<p>I wouldn't think it necessary to expose any public functions handling lists of U8s. That can and should be left to String. But internally the Unicode package works with a custom <code>CodePoint</code> type, which wraps an internal custom type which wraps a U32. There's some overhead in converting from utf-8 to codepoints and back, and I can see that anyone doing a substantial amount of unicode manipulation might prefer to work with codepoints. I'll think carefully about what I expose. For the moment, I have to expose some of the list functions I think because it's the only way for <em>me</em> to produce the necessary automated test without a lot of roundtripping from lists of codepoints to U8 and back again, which seems undesirable. But I <em>could</em> hide that behind an internal module.</p>\n<p>Anyway. Thanks for the very thoughtful and useful guidance.</p>",
        "id": 484160024,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732462578
    },
    {
        "content": "<p>And ... yes ... it <em>seems</em> to be doing what it should do (though I haven't worked out how to run 21,000 test cases in any sort of completely reliable way ... so fingers-still crossed that passing 7,000 of them is a hint of where we're headed).</p>\n<p>Just occasionally it's nice to see an expectation fail (this may only make sense if you're into unicode normalization ...):</p>\n<div class=\"codehilite\" data-code-language=\"roc\"><pre><span></span><code>expect\n    str = \"Café society\"\n    res = normalize NFD str\n    dbg Str.toUtf8 str\n\n    dbg Str.toUtf8 res\n\n    str == res\n</code></pre></div>\n<blockquote>\n<p>Running tests…</p>\n<p>[Normalization.roc:426] Str.toUtf8 str = [67, 97, 102, 195, 169, 32, 115, 111, 99, 105, 101, 116, 121]</p>\n<p>[Normalization.roc:428] Str.toUtf8 res = [67, 97, 102, 101, 204, 129, 32, 115, 111, 99, 105, 101, 116, 121]<br>\n<strong>── EXPECT FAILED in Normalization.roc ─────</strong></p>\n<p>This expectation failed:<br>\n<strong>423│</strong><strong>&gt;</strong>  expect<br>\n<strong>424│</strong><strong>&gt;</strong>      str = \"Café society\"<br>\n<strong>425│</strong><strong>&gt;</strong>      res = normalize NFD str</p>\n<p>When it failed, these variables had these values:<br>\n<strong>str</strong> : <strong>Str</strong><br>\n<strong>str</strong> = \"Café society\"<br>\n<strong>res</strong> : <strong>Str</strong><br>\n<strong>res</strong> = \"Café society\"</p>\n</blockquote>",
        "id": 484162308,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732464601
    },
    {
        "content": "<p>One other note, <code>NFC</code>, <code>NFD</code>, etc are not meaningful names</p>",
        "id": 484163150,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1732465435
    },
    {
        "content": "<p>They shouldn't be part of the API</p>",
        "id": 484163195,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1732465446
    },
    {
        "content": "<p>We should make those terms longer in a way that is meaningful to people who know little about Unicode</p>",
        "id": 484163216,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1732465475
    },
    {
        "content": "<p>General question, how often would a user want to pick a specific normalization vs just use a default normalization? Like will 99% of the time people just want to use <code>NFC</code> for example?</p>",
        "id": 484163270,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1732465559
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/channel/231634-beginners/topic/Questions.20about.20API.20design/near/484160024\">said</a>:</p>\n<blockquote>\n<p>For the moment, I have to expose some of the list functions I think because it's the only way for <em>me</em> to produce the necessary automated test without a lot of roundtripping from lists of codepoints to U8 and back again, which seems undesirable. But I <em>could</em> hide that behind an internal module.</p>\n</blockquote>\n<p>yeah I think an internal module sounds like the way to go!</p>\n<p>In general, I have a very hardline stance that the public-facing API should never, ever be changed for the sake of internal automated tests.</p>\n<p>Internal tests are a tool for helping to achieve the goal of package quality, but the API is a huge part of the package's quality itself. So sacrificing the package's quality in order to make it easier to use a tool that can <em>potentially</em> improve the package's quality is not the right tradeoff to me - I'd much rather find another way to test the package! <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span></p>",
        "id": 484163626,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732465888
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"343810\">Brendan Hansknecht</span> <a href=\"#narrow/channel/231634-beginners/topic/Questions.20about.20API.20design/near/484163216\">said</a>:</p>\n<blockquote>\n<p>We should make those terms longer in a way that is meaningful to people who know little about Unicode</p>\n</blockquote>\n<p>They are about <em>as meaningful</em> as they can be! These are the unicode terms, deliberately chosen because they are <em>not</em> exactly meaningful -- and the \"meaningful\" versions (canonical composition, canonical decomposition, compatibility decomposition, and compatibility decomposition with canonical composition) are not any better. It would just be very odd to use anything other than the Unicode Consortium approved acronyms, I think.</p>\n<p>So I think the right thing to do here is to use the jargon. I've written a fairly long piece of documentation for the module which explains them in more detail and includes recommendations about which to use. (Bottom line: probably NFC for most purposes ...)</p>",
        "id": 484169925,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732472255
    },
    {
        "content": "<p>Thanks for all the advice. I split it into two modules (one \"internal\" and intended for internal package use such as testing only), and decided provisionally to expose both a \"work-or-crash\" version and a \"check-and-result\" version, consistently with the way Num does it, so at least anyone who is massively crash-phobic can avoid even the tiniest risk. Otherwise, it exposes just two functions: <code>normalize</code> and <code>normalizeChecked</code>, each of which takes a tag to determine which normalization form it produces.</p>\n<p>I wrote a long-ish explanation of normalization at the top of the main module file, but <code>roc docs</code> doesn't seem to do anything with it: <strong>not sure what I should be doing about that</strong>.</p>\n<p>Anyway, still very much WIP, but it's sitting on a fork at <a href=\"https://github.com/PaulStanley/unicode\">https://github.com/PaulStanley/unicode</a>. One thing I'm currently having trouble with is working out how to test 21,000 odd test cases without exploding ... but it manages the first 7,000 without error, so fingers crossed. I'm pretty sure the real problem will be with speed and efficiency.</p>",
        "id": 484184872,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732487172
    },
    {
        "content": "<p>yooooo this is awesome, amazing work!!! <span aria-label=\"star struck\" class=\"emoji emoji-1f929\" role=\"img\" title=\"star struck\">:star_struck:</span></p>",
        "id": 484185700,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732487986
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/stream/231634-beginners/topic/Questions.20about.20API.20design/near/484169925\">said</a>:</p>\n<blockquote>\n<p>They are about <em>as meaningful</em> as they can be! These are the unicode terms, deliberately chosen because they are <em>not</em> exactly meaningful -- and the \"meaningful\" versions (canonical composition, canonical decomposition, compatibility decomposition, and compatibility decomposition with canonical composition) are not any better.</p>\n</blockquote>\n<p>Sad, but makes sense</p>",
        "id": 484189531,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1732492056
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/stream/231634-beginners/topic/Questions.20about.20API.20design/near/484184872\">said</a>:</p>\n<blockquote>\n<p>consistently with the way Num does it, so at least anyone who is massively crash-phobic can avoid even the tiniest risk. Otherwise, it exposes just two functions: <code>normalize</code> and <code>normalizeChecked</code>, each of which takes a tag to determine which normalization form it produces.</p>\n</blockquote>\n<p>Please don't. Num primitives for math are a class of special exceptions. This is not the API to model off of. In packages, we have debated completely banning crash. Crash is only meant for unreachable states within packages and not for error handling. Packages should all be crash-phobic.</p>",
        "id": 484189618,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1732492155
    },
    {
        "content": "<p>If a user wants to crash, they can make a wrapper in their application for doing so. The default should be results and error handling</p>",
        "id": 484189639,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1732492201
    },
    {
        "content": "<p>There is currently a crash in the unicode package... I left it there because I was trying to find all the edgcases for grapheme text segmentation. I think we should look at replacing that with a Result intead. Hannes helped with some fuzzing, but I haven't had the time to go back and clean all that up and fix it.</p>",
        "id": 484189945,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1732492551
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/stream/231634-beginners/topic/Questions.20about.20API.20design/near/484184872\">said</a>:</p>\n<blockquote>\n<p>I wrote a long-ish explanation of normalization at the top of the main module file, but <code>roc docs</code> doesn't seem to do anything with it: <strong>not sure what I should be doing about that</strong>.</p>\n</blockquote>\n<p>this is a bug in docs generation currently</p>",
        "id": 484197767,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732499898
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"775526\">Paul Stanley</span> <a href=\"#narrow/channel/231634-beginners/topic/Questions.20about.20API.20design/near/484184872\">said</a>:</p>\n<blockquote>\n<p>decided provisionally to expose both a \"work-or-crash\" version and a \"check-and-result\" version, consistently with the way Num does it, so at least anyone who is massively crash-phobic can avoid even the tiniest risk. Otherwise, it exposes just two functions: <code>normalize</code> and <code>normalizeChecked</code>, each of which takes a tag to determine which normalization form it produces.</p>\n</blockquote>\n<p>if I understand this right, the <a href=\"https://github.com/PaulStanley/unicode/blob/95db4bbc4365e5fee19f97917fad9625539a34f2/package/Normalization.roc#L195\">only way this can fail</a> is if a <code>Str</code> contains invalid UTF-8, which I think packages should assume never happens.</p>\n<p>In other words, this is a case (branch that should be unreachable) where I think <code>crash</code> is the right design, and I think the best design would be to expose <code>normalize</code> but not <code>normalizeChecked</code> <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span></p>",
        "id": 484205856,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732506699
    },
    {
        "content": "<p>Ah, if this is for an unreachable case, then yeah, crash and no checked variant</p>",
        "id": 484210533,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1732509991
    },
    {
        "content": "<p>Yes. I <em>think</em> that's the case, though I need to think a bit more about whether the unicode <code>CodePoint</code> module could ever fail to parse valid utf-8 to valid unicode codepoints (and that's existing code). Anyway, the main thing is I certainly understand the design philosophy on this sort of thing ... crash _only_ for unreachable cases. At which point I suppose the checked variant is un-necessary. I will proceed accordingly.</p>",
        "id": 484225032,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732519958
    },
    {
        "content": "<p>I'm quite certain that <em>normalization</em> as such can't turn valid unicode into invalid unicode. The issue, if there is one, is entirely at the boundary between String and CodePoint.</p>",
        "id": 484225166,
        "sender_full_name": "Paul Stanley",
        "timestamp": 1732520019
    },
    {
        "content": "<p>yeah valid UTF-8 should always be parseable into code points, so if that ever fails it's because of a bug in our implementation!</p>",
        "id": 484289113,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1732538478
    }
]