[
    {
        "content": "<p>For anyone interested in building applications that use LLMs in Roc, I have a new package for you!</p>\n<p><strong><a href=\"https://github.com/imclerran/roc-openrouter\">roc-openrouter</a></strong> <span aria-label=\"rocket\" class=\"emoji emoji-1f680\" role=\"img\" title=\"rocket\">:rocket:</span></p>\n<p>This provides an easy to use interface for interacting with the <a href=\"http://OpenRouter.ai\">OpenRouter.ai</a> API, and includes features like:</p>\n<ul>\n<li>Creating and parsing ChatML style requests and responses.</li>\n<li>Creating and parsing raw prompt style requests and responses.</li>\n<li>Formatting prompt strings with <code>[INST]</code>, <code>&lt;&lt;SYS&gt;&gt;</code>, and <code>&lt;s&gt;</code> tags for models with llama style fine-tuning.</li>\n<li>Easy access to over 140 up-to-date models (including gpt-4o), plus additional older models.</li>\n<li>Most common LLM parameters such as <code>temperature</code>, <code>topP</code>, <code>topK</code>, <code>repetitionPenalty</code>, etc.</li>\n<li>OpenRouter specific features like fallback models and provider preferences.</li>\n</ul>",
        "id": 439094057,
        "sender_full_name": "Ian McLerran",
        "timestamp": 1715890529
    },
    {
        "content": "<p>Prompting an LLM with the auto router is as easy as:</p>\n<div class=\"codehilite\" data-code-language=\"CoffeeScript\"><pre><span></span><code><span class=\"nv\">client</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nx\">Chat</span><span class=\"p\">.</span><span class=\"nx\">initClient</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"> </span><span class=\"nx\">apiKey</span><span class=\"w\"> </span><span class=\"p\">}</span>\n<span class=\"nv\">messages</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nx\">Chat</span><span class=\"p\">.</span><span class=\"nx\">appendUserMessage</span><span class=\"w\"> </span><span class=\"p\">[]</span><span class=\"w\"> </span><span class=\"s\">\"Hello, computer!\"</span>\n<span class=\"nv\">response</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nx\">Http</span><span class=\"p\">.</span><span class=\"nx\">send</span><span class=\"o\">!</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"nx\">Chat</span><span class=\"p\">.</span><span class=\"nx\">buildRequest</span><span class=\"w\"> </span><span class=\"nx\">client</span><span class=\"w\"> </span><span class=\"nx\">messages</span><span class=\"p\">)</span>\n<span class=\"k\">when</span><span class=\"w\"> </span><span class=\"nx\">Chat</span><span class=\"p\">.</span><span class=\"nx\">decodeTopMessageChoice</span><span class=\"w\"> </span><span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">body</span><span class=\"w\"> </span><span class=\"o\">is</span>\n<span class=\"w\">    </span><span class=\"nx\">Ok</span><span class=\"w\"> </span><span class=\"nx\">message</span><span class=\"w\"> </span><span class=\"nf\">-&gt;</span><span class=\"w\"> </span><span class=\"nx\">Stdout</span><span class=\"p\">.</span><span class=\"nx\">line</span><span class=\"o\">!</span><span class=\"w\"> </span><span class=\"nx\">message</span><span class=\"p\">.</span><span class=\"nx\">content</span>\n<span class=\"w\">    </span><span class=\"nx\">Err</span><span class=\"w\"> </span><span class=\"nx\">_</span><span class=\"w\"> </span><span class=\"nf\">-&gt;</span><span class=\"w\"> </span><span class=\"nx\">Stdout</span><span class=\"p\">.</span><span class=\"nx\">line</span><span class=\"o\">!</span><span class=\"w\"> </span><span class=\"s\">\"Problem decoding API response\"</span>\n</code></pre></div>",
        "id": 439101143,
        "sender_full_name": "Ian McLerran",
        "timestamp": 1715893449
    },
    {
        "content": "<p>Hey ya'll! I've got a big addition to <code>roc-openrouter</code> live as of today! The package now supports LLM tool use. This means that when using a model that supports tool usage (such as <code>gpt-4o</code>), the model can now call Roc functions, and use the results in it's answers.</p>\n<p><a href=\"/user_uploads/22008/4makW7t0SHJesxb7sAaBLeWD/Screenshot-2024-09-19-at-14.09.14.png\">Screenshot-2024-09-19-at-14.09.14.png</a><br>\nTo see this in action check out this <a href=\"https://github.com/imclerran/roc-openrouter/blob/main/examples/tools.roc\">example</a>.</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/22008/4makW7t0SHJesxb7sAaBLeWD/Screenshot-2024-09-19-at-14.09.14.png\" title=\"Screenshot-2024-09-19-at-14.09.14.png\"><img data-original-dimensions=\"916x278\" src=\"/user_uploads/thumbnail/22008/4makW7t0SHJesxb7sAaBLeWD/Screenshot-2024-09-19-at-14.09.14.png/840x560.webp\"></a></div><p><del>While this API is functional, and I'm pretty happy with it as is, I think it could still use a little refinement to simplify the process.</del> As always, I'm open to feedback and pull requests!</p>\n<p>EDIT: Updated the API by using module params to allow the Tools module to make API requests. This allowed me to streamline the tool calling process significantly.</p>",
        "id": 471548128,
        "sender_full_name": "Ian McLerran",
        "timestamp": 1726772995
    },
    {
        "content": "<p>yay! happy to see module params in use <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 471748361,
        "sender_full_name": "Agus Zubiaga",
        "timestamp": 1726842953
    },
    {
        "content": "<p>Thanks for all your work on module params! That’s a feature I’ve been looking forward to ever since it was first proposed.</p>",
        "id": 471757140,
        "sender_full_name": "Ian McLerran",
        "timestamp": 1726844823
    }
]