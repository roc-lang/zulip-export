[
    {
        "content": "<p>So a normal double has about 16 decimal places of accuracy when ignoring the exponent. glibc does calculations in a way such that is has approximately 16.5 decimal places of accuracy. Thus, it should always be as correct as possible when using nearest rounding mode.</p>\n<p>Dec has 18 decimal places. Do we want the same accuracy as floats, or should we attempt to implement trig functions such that they are accurate to all 18 decimal places (probably at the cost of some speed, but I am not sure how much at the moment)</p>",
        "id": 391220112,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694796751
    },
    {
        "content": "<p>whoa, fascinating!</p>",
        "id": 391238901,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694802689
    },
    {
        "content": "<p>my intuition is to go for speed, because it's going to be an approximation anyway</p>",
        "id": 391238964,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694802705
    },
    {
        "content": "<p>like it's going to lose some precision, so might as well make use of floating-point ops to make it go faster</p>",
        "id": 391239044,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694802724
    },
    {
        "content": "<p>Oh, I wasn't thinking of using floating point ops. I was still thinking of implementing it natively with dec.</p>\n<p>That said, if we are fine with inaccuracies, it may be fine to do dec -&gt; f64 then run the trig function finally f64 -&gt; dec.</p>",
        "id": 391239997,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694803058
    },
    {
        "content": "<p>That may actually be faster due to multiplication being faster with floats than with dec.</p>",
        "id": 391240086,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694803084
    },
    {
        "content": "<p>Though, we may be able to do some tricks here given trig functions only have to take in values 0 to 2pi.</p>",
        "id": 391240210,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694803132
    },
    {
        "content": "<p>And 2pi is guaranteed to fit into the lower half of a dec. So we may be able to use a fast path were all the math is 64bit instead of 128bit. That could actually be a huge speed benefit....hmmm.</p>",
        "id": 391240482,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694803248
    },
    {
        "content": "<p>caveat. Still would be 64 bits promoting to 128 and maybe some 128 to 128 bit operations, but no need for 256 bit operations.</p>\n<p>Sin calculations for f64 actually use 2 f64s as well to get more precision.</p>",
        "id": 391240761,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694803346
    },
    {
        "content": "<p>gotcha - yeah I don't have strong feelings about either way <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span></p>",
        "id": 391241039,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694803454
    },
    {
        "content": "<p>If my theory is correct, and we can stay in the land of 2x u64, there is a chance that dec based trig functions would actually be faster than the floating point ones......Totally just wild theory at this point though.</p>",
        "id": 391241047,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694803460
    },
    {
        "content": "<p>mainly I think it's reasonable to choose either approach!</p>",
        "id": 391241050,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694803462
    },
    {
        "content": "<p>that would be really sweet if true! <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 391241072,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694803474
    },
    {
        "content": "<p>Did some quick benchmarking of u64 math. u64s are a lot faster than floats at addition and subtraction, but they are about the same speed for multiplication and actually slower for division.</p>",
        "id": 391263227,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694811888
    },
    {
        "content": "<p>So even if we implemented all of this with u64 math, I would expect it to be at best the same speed as the float version. Cause the core of the algorithms in terms of runtime is multiplication.</p>",
        "id": 391263302,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694811927
    },
    {
        "content": "<p>So I think I may opt for converting to floats just to keep this all simple for now.</p>",
        "id": 391263403,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694811967
    },
    {
        "content": "<p>Long term, it is an interesting area to investigate (especially if we later decide we want all 18 decimal places of accuracy)</p>",
        "id": 391263452,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694811996
    },
    {
        "content": "<p>So these functions will really just be modulus by 2 pi. Then call the float versions of the functions. May need to double check that modulus is accurate enough and I don't need to do fancier estimation. But otherwise, that is the rough plan.</p>",
        "id": 391263549,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694812062
    },
    {
        "content": "<p>sounds great!</p>",
        "id": 391267952,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694813924
    },
    {
        "content": "<p>Yeah, definitely will need to do some sort of high precision modulo for this to be accurate. The max dec modulo 2*pi as a dec is quite a bit off (<del>totally the wrong number to be clear</del> that was a bug. still very off but not totally wrong).</p>",
        "id": 391273872,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694816933
    },
    {
        "content": "<p>Took a bit of fiddling, but figured out how to do high precision modulus on dec: <a href=\"https://godbolt.org/z/jx51eKbr7\">https://godbolt.org/z/jx51eKbr7</a></p>",
        "id": 391318828,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694835411
    },
    {
        "content": "<p>This uses a constant that technically is 192bit in precision instead of 128bit for doing the modulus. So an extra 64 bits below dec.<br>\nSo instead of modulo <code>6.283185307179586477</code>, it is modulo roughly <code>6.2831853071795864769252867665590057684</code></p>",
        "id": 391319411,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694835677
    },
    {
        "content": "<p>Ok. Now I think I have a full implementation. This uses the fancy division by constant trick to make this only use multiplication. It is high accuracy and should be reasonably fast. Also got it working both with negative and positive numbers.</p>\n<p><a href=\"https://godbolt.org/z/aebeTTfaj\">https://godbolt.org/z/aebeTTfaj</a></p>",
        "id": 391402599,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694885275
    },
    {
        "content": "<p>Not terrible:</p>\n<div class=\"codehilite\"><pre><span></span><code>Dec/F64:\nsin:            3.00\nasin:           8.94\n</code></pre></div>",
        "id": 391405431,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694887293
    },
    {
        "content": "<p>wow, amazing! I expected it to be a lot slower!</p>",
        "id": 391406094,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694887649
    },
    {
        "content": "<p>I mean, this is with it converting to and then running the float impl. Just has to do some setup first to ensure modulus is accurate.</p>\n<p>Also, I guess <code>asin</code> is a really fast function cause it doesn't have to do the modulus. It is just the cost of converting from float and back. Yet is has way more overhead than <code>sin</code> which is also doing the modulus.</p>",
        "id": 391406238,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694887734
    },
    {
        "content": "<p>So one point of tradeoff.</p>\n<p>High accuracy dec sign is <code>3x</code> slower than f64. Low accuracy dec sin is only <code>2.3x</code> slower than f64. Low accuracy dec sign is basically garbage at the far end of the dec range. That said, sin for floats on these giant numbers is also basically garbage in the same range. So we have information to be much more accurate than floats at the large ranges, but it costs some runtime perf. Given we have the information, I am learning torwards keeping dec more accurate at the cost of some perf, but was wondering what the general opinion is.</p>",
        "id": 391460515,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694929659
    },
    {
        "content": "<p>I guess the general design is for the default to be accurate at the expense of perf, with those users looking for perf can always choose F64 etc?</p>",
        "id": 391460763,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1694929849
    },
    {
        "content": "<p>Also, I think I have all of dec trig working now. To catch up with floats, dec is missing:</p>\n<ul>\n<li>ln</li>\n<li>pow</li>\n<li>abs</li>\n<li>sqrt</li>\n<li>a number of conversion functions to/from int/float</li>\n<li>proper calls to roc panic or error returns instead of zig panics in many locations</li>\n</ul>",
        "id": 391461286,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694930387
    },
    {
        "content": "<p>yeah I agree with keeping <code>Dec</code> accurate, especially when the performance factor is that close</p>",
        "id": 391480305,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694945716
    },
    {
        "content": "<p>maybe if there's a massive perf gap but a relatively small accuracy gap I could see an argument for lowering accuracy though <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span></p>",
        "id": 391480432,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1694945802
    },
    {
        "content": "<p>SG</p>",
        "id": 391519006,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1694962829
    },
    {
        "content": "<p>Hmm. So my perf numbers may not be correct. Compilers are too smart and optimizing things in unexpected ways.</p>",
        "id": 391615650,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1695011418
    },
    {
        "content": "<p>Need to dig into some assembly more to figure out if this is generating what I want, but it isn't clear at the moment. I think the perf results my be different from what I currently reported.</p>",
        "id": 391615777,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1695011465
    },
    {
        "content": "<p>These are probably more accurate numbers, but I'll actually do some assembly diving on x86 to double check tomorrow:</p>\n<div class=\"codehilite\"><pre><span></span><code>Dec/F64:\naddition:       5.37\nsubtraction:    3.37\nmultiplication: 14.25\ndivision:       45.52\nsin:            3.72\ncos:            3.75\ntan:            2.47\nasin:           9.10\nacos:           5.55\natan:           1.67\n</code></pre></div>",
        "id": 391617434,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1695012265
    },
    {
        "content": "<p>interesting!</p>",
        "id": 391726200,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1695051217
    },
    {
        "content": "<p>Ok. I definitely have the assembly I want now. That said, the branch predictor (especially on m1 for some reason) is annoying.</p>",
        "id": 391750788,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1695060021
    },
    {
        "content": "<p>Will have new benchmarks soon that I actually believe are accurate (equivalent to running in a long hot loops)</p>",
        "id": 391750869,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1695060060
    },
    {
        "content": "<p>Ok. So these are benchmark numbers that I am confident in and have double checked the assembly of (on m1):</p>\n<div class=\"codehilite\"><pre><span></span><code>Dec/F64:\naddition:       0.55\nsubtraction:    0.53\nmultiplication: 15.09\ndivision:       53.74\nsin:            3.90\ncos:            3.62\ntan:            2.34\nasin:           1.83\nacos:           1.72\natan:           1.73\n</code></pre></div>\n<p>The caveats are:</p>\n<ol>\n<li>When looking at smaller benchmarks addition/subtraction perf can greatly be hurt. I think the issue is that addition and subtraction require a potential jump to <code>roc_panic</code> (could have a branch misprediction). It also is simply more instructions overall. Floats are consistent. Dec is not. So with smaller benchmarks, Dec's have a lot of variance here and can be like 2x slower than floats. But in a hot loop with warmup, Dec addition and subtraction is definitely faster.</li>\n<li>Currently the trig functions don't have any quick exits. They always convert to float and then run the function on the generated float. If the trig functions hit a quick exit condition, they are much faster for floats. That is where asin being 9-10x  faster comes from. If we ensure that the function is not early existing, it is only ~2x slower as shown in the numbers above.</li>\n<li>The compiler can reason about floats better. It will do fast math optimizations on them and does a better job at dead code removal when dealing with floats.</li>\n<li>They take 2x the memory which of course will hurt cache locality if stored.</li>\n<li>In my benchmark, I tested a chain of dependent operations rather than independent ones. (This is cause the optimizeer kept optimizing away all the independent float ops unless I added a lot of unwanted datamovement).</li>\n</ol>",
        "id": 391752811,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1695060879
    },
    {
        "content": "<p>wow, this is really interesting!</p>",
        "id": 391762050,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1695065314
    },
    {
        "content": "<p>Edited the above comment to capture a few more caveats.</p>",
        "id": 391768601,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1695068293
    }
]