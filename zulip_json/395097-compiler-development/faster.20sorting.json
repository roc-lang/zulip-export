[
    {
        "content": "<p>Given I had already started on <code>quadsort</code> for <code>blitsort</code>, I am just transitioning over to working on <code>quadsort</code> for <code>fluxsort</code>. The differencen being that <code>fluxsort</code> uses more memory for more performance.</p>\n<p>It will definitely be slow to port <code>quadsort</code> cause it has a lot of low level optimization to be branchless where possible. This tends to be a large perf win for random data where the branch predictor is just constantly wrong. It also has some low level routines for small arrays to make them really fast.</p>\n<p>This is <code>tiny_sort</code> in zig: <a href=\"https://godbolt.org/z/q5PTnr13z\">https://godbolt.org/z/q5PTnr13z</a></p>\n<p>It is for arrays of length 0 to 7.</p>\n<p>It is just really cool to see the assembly. It has one jump table for the size of the input. It has 4 conditional branches (all for early returns when data happens to be sorted, only 1 can be hit for a given size array). All other control flow is unconditional jumps/calls.</p>",
        "id": 453535559,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721771372
    },
    {
        "content": "<p>The other nice part of these primitives for quadsort is that they should be transferable to any other sort. Like if we use powersort/glidesort in the future, it still would be a gain to drop into these really optimized routines for sub arrays that are tiny.</p>",
        "id": 453536429,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721771583
    },
    {
        "content": "<p>promising first results:</p>\n<p>mergesort from <a class=\"stream-topic\" data-stream-id=\"231634\" href=\"/#narrow/stream/231634-beginners/topic/Obvious.20inefficiencies.20in.20merge.20sort.20algorithm.3F\">#beginners &gt; Obvious inefficiencies in merge sort algorithm?</a>:</p>\n<div class=\"codehilite\"><pre><span></span><code>List sorted correctly!\nSorted 1000000 integers in 100 milliseconds.\n</code></pre></div>\n<p>quadsort (not fully implemented, and still a few bugs, but enough to run first tests):</p>\n<div class=\"codehilite\"><pre><span></span><code>List sorted correctly!\nSorted 1000000 integers in 41 milliseconds.\n</code></pre></div>\n<p>And this is just quadsort. Fluxsort wrapper theoretically can make it even faster.</p>",
        "id": 453821005,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721866789
    },
    {
        "content": "<p>Main reason for gains:</p>\n<div class=\"codehilite\"><pre><span></span><code>branch_misses ... âš¡- 99.4% Â±  0.0%\n</code></pre></div>",
        "id": 453822502,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721867604
    },
    {
        "content": "<p>almost 100% less branch misses</p>",
        "id": 453822511,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721867617
    },
    {
        "content": "<p>Quadsort is actually more instructions overall:</p>\n<div class=\"codehilite\"><pre><span></span><code>instructions ... ðŸ’© + 27.3% Â±  0.0%\n</code></pre></div>",
        "id": 453822593,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721867654
    },
    {
        "content": "<p>also:</p>\n<div class=\"codehilite\"><pre><span></span><code>cache_misses ...  âš¡- 70.8% Â±  1.0%\n</code></pre></div>",
        "id": 453822631,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721867700
    },
    {
        "content": "<p>This stuff just feels like black magic to me.</p>",
        "id": 453836877,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1721876622
    },
    {
        "content": "<p>I love how we can tune the performance and see such amazing results.</p>",
        "id": 453836962,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1721876681
    },
    {
        "content": "<p>1 more point of comparison.</p>\n<p>The raw C quadsort on the same size list of longs, task <code>27ms</code> if the comparison is inlined and <code>99ms</code> if the comparison is not inlined.</p>",
        "id": 453836969,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721876688
    },
    {
        "content": "<p>wow, so you got it to 41ms when a pure C implementation is 27ms? <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 453852250,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1721882475
    },
    {
        "content": "<p>Yeah, though llvm is doing a ton of heavy lifting. It manages to inline the comparison function even though we pass it into zig as a pointer.</p>\n<p>Also, I haven't done any perf tuning yet. I know of at least one location where for sure the zig is not generating quite the same as the gotos in C. I bet there are other locations as well.</p>",
        "id": 453852644,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721882673
    },
    {
        "content": "<p>Also, I currently have a broken case. Not sure what is going wrong. Just disabled the case for now. Re-enabling it should be some form of perf gain assuming it was getting hit. With it disabled, the sort is falling back to branchless fully unordered mode more often.</p>",
        "id": 453852855,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721882822
    },
    {
        "content": "<p>Also, I guess it must have been getting hit, otherwise, it wouldn't be able to break things.</p>",
        "id": 453852879,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721882849
    },
    {
        "content": "<p>I don't want to admit how much time I spent to fix this bug:</p>\n<div class=\"codehilite\" data-code-language=\"Diff\"><pre><span></span><code><span class=\"gd\">-                        arr_ptr += 8;</span>\n<span class=\"gi\">+                        arr_ptr += 8 * element_width;</span>\n</code></pre></div>",
        "id": 453863120,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721888584
    },
    {
        "content": "<p>Down to 34ms. So 34 vs 27ms.</p>",
        "id": 453863335,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721888747
    },
    {
        "content": "<p>Also, fluxsort is at 20ms.</p>",
        "id": 453863406,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721888771
    },
    {
        "content": "<p>So definitely still more gains from adding the wrapper layer (it also is much simpler than quadsort)</p>",
        "id": 453863428,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721888790
    },
    {
        "content": "<p>So quadsort is fully working now.</p>\n<p>I still need to:</p>\n<ol>\n<li><del>add a fallback path for when elements are super large. Instead of sorting the array, will generate and sort an array of pointers.</del></li>\n<li>wire through incrementing the refcount (will make it specialized based on if refcouting is required). This will definitely be a pain. The easy way would be to increment at every compare, but I will probably try to group incrementing where I can to lower the cost. 2 new args to every function and a lot of extra noise in conditionals. (could be done in a different PR, main is broken for this anyway)</li>\n<li>Add fluxsort wrapper (definitely could be done in a different PR)</li>\n<li><del>Maybe should fuzz it to make sure it is correct. Though I have a lot of tests, there are a ton of cases in general.</del> DONE</li>\n<li><del>Performance tune? I mean it's pretty darn close to the c, but while it's fresh in my brain maybe should look at diff in more detail. (My biggest guess is most of the cost is related to the element width not being known at compile time, but maybe llvm is propagating it everywhere correctly, followed by a go-to that I know is a function call rn, but just guesses).</del> (more debugging on M1 should be done, but perf is good enough that I'm leaving it be for now).</li>\n</ol>",
        "id": 453864053,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721889185
    },
    {
        "content": "<p>yooo this is awesome!!!</p>",
        "id": 453922059,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1721906400
    },
    {
        "content": "<p>Interesting, our perf is way worse on m1 mac than on x86.... still better than merge sort, but much farther from the C version.</p>",
        "id": 453982261,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721921974
    },
    {
        "content": "<p>I can't seem to get flamegraphs from roc into zig working on my mac. So pretty hard to debug the perf.</p>",
        "id": 454069340,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721949828
    },
    {
        "content": "<p>But yeah, on m1 mac we are like 90ms, but the C is 25ms. Even C with the comparison as no inline is 75ms.</p>",
        "id": 454069600,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721949998
    },
    {
        "content": "<p>If I average 10 runs, it is 67ms, which is a lot closer, but still not 25ms. and much farther away than the 34ms I get on linux.</p>",
        "id": 454070408,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721950569
    },
    {
        "content": "<p><a href=\"/user_uploads/22008/jMBU8BlpEcHZpIuijaU-yjNR/Screenshot-2024-07-25-at-4.38.35PM.png\">Sad Flamegraph...</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/22008/jMBU8BlpEcHZpIuijaU-yjNR/Screenshot-2024-07-25-at-4.38.35PM.png\" title=\"Sad Flamegraph...\"><img data-original-dimensions=\"636x163\" src=\"/user_uploads/thumbnail/22008/jMBU8BlpEcHZpIuijaU-yjNR/Screenshot-2024-07-25-at-4.38.35PM.png/840x560.webp\"></a></div>",
        "id": 454070888,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721950804
    },
    {
        "content": "<p>Sad because all the time is spent in one function. And we can't see into that function, because that's the boundary where roc calls into zig?</p>",
        "id": 454075583,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1721952849
    },
    {
        "content": "<p>Yeah</p>",
        "id": 454075727,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721952967
    },
    {
        "content": "<p>I'm pretty sure that function is just the sort function</p>",
        "id": 454075739,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721952982
    },
    {
        "content": "<p>That's with me turning off strip on the zig builtins. So I feel like there should be debug info</p>",
        "id": 454075808,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721953038
    },
    {
        "content": "<p>How are you building it? Is roc driving the linking? Maybe you could <code>--no-link</code> and then use zig to <code>build-exe</code>?</p>",
        "id": 454075874,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1721953085
    },
    {
        "content": "<p>Oh wait... nvm, this is inside roc</p>",
        "id": 454075892,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1721953106
    },
    {
        "content": "<p>I probably could build a zig app that just directly imports <code>sort.zig</code>. That probably would give me info.</p>",
        "id": 454075908,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721953138
    },
    {
        "content": "<p>That's a good way to isolate the sort impl</p>",
        "id": 454075933,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1721953177
    },
    {
        "content": "<p>Probably will want to do that anyway at some point for direct fuzzing.</p>",
        "id": 454087557,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721953676
    },
    {
        "content": "<p>Apparently essentially all of the time is spent in the copy function...which confuses me cause I'm pretty sure it is getting inlined, so not really sure why it is taking up so much time.</p>",
        "id": 454141312,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721957558
    },
    {
        "content": "<p>Hmm, I just hit a segfault on linux. Maybe I have a bug and sorting is looping like crazy sorting mem outside of the array or incrementing incorrectly somehow</p>",
        "id": 454141926,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721957985
    },
    {
        "content": "<p>Using a zig app as the driver, I have managed to fix a few bugs. That said, I am still confused by the perf.</p>\n<p>On M1 mac, the zig version takes around 70ms. The c++ around 25ms.<br>\nIf I bench the zig version or run it with a profiler, it takes around 45ms.<br>\nIf I use a cycle profiler to compare the two, they are within 10% cycle count wise.</p>\n<p>I don't know of a good equivalent to perf on mac to get time spent on cache misses and waiting on data.<br>\nProbably gonna move on soon and just work on other things.</p>",
        "id": 454190146,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721977319
    },
    {
        "content": "<p>Oh, also, in the profiler, almost all the time is spent copying data (which I wouldn't expect C to do better assuming I implemented the algorithm correctly and am copying the same data around).</p>\n<p>Given it runs good on x86, that also suggests that I implemented the algorithm correctly.</p>",
        "id": 454191449,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721977376
    },
    {
        "content": "<p>But maybe llvm is optimizing poorly for us on m1 mac for some reason</p>",
        "id": 454191855,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1721977395
    },
    {
        "content": "<p>Got fuzzing working. Ran it overnight. Definitely found a few edge cases. That said, for 213 million  runs, a 552 test cases isn't bad. And I would guess that many test cases have the same root cause.</p>",
        "id": 454335823,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722012126
    },
    {
        "content": "<p>So turns out the bug was a non-bug. I turned a comment in the original C into an assert. Turns out the comment was slightly off. Updated the comment and assert. Running more fuzzing. I think we may be bug free!</p>",
        "id": 454400855,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722042844
    },
    {
        "content": "<p>Down to the last two pieces:</p>\n<ol>\n<li><del>wiring <code>inc_n_data</code> and <code>data_is_owned</code> through everything such that an owning closure could be used. (probably should fuzz that works correctly, basically, make the owned data an incrementing int and make sure it equals the number of times compare is called).</del></li>\n<li>adding the <code>fluxsort</code> wrapper around <code>quadsort</code> (and fuzzing it)</li>\n</ol>\n<p><code>quadsort</code> is working, fuzzed, and can fallback to sort indirectly for giant values.</p>",
        "id": 454447272,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722070910
    },
    {
        "content": "<p>Definitely a bit of a pervasive PR, but we have refcounting using a comptime bool to add the code or not. Also, did my best to minimize the times we actually call to increment the refcount. Attempt to batch wherever possible. So plenty of places where we increment by 4 or 16 for example.</p>",
        "id": 454544310,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722125111
    },
    {
        "content": "<p>Now just need to add that into the fuzzer.</p>",
        "id": 454544316,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722125120
    },
    {
        "content": "<p>Most places where we have to increment by only 1 are in compares that are used with short circuit evaluation. So if the first compare fails, the rest won't run.</p>",
        "id": 454544390,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722125166
    },
    {
        "content": "<p>And no way to get around that.</p>",
        "id": 454544395,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722125171
    },
    {
        "content": "<p>Ran it through my existing fuzz corpus and also a bit after. Missed one refcount location, but otherwise, refcounting seems to work happily.</p>",
        "id": 454546806,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722127076
    },
    {
        "content": "<p>Down to just the fluxsort wrapper and testing/fuzzing for it.</p>",
        "id": 454546855,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722127104
    },
    {
        "content": "<p>Printing out the breakdown of sorting is kinda cool:</p>\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>sort strategies</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<div class=\"codehilite\"><pre><span></span><code>quicksort 1000 elems\nmedian of nine: 2938417487880084056\npartition strategy: default\n    quicksort 332 elems\n    median of nine: 6817335681333689882\n    partition strategy: default\n        quicksort 120 elems\n        median of nine: 7738655368416626995\n        partition strategy: default\n            mergesort 78 elems\n            mergesort 42 elems\n        quicksort 212 elems\n        median of nine: 3983938187880039198\n        partition strategy: default\n            quicksort 163 elems\n            median of nine: 5445429211482806183\n            partition strategy: default\n                mergesort 82 elems\n                mergesort 81 elems\n            mergesort 49 elems\n    quicksort 668 elems\n    median of nine: -4781184063276946074\n    partition strategy: default\n        quicksort 426 elems\n        median of nine: 764764259046233900\n        partition strategy: default\n            quicksort 117 elems\n            median of nine: 2096483146860794127\n            partition strategy: default\n                mergesort 45 elems\n                mergesort 72 elems\n            quicksort 309 elems\n            median of nine: -1875810895047206237\n            partition strategy: default\n                quicksort 137 elems\n                median of nine: -254467376449306342\n                partition strategy: default\n                    mergesort 48 elems\n                    mergesort 89 elems\n                quicksort 172 elems\n                median of nine: -3930025406165151116\n                partition strategy: default\n                    quicksort 121 elems\n                    median of nine: -3020111438722416420\n                    partition strategy: default\n                        mergesort 66 elems\n                        mergesort 55 elems\n                    mergesort 51 elems\n        quicksort 242 elems\n        median of nine: -7138956423631159883\n        partition strategy: default\n            quicksort 137 elems\n            median of nine: -5931406857942076890\n            partition strategy: default\n                mergesort 68 elems\n                mergesort 69 elems\n            quicksort 105 elems\n            median of nine: -7657208392615692120\n            partition strategy: default\n                mergesort 29 elems\n                mergesort 76 elems\n</code></pre></div>\n</div></div>",
        "id": 454673509,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722205881
    },
    {
        "content": "<p>With fluxsort, the more random the data is, the more it uses quicksort.  If many elements of the input have the same value, it will use dual pivot quicksort to skip large chunks of sorting. If the array is relatively ordered or is simply small, will fallback to mergesort.</p>\n<p>Also has some smart handling for reversed data.</p>",
        "id": 454673690,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722206031
    },
    {
        "content": "<p>So besides an issue with the surgical linker for the fallback to sorting pointers if the element size is too large, I think I have full fluxsort working.</p>",
        "id": 454689336,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722215131
    },
    {
        "content": "<p>that's awesome!</p>",
        "id": 454691106,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1722216266
    },
    {
        "content": "<p>So final perf numbers.</p>\n<p><strong>Summary</strong><br>\nx86_64:</p>\n<ul>\n<li>4x faster than mergesort written in pure roc.</li>\n<li>tied with c++ (actually maybe a tiny bit faster and less memory).</li>\n</ul>\n<p>M1:</p>\n<ul>\n<li>2x faster than mergesort written in pure roc.</li>\n<li>2x slower than c++.</li>\n</ul>\n<hr>\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>M1 (Still not sure why roc is slower here)</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<div class=\"codehilite\"><pre><span></span><code>Benchmark 1: ./roc-mergesort\n  Time (mean Â± Ïƒ):      77.6 ms Â±   0.6 ms    [User: 73.6 ms, System: 2.5 ms]\n  Range (min â€¦ max):    76.7 ms â€¦  80.9 ms    100 runs\n\nBenchmark 2: ./roc-builtinsort\n  Time (mean Â± Ïƒ):      40.3 ms Â±   0.5 ms    [User: 36.9 ms, System: 2.1 ms]\n  Range (min â€¦ max):    39.6 ms â€¦  44.0 ms    100 runs\n\nBenchmark 3: ./cc-quadsort\n  Time (mean Â± Ïƒ):      31.1 ms Â±   0.9 ms    [User: 27.6 ms, System: 2.3 ms]\n  Range (min â€¦ max):    30.1 ms â€¦  35.6 ms    100 runs\n\nBenchmark 4: ./cc-fluxsort\n  Time (mean Â± Ïƒ):      21.0 ms Â±   0.4 ms    [User: 18.0 ms, System: 2.0 ms]\n  Range (min â€¦ max):    20.5 ms â€¦  23.1 ms    100 runs\n\nSummary\n  ./cc-fluxsort ran\n    1.48 Â± 0.05 times faster than ./cc-quadsort\n    1.92 Â± 0.04 times faster than ./roc-builtinsort\n    3.70 Â± 0.07 times faster than ./roc-mergesort\n</code></pre></div>\n</div></div>\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>x86_64 intel i7-8750H gaming laptop (amazing results)</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>hyperfine</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<div class=\"codehilite\"><pre><span></span><code>Benchmark 1: ./roc-mergesort\n  Time (mean Â± Ïƒ):      99.4 ms Â±   2.9 ms    [User: 96.2 ms, System: 3.2 ms]\n  Range (min â€¦ max):    96.2 ms â€¦ 121.6 ms    100 runs\n\nBenchmark 2: ./roc-builtinsort\n  Time (mean Â± Ïƒ):      25.4 ms Â±   0.5 ms    [User: 23.1 ms, System: 2.3 ms]\n  Range (min â€¦ max):    24.7 ms â€¦  27.7 ms    100 runs\n\nBenchmark 3: ./cc-quadsort\n  Time (mean Â± Ïƒ):      35.9 ms Â±   1.5 ms    [User: 31.6 ms, System: 4.3 ms]\n  Range (min â€¦ max):    33.1 ms â€¦  38.1 ms    100 runs\n\nBenchmark 4: ./cc-fluxsort\n  Time (mean Â± Ïƒ):      26.5 ms Â±   0.5 ms    [User: 22.4 ms, System: 4.1 ms]\n  Range (min â€¦ max):    25.5 ms â€¦  28.0 ms    100 runs\n\nSummary\n  ./roc-builtinsort ran\n    1.04 Â± 0.03 times faster than ./cc-fluxsort\n    1.42 Â± 0.07 times faster than ./cc-quadsort\n    3.92 Â± 0.14 times faster than ./roc-mergesort\n</code></pre></div>\n</div></div>\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>poop</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<div class=\"codehilite\"><pre><span></span><code>Benchmark 1 (50 runs): ./roc-mergesort\n  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta\n  wall_time          98.5ms Â± 1.11ms    97.1ms â€¦  104ms          5 (10%)        0%\n  peak_rss           16.3MB Â± 66.0KB    16.3MB â€¦ 16.4MB          0 ( 0%)        0%\n  cpu_cycles          377M  Â± 1.07M      376M  â€¦  383M           1 ( 2%)        0%\n  instructions        385M  Â± 8.40       385M  â€¦  385M           2 ( 4%)        0%\n  cache_references   11.6M  Â± 43.1K     11.5M  â€¦ 11.7M           0 ( 0%)        0%\n  cache_misses       5.58M  Â±  203K     5.40M  â€¦ 6.67M           4 ( 8%)        0%\n  branch_misses      9.50M  Â± 5.82K     9.49M  â€¦ 9.52M           0 ( 0%)        0%\nBenchmark 2 (182 runs): ./roc-builtinsort\n  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta\n  wall_time          26.6ms Â±  766us    25.1ms â€¦ 28.4ms          0 ( 0%)        âš¡- 73.0% Â±  0.3%\n  peak_rss           12.9MB Â±  748KB    12.5MB â€¦ 14.7MB         29 (16%)        âš¡- 20.9% Â±  1.3%\n  cpu_cycles         95.5M  Â± 2.94M     90.5M  â€¦  102M           0 ( 0%)        âš¡- 74.7% Â±  0.2%\n  instructions        281M  Â±  321K      280M  â€¦  281M           2 ( 1%)        âš¡- 27.1% Â±  0.0%\n  cache_references   4.16M  Â± 46.2K     4.06M  â€¦ 4.27M           0 ( 0%)        âš¡- 64.1% Â±  0.1%\n  cache_misses        637K  Â± 60.0K      526K  â€¦  956K           3 ( 2%)        âš¡- 88.6% Â±  0.6%\n  branch_misses       289K  Â± 60.9K      187K  â€¦  362K           0 ( 0%)        âš¡- 97.0% Â±  0.2%\nBenchmark 3 (139 runs): ./cc-quadsort\n  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta\n  wall_time          34.8ms Â± 1.01ms    33.9ms â€¦ 39.2ms         12 ( 9%)        âš¡- 64.6% Â±  0.3%\n  peak_rss           18.4MB Â± 76.4KB    18.2MB â€¦ 18.6MB          9 ( 6%)        ðŸ’©+ 12.5% Â±  0.1%\n  cpu_cycles          117M  Â±  807K      115M  â€¦  120M          11 ( 8%)        âš¡- 69.0% Â±  0.1%\n  instructions        283M  Â±  173       283M  â€¦  283M          18 (13%)        âš¡- 26.5% Â±  0.0%\n  cache_references   6.70M  Â± 59.4K     6.62M  â€¦ 6.88M           8 ( 6%)        âš¡- 42.2% Â±  0.2%\n  cache_misses       1.82M  Â±  126K     1.60M  â€¦ 2.18M           2 ( 1%)        âš¡- 67.4% Â±  0.9%\n  branch_misses      53.3K  Â± 2.28K     47.0K  â€¦ 61.0K          20 (14%)        âš¡- 99.4% Â±  0.0%\nBenchmark 4 (172 runs): ./cc-fluxsort\n  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta\n  wall_time          28.1ms Â± 2.17ms    26.2ms â€¦ 49.8ms          8 ( 5%)        âš¡- 71.5% Â±  0.6%\n  peak_rss           18.4MB Â± 80.3KB    18.2MB â€¦ 18.6MB          7 ( 4%)        ðŸ’©+ 12.6% Â±  0.1%\n  cpu_cycles         92.5M  Â± 4.48M     88.1M  â€¦  130M           2 ( 1%)        âš¡- 75.5% Â±  0.3%\n  instructions        267M  Â±  186K      267M  â€¦  268M           3 ( 2%)        âš¡- 30.6% Â±  0.0%\n  cache_references   4.35M  Â± 70.5K     4.21M  â€¦ 4.90M           3 ( 2%)        âš¡- 62.5% Â±  0.2%\n  cache_misses        822K  Â±  120K      682K  â€¦ 2.04M           7 ( 4%)        âš¡- 85.3% Â±  0.8%\n  branch_misses       263K  Â± 65.8K      193K  â€¦  370K           0 ( 0%)        âš¡- 97.2% Â±  0.2%\n</code></pre></div>\n</div></div>\n</div></div>",
        "id": 454705605,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722223985
    },
    {
        "content": "<p>PR: <a href=\"https://github.com/roc-lang/roc/issues/6932\">#6932</a></p>",
        "id": 454706950,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722224362
    },
    {
        "content": "<p>Nice work, this is really cool. Love how you explored the performance and shared what you learnt along the way. </p>\n<p>I found it super interesting to follow along with, and now I really want to understand the perf characteristics more with my code.</p>",
        "id": 454713494,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1722226834
    },
    {
        "content": "<p>I'm going to leave this fuzzing overnight, but everything is ready for review and merge here.</p>",
        "id": 454735127,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722234729
    },
    {
        "content": "<p>I thought I might try and run this (or something similar) and see what I see on my M2 mac. </p>\n<p>Based on my results, I'm guessing this isn't the correct way to test this. </p>\n<h2>test program</h2>\n<p>I used this program inspired by <a href=\"https://github.com/roc-lang/roc/issues/6294\">#6294</a> -- it's not the same because the API has changed a lot since then.</p>\n<div class=\"codehilite\"><pre><span></span><code>app [main] {\n    pf: platform &quot;https://github.com/roc-lang/basic-cli/releases/download/0.13.0/nW9yMRtZuCYf1Oa9vbE5XoirMwzLbtoSgv7NGhUlqYA.tar.br&quot;,\n}\n\nimport pf.Task\n\nmain =\n    n = 86896\n    list = List.range { start: At n, end: Before 0 }\n\n    actual = List.sortWith list Num.compare\n    expected = List.range { start: At 1, end: At n }\n\n    if actual == expected then\n        Task.ok {}\n    else\n        Task.err NotSorted\n</code></pre></div>\n<h2>results M2 mac</h2>\n<div class=\"codehilite\"><pre><span></span><code>$ hyperfine ./sort\nBenchmark 1: ./sort\n  Time (mean Â± Ïƒ):      40.4 ms Â±  93.3 ms    [User: 10.0 ms, System: 1.3 ms]\n  Range (min â€¦ max):     9.3 ms â€¦ 305.9 ms    10 runs\n\n$ hyperfine ./sort-opt\nBenchmark 1: ./sort-opt\n  Time (mean Â± Ïƒ):     164.6 ms Â± 502.0 ms    [User: 3.9 ms, System: 1.7 ms]\n  Range (min â€¦ max):     3.1 ms â€¦ 1593.4 ms    10 runs\n\n$ hyperfine -m 1000 ./sort\nBenchmark 1: ./sort\n  Time (mean Â± Ïƒ):       9.3 ms Â±   0.2 ms    [User: 7.9 ms, System: 0.8 ms]\n  Range (min â€¦ max):     8.8 ms â€¦   9.7 ms    1000 runs\n\n$ hyperfine -m 1000 ./sort-opt\nBenchmark 1: ./sort-opt\n  Time (mean Â± Ïƒ):       3.0 ms Â±   0.2 ms    [User: 1.8 ms, System: 0.7 ms]\n  Range (min â€¦ max):     2.6 ms â€¦   5.3 ms    1000 runs\n</code></pre></div>",
        "id": 454798867,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1722251521
    },
    {
        "content": "<p><code>sort-opt</code> was built using <code>--optimize</code></p>",
        "id": 454799045,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1722251542
    },
    {
        "content": "<p>Try running <code>./bench.sh</code> from this repo: <a href=\"https://github.com/bhansconnect/roc-sorting\">https://github.com/bhansconnect/roc-sorting</a></p>",
        "id": 454859512,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722265109
    },
    {
        "content": "<p>And yeah, that benchmark isn't good cause fluxsort will detect the entire list is reversed and just flip it</p>",
        "id": 454859782,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722265178
    },
    {
        "content": "<blockquote>\n<p>leave this fuzzing overnight</p>\n</blockquote>\n<p>250 million executions later with 0 crashes. There were some timeouts (no hangs), but that's expected. Timeouts are expected cause with a large enough input, sorting will get slow. Timeouts just mean it took longer than expected, but still finished in a reasonable time. Hangs are if it takes so long that the fuzzer decides to kill it.</p>",
        "id": 454870446,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722267563
    },
    {
        "content": "<p>So looked at the M1 story a bit more:</p>\n<p>A raw zig version using our new builtin sort is essentially as fast as the C sort on M1.</p>\n<div class=\"codehilite\"><pre><span></span><code>Summary\n  ./cc-fluxsort ran\n    1.04 Â± 0.02 times faster than ./zig-raw-builtinsort\n</code></pre></div>\n<p>So it is somehow due to the code roc is generating. Maybe llvm is not inlining the compare or copy for llvm on m1 (I don't think this is the case, would be way slower)? Maybe the compare isn't generating branchless? Maybe some other complexity of llvm ir is leading to an optimization failing to apply?</p>",
        "id": 454923847,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722280413
    },
    {
        "content": "<p>Super exciting! <span aria-label=\"grinning face with smiling eyes\" class=\"emoji emoji-1f601\" role=\"img\" title=\"grinning face with smiling eyes\">:grinning_face_with_smiling_eyes:</span></p>",
        "id": 454955149,
        "sender_full_name": "Isaac Van Doren",
        "timestamp": 1722289031
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"515757\">@Luke Boswell</span> if you get a chance, I'd be curious what your M2 results are for this:</p>\n<blockquote>\n<p>Try running <code>./bench.sh</code> from this repo: <a href=\"https://github.com/bhansconnect/roc-sorting\">https://github.com/bhansconnect/roc-sorting</a></p>\n</blockquote>",
        "id": 455021204,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722313424
    },
    {
        "content": "<p>Should run on latest main with zig 0.11 and any form of clang++.</p>",
        "id": 455021346,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722313470
    },
    {
        "content": "<p>M2 macbook air</p>\n<div class=\"codehilite\"><pre><span></span><code>Benchmark 1: ./roc-mergesort\n  Time (mean Â± Ïƒ):      71.1 ms Â±   0.8 ms    [User: 68.1 ms, System: 1.9 ms]\n  Range (min â€¦ max):    69.9 ms â€¦  72.1 ms    100 runs\n\nBenchmark 2: ./roc-builtinsort\n  Time (mean Â± Ïƒ):      36.6 ms Â±   0.5 ms    [User: 34.4 ms, System: 1.5 ms]\n  Range (min â€¦ max):    35.8 ms â€¦  37.3 ms    100 runs\n\nBenchmark 3: ./zig-raw-builtinsort\n  Time (mean Â± Ïƒ):      33.7 ms Â±   0.4 ms    [User: 32.4 ms, System: 1.0 ms]\n  Range (min â€¦ max):    33.0 ms â€¦  34.3 ms    100 runs\n\nBenchmark 4: ./cc-quadsort\n  Time (mean Â± Ïƒ):      27.1 ms Â±   0.3 ms    [User: 25.3 ms, System: 1.5 ms]\n  Range (min â€¦ max):    26.8 ms â€¦  27.8 ms    100 runs\n\nBenchmark 5: ./cc-fluxsort\n  Time (mean Â± Ïƒ):      19.0 ms Â±   0.1 ms    [User: 17.3 ms, System: 1.3 ms]\n  Range (min â€¦ max):    18.7 ms â€¦  19.3 ms    100 runs\n\nSummary\n  ./cc-fluxsort ran\n    1.43 Â± 0.02 times faster than ./cc-quadsort\n    1.78 Â± 0.02 times faster than ./zig-raw-builtinsort\n    1.93 Â± 0.03 times faster than ./roc-builtinsort\n    3.75 Â± 0.05 times faster than ./roc-mergesort\n</code></pre></div>",
        "id": 455023239,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1722314022
    },
    {
        "content": "<p>And on the WIP LLVM 18 branch -- this is a great way to confirm that the optimisation passes I removed are definitely still required... so don't take these results seriously</p>\n<div class=\"codehilite\"><pre><span></span><code>Benchmark 1: ./roc-mergesort\n  Time (mean Â± Ïƒ):     431.0 ms Â±   2.7 ms    [User: 425.4 ms, System: 2.4 ms]\n  Range (min â€¦ max):   425.5 ms â€¦ 445.8 ms    100 runs\n\nBenchmark 2: ./roc-builtinsort\n  Time (mean Â± Ïƒ):     203.1 ms Â±   0.9 ms    [User: 200.1 ms, System: 1.4 ms]\n  Range (min â€¦ max):   198.0 ms â€¦ 206.5 ms    100 runs\n</code></pre></div>",
        "id": 455024701,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1722314554
    },
    {
        "content": "<p>ok, so still a gap from c++ to zig/roc. Not sure why the perf diff would be apple silicon specific, but good to know it is consistent.</p>",
        "id": 455028961,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1722316215
    }
]