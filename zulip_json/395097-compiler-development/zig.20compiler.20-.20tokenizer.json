[
    {
        "content": "<p>I'm just tinkering with tokenizing fuzzing bugs. Decided to pull into a separate thread to not clutter other discussions.</p>\n<p><span class=\"user-mention\" data-user-id=\"453336\">@Joshua Warner</span> how would you expect a numeric base without any follow digits to tokenize?<br>\n<code>0x.</code> for example. Should we generate some sort of malformed node or error if the base is not followed by a number?</p>\n<p>Currently this is one of the tokenizer fuzzer failures and I was just trying to clean it up.</p>",
        "id": 504243804,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741416998
    },
    {
        "content": "<p>example failure: <code>zig build repro-tokenize -- -b MHguMA== -v</code></p>",
        "id": 504244258,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741417378
    },
    {
        "content": "<p>Yeah that looks malformed to me</p>",
        "id": 504292307,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1741450161
    },
    {
        "content": "<p>Found an issue from a fuzz crash. Made a small test that is failing, and investigating now. It tokenizes the <code>]</code> as a <code>CloseCurly</code> instead of an <code>CloseSquare</code>.</p>\n<div class=\"codehilite\" data-code-language=\"Zig\"><pre><span></span><code><span class=\"k\">try</span><span class=\"w\"> </span><span class=\"n\">testTokenization</span><span class=\"p\">(</span>\n<span class=\"w\">        </span><span class=\"n\">gpa</span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"sh\">\\\\f{o,</span>\n<span class=\"w\">        </span><span class=\"sh\">\\\\     ]</span>\n<span class=\"w\">        </span><span class=\"sh\">\\\\</span>\n<span class=\"w\">        </span><span class=\"sh\">\\\\foo =</span>\n<span class=\"w\">        </span><span class=\"sh\">\\\\</span>\n<span class=\"w\">        </span><span class=\"sh\">\\\\    \"onmo %</span>\n<span class=\"w\">    </span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"o\">&amp;</span><span class=\"p\">[</span><span class=\"n\">_</span><span class=\"p\">]</span><span class=\"n\">Token</span><span class=\"p\">.</span><span class=\"n\">Tag</span><span class=\"p\">{</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">LowerIdent</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">OpenCurly</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">LowerIdent</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">Comma</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">Newline</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">CloseSquare</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">Newline</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">LowerIdent</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">OpAssign</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">Newline</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">StringStart</span><span class=\"p\">,</span>\n<span class=\"w\">            </span><span class=\"p\">.</span><span class=\"n\">StringPart</span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"p\">},</span>\n<span class=\"w\">    </span><span class=\"p\">);</span>\n</code></pre></div>",
        "id": 504451236,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741569213
    },
    {
        "content": "<p>Optimistically, I think that ought to detect the mismatched brackets, infer the intent was to have the correct closing bracket there, emit a message, and continue.</p>\n<p>That said, it feels a bit more likely that thatâ€™s just an accident at this point.</p>",
        "id": 504453882,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1741570991
    },
    {
        "content": "<p>Yeah, you're correct. I hadn't noticed the Diagnostic was being correctly reported for Mismatched braces.</p>",
        "id": 504462556,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741576911
    },
    {
        "content": "<p>I had a break for lunch, but almost finished re-wiring the way I'm dealing with Problems in the snapshots so these issues are surfaced easier.</p>",
        "id": 504462610,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741576943
    },
    {
        "content": "<p>From your other post <span class=\"user-mention\" data-user-id=\"515757\">@Luke Boswell</span> :</p>\n<div class=\"codehilite\"><pre><span></span><code>~~~PROBLEMS\ncheck.parse.tokenize.Diagnostic.Tag.AsciiControl\ncheck.parse.tokenize.Diagnostic.Tag.MismatchedBrace\ncheck.parse.tokenize.Diagnostic.Tag.UnclosedString\n</code></pre></div>",
        "id": 504584691,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741613965
    },
    {
        "content": "<p>Looks like it's there just fine.  We just don't seem to short circuit the input when we have tokenize errors</p>",
        "id": 504584791,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741613990
    },
    {
        "content": "<p>I hope we do for parse errors</p>",
        "id": 504584830,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741613999
    },
    {
        "content": "<p>THe invariant should be: For any fuzz input that has no tokenization or parse errors, it should have stable formatting</p>",
        "id": 504584986,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741614027
    },
    {
        "content": "<p>And a stable AST</p>",
        "id": 504585023,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741614036
    },
    {
        "content": "<p>We just call the parser directly passing in the source. It calls the tokenizer. Not sure where the tokenizer errors end up. But currently only the errors returned by parse are checked. This is where one global list of all errors that builds up with each new stage would be nice likely</p>",
        "id": 504629236,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741622835
    },
    {
        "content": "<p>I think I agree that after a stage any stage errors should be added to a tagged union list of some sort and then the next stage can choose to proceed or not based on it being non-empty</p>",
        "id": 504688862,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741641309
    },
    {
        "content": "<p>Yeah, may even switch on type of error. Cause we want to attempt to compile even with many classes of errors.</p>",
        "id": 504689988,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741641797
    },
    {
        "content": "<p>I've done this in my latest PR for review. Probably needs adjustment, but its a start.</p>",
        "id": 504690214,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741641886
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"781658\">Anthony Bullard</span> <a href=\"#narrow/channel/395097-compiler-development/topic/zig.20compiler.20-.20tokenizer/near/504688862\">said</a>:</p>\n<blockquote>\n<p>I think I agree that after a stage any stage errors should be added to a tagged union list of some sort and then the next stage can choose to proceed or not based on it being non-empty</p>\n</blockquote>\n<p>Pretty much every kind of error should be continued from, the only places I can think of this not being true are:</p>\n<ul>\n<li>The file passed to <code>roc check/build/etc</code> not being found</li>\n<li>The platform package not being found</li>\n<li>The command being <code>roc build</code> and having type errors</li>\n<li>The platform not receiving a valid \"provides\" function (or none at all)</li>\n</ul>",
        "id": 504691372,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741642355
    },
    {
        "content": "<p>There are definitely classes of malformed nodes for example where it would not make sense to continue...</p>",
        "id": 504698461,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741645205
    },
    {
        "content": "<p>Not to mention illegal tokens</p>",
        "id": 504698508,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741645222
    },
    {
        "content": "<p>Can you give an example of the former? Illegal tokens could make sense, but I think we'd still want to allow running the code with malformed nodes, it'd just crash quickly</p>",
        "id": 504703909,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647608
    },
    {
        "content": "<p>It feels like these are cases where we'd now be deciding \"surely the user doesn't want to run code that is malformed\" for them</p>",
        "id": 504704068,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647662
    },
    {
        "content": "<p>But they should be free to decide for themselves</p>",
        "id": 504704275,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647751
    },
    {
        "content": "<p>If I have a malformed expression in a list literal, how do I run that?</p>",
        "id": 504704300,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741647770
    },
    {
        "content": "<p>I crash</p>",
        "id": 504704322,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647778
    },
    {
        "content": "<p>Just like I do for a type error</p>",
        "id": 504704334,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647784
    },
    {
        "content": "<p>Canonicalization will generate a runtime error for that whole node</p>",
        "id": 504704363,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647796
    },
    {
        "content": "<p>Sure but that seems a little silly to me</p>",
        "id": 504704407,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741647826
    },
    {
        "content": "<p>Iâ€™m using a strongly typed, compiled language to shift errors to the left</p>",
        "id": 504704473,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741647845
    },
    {
        "content": "<p>What if that function is barely called?</p>",
        "id": 504704490,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647852
    },
    {
        "content": "<p>I think you might be missing the second paradigm of using Roc</p>",
        "id": 504704515,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647869
    },
    {
        "content": "<p>Iâ€™d still want to know closer to when I wrote it</p>",
        "id": 504704528,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741647877
    },
    {
        "content": "<p>The first is the one we both like and mainly care about</p>",
        "id": 504704531,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647879
    },
    {
        "content": "<p>Then when it just happens to get called - maybe a week later</p>",
        "id": 504704547,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741647892
    },
    {
        "content": "<p>Oh, I understand the disconnect</p>",
        "id": 504704592,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647912
    },
    {
        "content": "<p>The runtime error would be paired with a compiler error that would give a non-zero exit code on <code>roc build</code></p>",
        "id": 504704642,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647942
    },
    {
        "content": "<p>You can still use the binary, but you'd know immediately that you have a positive number of errors and probably should fix those</p>",
        "id": 504704743,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647973
    },
    {
        "content": "<p>During dev, you want to be able to run anyway</p>",
        "id": 504704777,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741647991
    },
    {
        "content": "<p>And 99% of people will fix the error</p>",
        "id": 504704792,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741648005
    },
    {
        "content": "<p>But doing we really want to block the 1% of people that want to run anyway?</p>",
        "id": 504704821,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741648021
    },
    {
        "content": "<p>If we decide against supporting that, then I truly have misaligned on \"always inform, never block\"</p>",
        "id": 504704885,
        "sender_full_name": "Sam Mohr",
        "timestamp": 1741648057
    },
    {
        "content": "<p>yeah that's idea is \"always inform, never block\" - report the compiler error so you know there's a problem, but always let you have the choice to run it anyway</p>",
        "id": 504704926,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1741648080
    },
    {
        "content": "<p>you shift left while also simultaneously not shifting left if you don't want to. it's like SchrÃ¶dinger's Shift Left</p>",
        "id": 504705016,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1741648114
    },
    {
        "content": "<p>Got it.  I'm just not the target audience for that paradigm.  I get enough runtime errors writing JavaScript</p>",
        "id": 504709644,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1741650708
    },
    {
        "content": "<p>really simple example of where this is nice at even the lexing level: I'm trying to merge in a branch and see if it fixes what I'm working on. There are merge conflicts in a part of the code base I'm not working on, creating syntax errors with all their <code>======</code>s etc.</p>\n<p>I would still like to be able to run tests on my unrelated part of the code base, so I can tell where it's worth my time to fix those merge conflicts or whether that branch doesn't fix my problem. If the merge conflicts block me from trying it out, I have no choice but to fix them first before I know whether that'll be a waste of time!</p>",
        "id": 504724589,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1741659242
    },
    {
        "content": "<p>After some digging, I found the Newline tokens don't have region information set. I think this might be the cause of challenges getting the correct offsets for AST nodes.</p>\n<p>From what I've discovered so far, I think it's because we are using the offset field to store the indentation. I'm wondering if we could use the <code>extra</code> field for this instead. </p>\n<div class=\"codehilite\"><pre><span></span><code>pub fn pushNewline(self: *TokenizedBuffer, indent: u32) void {\n    self.tokens.append(self.env.gpa, .{\n        .tag = .Newline,\n        .offset = indent, // store the indent in the offset field\n        .extra = .{ .length = 0 },\n    }) catch |err| exitOnOom(err);\n}\n</code></pre></div>",
        "id": 505042945,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741762016
    },
    {
        "content": "<p>(deleted) -- i think that example is just going to cause more confusion</p>",
        "id": 505042986,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741762041
    },
    {
        "content": "<p>Yeah, instead of having an offset, newlines store the indentation of the following line</p>",
        "id": 505043350,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741762206
    },
    {
        "content": "<p>So I think the parser needs to make sure not to use locations from newlines</p>",
        "id": 505043375,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741762220
    },
    {
        "content": "<p>It needs to take the token before or after the newline depending on its goal</p>",
        "id": 505043413,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741762241
    },
    {
        "content": "<p>But yeah, probably could move indents to the extra field instead</p>",
        "id": 505043516,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741762292
    },
    {
        "content": "<p>That sounds cleaner. Especially since we have the space anyway for it.</p>",
        "id": 505043609,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741762323
    },
    {
        "content": "<p>Yeah, I'm just starting with <code>module []</code> and trying to figure out why the region for that isn't what I expect. </p>\n<p>I think the issue is that <code>self.expect(.CloseSquare) catch { ...}</code> calls <code>advance</code> which moves <code>self.pos</code> forward n steps (we don't know how many) until the next non-newline token. So after parsing the module header, we set the region to be the start of the next non-newline token, instead of the end of the <code>]</code>.</p>",
        "id": 505043909,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741762450
    },
    {
        "content": "<p>I have an idea which might fix it</p>",
        "id": 505044018,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741762507
    },
    {
        "content": "<p>Actually I found the fix, change <code>_ = self.parseCollectionSpan</code> to <code>const end = self.parseCollectionSpan</code>, and use that for the region. <span aria-label=\"octopus\" class=\"emoji emoji-1f419\" role=\"img\" title=\"octopus\">:octopus:</span></p>",
        "id": 505046850,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741763557
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"453336\">@Joshua Warner</span> how do you think we should handle something like <code>0u8.0</code> in the tokenizer?</p>\n<p>Currently, we convert it into <code>111.1</code> which leads to it retokenizing as a float which fails. I'm debating using the extra field of the token to store the suffix. Would be an enum of <code>none</code>, <code>u8</code>, <code>i8</code>, etc. We could actually still store the length as well assuming we limit int literals to less than 2^28 characters.</p>",
        "id": 505285825,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741827207
    },
    {
        "content": "<p>exact repro for context: <code>zig build repro-tokenize -- -b MHU4LjA= -v</code></p>",
        "id": 505285959,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741827255
    },
    {
        "content": "<p>Also, is <code>.7</code> a valid float? I assume we should just make it a float and then reformat it. Though I could also see it mapping to a recoverable malformed node for missing the leading zero.</p>",
        "id": 505289925,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741828857
    },
    {
        "content": "<p>I think <code>.7</code> should not be valid</p>",
        "id": 505293518,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741830485
    },
    {
        "content": "<p>I think <code>.7</code> should not be valid</p>",
        "id": 505293535,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741830495
    },
    {
        "content": "<p>I guess the question is how is it invalid. As in, if we see <code>.7</code>, I am 99% sure that we want the formatter to output <code>0.7</code>. so simply treating it as a valid float in the compiler without any sort of malformed node may be the best bet? I guess we should still push a message. That way we can raise a warning?</p>",
        "id": 505293946,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741830689
    },
    {
        "content": "<p>I guess I'm not fully sure when we want a malformed node vs a message vs etc</p>",
        "id": 505293990,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741830715
    },
    {
        "content": "<p>today <code>.7</code> is a tuple accessor function, but I believe we discussed how that syntax needs to change to <code>_.7</code></p>",
        "id": 505295007,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1741831160
    },
    {
        "content": "<p>so if it's not a tuple accessor, it seems fine to have it be a number literal</p>",
        "id": 505295042,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1741831178
    },
    {
        "content": "<p>but yeah I'd have the formatter add the <code>0</code></p>",
        "id": 505295068,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1741831190
    },
    {
        "content": "<p>totally forgot about tuple accessors</p>",
        "id": 505295895,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741831525
    },
    {
        "content": "<p>I would expect <code>0u8.0</code> to be: 0u8 (an int literal), then a NoSpaceDotInt token</p>",
        "id": 505312717,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1741838576
    },
    {
        "content": "<p>Yeah, so the issue here is technically reprinting for the fuzzer. Gets turned into <code>111.1</code>.</p>",
        "id": 505320154,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741842401
    },
    {
        "content": "<p>hmm, yeah, I think we need smarter number reprinting. Another example failure that is really the reprinting:<br>\n<code>0o0.0</code> becomes <code>111.1</code>.  First parses as an int and then a NoSpaceDotInt. The second parses as a float.</p>",
        "id": 505323802,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741844224
    },
    {
        "content": "<p>How do people feel about adding a <code>FileStart</code> token that is always the first, in the zero'th position?</p>\n<p>For something like a <code>.missing_header</code> diagnostic, it would make more sense to attach that to the whole file than to a single token. Maybe there are other errors that apply to the whole file?</p>\n<p>Or should we special case the error in this case and if something comes up in future that we want to apply for the whole file, we revisit?</p>",
        "id": 505589527,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741930665
    },
    {
        "content": "<p>Here is a fuzz crash I was looking at. To get formatting stable, we will need to format something for these malformed nodes. </p>\n<p>The question is what. </p>\n<p>My first thought was just write out the original bytes. </p>\n<div class=\"codehilite\"><pre><span></span><code>~~~SOURCE\n4o|\n~~~PROBLEMS\nPARSER: missing_header\nPARSER: unexpected_token\n~~~TOKENS\nMalformedNumberBadSuffix(1:1-1:3),OpBar(1:3-1:4),EndOfFile(1:4-1:4),\n~~~PARSE\n(file (1:1-1:4)\n    (malformed_header (1:1-1:3) &quot;missing_header&quot;)\n    (malformed_expr (1:3-1:4) &quot;unexpected_token&quot;))\n</code></pre></div>",
        "id": 505589699,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741930751
    },
    {
        "content": "<p>I would start by just not formatting on failures like this</p>",
        "id": 505589754,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741930787
    },
    {
        "content": "<p>You have problems, so don't format at all. Just stop after parse</p>",
        "id": 505589819,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741930806
    },
    {
        "content": "<p>This is what I'm looking at... is this just a <code>repro-parse</code> specific thing then?</p>\n<div class=\"codehilite\"><pre><span></span><code>$ zig build repro-parse -- /private/tmp/corpus/default/crashes.2025-03-14-16:15:46/id:000003,sig:06,src:000007,time:57864030,execs:42508956,op:havoc,rep:4\nReading bytes for repro from /private/tmp/corpus/default/crashes.2025-03-14-16:15:46/id:000003,sig:06,src:000007,time:57864030,execs:42508956,op:havoc,rep:4\nslices differ. first difference occurs at index 0 (0x0)\n\n============ expected this output: =============  len: 2 (0x2)\n\n[0]: check.parse.IR.Diagnostic{ .tag = check.parse.IR.Diagnostic.Tag.missing_header, .region = check.parse.IR.Region{ .start = 0, .end = 0 } }\n[1]: check.parse.IR.Diagnostic{ .tag = check.parse.IR.Diagnostic.Tag.unexpected_token, .region = check.parse.IR.Region{ .start = 1, .end = 2 } }\n\n============= instead found this: ==============  len: 0 (0x0)\n\n\n================================================\n</code></pre></div>",
        "id": 505589863,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741930838
    },
    {
        "content": "<p>Long term, we do want to support formatting even with some problems, but that is likely to be a larger project (I guess you totally could take it on now if you want).</p>",
        "id": 505589867,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741930838
    },
    {
        "content": "<p>Interesting. I assumed we were already doing that because it seems the fuzzer is checking things even with errors.</p>",
        "id": 505589956,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741930880
    },
    {
        "content": "<p>It's not supported to</p>",
        "id": 505590121,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741930933
    },
    {
        "content": "<p>Root error starts here:</p>\n<div class=\"codehilite\" data-code-language=\"Zig\"><pre><span></span><code><span class=\"w\">    </span><span class=\"n\">std</span><span class=\"p\">.</span><span class=\"n\">testing</span><span class=\"p\">.</span><span class=\"n\">expectEqualSlices</span><span class=\"p\">(</span><span class=\"n\">IR</span><span class=\"p\">.</span><span class=\"n\">Diagnostic</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">parse_ast</span><span class=\"p\">.</span><span class=\"n\">errors</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"o\">&amp;</span><span class=\"p\">[</span><span class=\"n\">_</span><span class=\"p\">]</span><span class=\"n\">IR</span><span class=\"p\">.</span><span class=\"n\">Diagnostic</span><span class=\"p\">{})</span><span class=\"w\"> </span><span class=\"k\">catch</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<span class=\"w\">        </span><span class=\"k\">return</span><span class=\"w\"> </span><span class=\"k\">error</span><span class=\"p\">.</span><span class=\"n\">ParseFailed</span><span class=\"p\">;</span>\n<span class=\"w\">    </span><span class=\"p\">};</span>\n</code></pre></div>\n<p>Should bubble up through:</p>\n<div class=\"codehilite\" data-code-language=\"Zig\"><pre><span></span><code><span class=\"w\">    </span><span class=\"kr\">const</span><span class=\"w\"> </span><span class=\"n\">formatted</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"k\">try</span><span class=\"w\"> </span><span class=\"n\">parseAndFmt</span><span class=\"p\">(</span><span class=\"n\">gpa</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">input</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">debug</span><span class=\"p\">);</span>\n</code></pre></div>\n<p>Then should be ignored here:</p>\n<div class=\"codehilite\" data-code-language=\"Zig\"><pre><span></span><code><span class=\"w\">            </span><span class=\"k\">error</span><span class=\"p\">.</span><span class=\"n\">ParseFailed</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<span class=\"w\">                </span><span class=\"c1\">// No issue. Just bad input we couldn't parse.</span>\n<span class=\"w\">                </span><span class=\"k\">return</span><span class=\"p\">;</span>\n<span class=\"w\">            </span><span class=\"p\">},</span>\n</code></pre></div>",
        "id": 505590243,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741931012
    },
    {
        "content": "<p>Ah I see. We're not pushing the errors into ModuleEnv yet.</p>",
        "id": 505590389,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741931063
    },
    {
        "content": "<p>Oh, I don't think this checks module env errors yet, is that the issue?</p>",
        "id": 505590468,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741931103
    },
    {
        "content": "<p>Or maybe the opposite, we are pushing into the ModuleEnv but in the fuzzer it's still checking in the IR</p>",
        "id": 505590484,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741931109
    },
    {
        "content": "<p>This test case <code>4o|</code> is passing the fuzzer</p>",
        "id": 505590761,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741931255
    },
    {
        "content": "<p>It just prints out a parse error</p>",
        "id": 505590769,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741931263
    },
    {
        "content": "<p>Due to first pars failing, it exits early (and considers it a success)</p>",
        "id": 505590853,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741931285
    },
    {
        "content": "<p><code> zig build repro-parse -- -b NG98Cg== -v &amp;&amp; echo \"all passed\"</code></p>",
        "id": 505590900,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741931326
    },
    {
        "content": "<p>I guess that debug print had me confused. Thanks for explaining that</p>",
        "id": 505590957,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741931352
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>$ echo $?\n0\n</code></pre></div>",
        "id": 505590969,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741931358
    },
    {
        "content": "<p>Maybe in verbose mode we should print out  a message to clarify that on first parse failure we just exit.</p>",
        "id": 505590997,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741931377
    },
    {
        "content": "<p>That or maybe add a flag, that just uses some sort of mem eql instead of the testing version that prints on error</p>",
        "id": 505591100,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741931426
    },
    {
        "content": "<p>Yeah, someone else is going to get tripped up on this too I'm sure</p>",
        "id": 505591139,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741931453
    },
    {
        "content": "<p>How should we handle malformed tokens? here is an example.<br>\n<a href=\"/user_uploads/22008/by5PH3_T0Sfze9Fza2lgKV74/Screenshot-2025-03-14-at-17.08.52.png\">Screenshot 2025-03-14 at 17.08.52.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/22008/by5PH3_T0Sfze9Fza2lgKV74/Screenshot-2025-03-14-at-17.08.52.png\" title=\"Screenshot 2025-03-14 at 17.08.52.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"724x406\" src=\"/user_uploads/thumbnail/22008/by5PH3_T0Sfze9Fza2lgKV74/Screenshot-2025-03-14-at-17.08.52.png/840x560.webp\"></a></div><p>That currently gives us these tokens -- there isn't anything for the NUL byte</p>\n<div class=\"codehilite\"><pre><span></span><code>~~~TOKENS\nKwModule(1:1-1:7),OpenSquare(1:8-1:9),CloseSquare(1:9-1:10),Newline(1:1-1:1),\nLowerIdent(2:1-2:4),EndOfFile(2:5-2:5),\n~~~PARSE\n(file (1:1-2:5)\n    (module (1:1-1:10))\n    (ident (2:1-2:4) \"\" \"foo\"))\n</code></pre></div>",
        "id": 505593788,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741932782
    },
    {
        "content": "<p>Oh wait.. I think I see other MalformedXXX tokens <span aria-label=\"man facepalming\" class=\"emoji emoji-1f926-200d-2642\" role=\"img\" title=\"man facepalming\">:man_facepalming:</span></p>",
        "id": 505593886,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1741932833
    },
    {
        "content": "<p>Might just be <code>.MalformedUnknownToken</code></p>",
        "id": 505594476,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1741933119
    },
    {
        "content": "<p>Random comment from Loris that I think is a good idea when we consider making more intensely optimized parsers via simd or only using start offset or similar:</p>\n<p>Keep around the naive path. It makes a great fuzz oracle.</p>\n<p>That might be a long time in the future, but something to consider for more invasive changes.</p>",
        "id": 506533430,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1742317160
    },
    {
        "content": "<p>Yes!</p>",
        "id": 506546428,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1742320843
    },
    {
        "content": "<p>Also good read on optimizing a tokenizer in zig: <a href=\"https://iridescence.me/2025/03/14/elyra-part-1-optimal-tokenization/\">https://iridescence.me/2025/03/14/elyra-part-1-optimal-tokenization/</a></p>",
        "id": 506633605,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1742359865
    },
    {
        "content": "<p>Thus far the tokenizer is surprisingly resistant to my attemps to simd-ify individual functions, e.g. chompTrivia/etc). I kinda suspect llvm already doing a decent job of vectorizing the obvious things.</p>",
        "id": 528573087,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752457558
    },
    {
        "content": "<p>I would be stunned it chomp trivia uses simd. Way too many conditionals for llvm to work through</p>",
        "id": 528573718,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752458247
    },
    {
        "content": "<p>if you've got free time, the SIMDjson is my favorite paper I've ever read</p>",
        "id": 528573767,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752458300
    },
    {
        "content": "<p>it's really mind-expanding and it's not something you can just pick up anytime</p>",
        "id": 528573785,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752458314
    },
    {
        "content": "<p>really need time to digest it and play around with the concepts imo</p>",
        "id": 528573799,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752458325
    },
    {
        "content": "<p>also since that paper was written, Daniel Lemire posted how to do one of the critical vectorized classification techniques mentioned in the paper: <a href=\"https://lemire.me/blog/2025/06/01/easy-vectorized-classification-with-z3/\">https://lemire.me/blog/2025/06/01/easy-vectorized-classification-with-z3/</a></p>",
        "id": 528573967,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752458455
    },
    {
        "content": "<p>Yeah, no simd in current <code>chompTrivia</code>: <a href=\"https://zig.godbolt.org/z/PGeveEP1d\">https://zig.godbolt.org/z/PGeveEP1d</a></p>",
        "id": 528574642,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752459043
    },
    {
        "content": "<p>Also double checked <a href=\"https://zig.godbolt.org/z/cnbfhqnfx\">a simple function</a> to make sure that godbolt zig is setup to allow llvm to automatically add simd</p>",
        "id": 528574668,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752459072
    },
    {
        "content": "<p>Also, I just realized that we limit the tokenizer to 128 diagnostics, but the rest of the stack is handled differently. Probably something to make consistent</p>",
        "id": 528574810,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752459245
    },
    {
        "content": "<p>Of note, I just use tracy to plot the number of bytes being consumed by chomp trivia. The max number of bytes consumed at once is 20 and most of the time, I think it is only 1 byte. So you have a very very short loop to take advantage of simd. (this is with one of my basic million line files).</p>",
        "id": 528576448,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752460766
    },
    {
        "content": "<p>That makes the problem harder if only looking at that thin slice of the problem and not turning the whole parser to simd where you can be more consistent.</p>",
        "id": 528576475,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752460798
    },
    {
        "content": "<p>If you look at something like <code>List.roc</code> the distribution is<br>\n82% 1 char -&gt; simd probably makes this slower, in best case same (unless simd changes it to branchless then maybe faster, but still unlikely)<br>\n8% 4 char<br>\n5% 8 char<br>\n3% 12 char<br>\n1% 16 char<br>\n&lt;1% 20 or 24 char</p>",
        "id": 528577822,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752462313
    },
    {
        "content": "<p>I'm kinda confused why all of these are multiples of 4. (oh...that's tabbing via spaces, isn't it)</p>",
        "id": 528577850,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752462356
    },
    {
        "content": "<p>Oh wait...sorry...that distribution is wrong, it missed the new line early exit from chompTrivia (so is probably missing every comment which ends in a newline)</p>",
        "id": 528577932,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752462432
    },
    {
        "content": "<p>Ok, corrected distributions:<br>\n75% 1 char<br>\n5% 4 char<br>\n3% 8 char<br>\n2% 3 char<br>\n2% 12 char<br>\n1% 7 char<br>\n1% 10 char</p>\n<p>~10% 13 to 90 char<br>\nSo these are the comments. Looks like ~1 sample for most things 10 to about 90 characters. (all of these definitely should see benefit from simd)</p>",
        "id": 528579462,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752464359
    },
    {
        "content": "<p>But yeah, 75% 1 char means that simd will be hard to show value on this function alone. Cause 75% of the time we likely are doing more work because of simd.</p>",
        "id": 528579539,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752464455
    },
    {
        "content": "<p>Switching from the manual loop looking for newlines after comments to indexOfScalarPos instead (which is vectorized internally), seemed to have basically no difference (even a slight regression actually).</p>",
        "id": 528579573,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752464492
    },
    {
        "content": "<p>What corpus are you using?</p>",
        "id": 528579613,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752464522
    },
    {
        "content": "<p>Yeah, good point about doing the simd-ification at the level of the outer loop</p>",
        "id": 528579644,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752464552
    },
    {
        "content": "<p>That distribution is just from <code>List.roc</code>. I wanted to see roughly what a normal (but highly commented file) would map to.</p>",
        "id": 528579652,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752464559
    },
    {
        "content": "<p>Cause <code>List.roc</code> is approximately the best case.</p>",
        "id": 528579666,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752464577
    },
    {
        "content": "<blockquote>\n<p>Switching from the manual loop looking for newlines after comments to indexOfScalarPos instead (which is vectorized internally), seemed to have basically no difference (even a slight regression actually).</p>\n</blockquote>\n<p>Might turn into a case where it ends up being hardware/dataset dependent for if it is a win. Might also only be a win for cpus that are in performance mode rather than standard power management settings.</p>\n<p>One of the really hard parts of simd is that if only a small part of a program is simd, even if that part is faster, it might cause enough heat that the cpu down clocks. That then leads to all the rest of the program running slower. This is part of the reason why just having a tiny bit of simd can often fail.</p>",
        "id": 528579777,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752464707
    },
    {
        "content": "<p>Does zig have simd intrinsics?</p>",
        "id": 528580210,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752465186
    },
    {
        "content": "<p><code>@Vector</code> I think is guaranteed to map to simd.</p>",
        "id": 528580352,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752465326
    },
    {
        "content": "<p>At least it is the intended type to use to get simd.</p>",
        "id": 528580367,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752465345
    },
    {
        "content": "<p>The basic simd stuff like <code>@Vector/@select/etc</code> is sufficient for a lot of cases, but I don't see any of the table lookup stuff (e.g. vqtbl4q_u8)</p>",
        "id": 528580407,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752465378
    },
    {
        "content": "<p>Oh, though also yes under <a href=\"https://ziglang.org/documentation/master/std/#std.simd\">std.simd</a></p>",
        "id": 528580409,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752465380
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"453336\">Joshua Warner</span> <a href=\"#narrow/channel/395097-compiler-development/topic/zig.20compiler.20-.20tokenizer/near/528579573\">said</a>:</p>\n<blockquote>\n<p>Switching from the manual loop looking for newlines after comments to indexOfScalarPos instead (which is vectorized internally), seemed to have basically no difference (even a slight regression actually).</p>\n</blockquote>\n<p>Just tested this on my M1 mac I see just under an 8% gain in performance for tokenizing the 1 million lines of code duplicated version of List.roc (and that is on battery, though plug in makes no difference)</p>",
        "id": 528580607,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752465597
    },
    {
        "content": "<p>For tokenizing normal <code>List.roc</code>, I see a 3% gain, but that may be noise.</p>",
        "id": 528580870,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752465742
    },
    {
        "content": "<p>runs so fast that it might be other things causing the perf change.</p>",
        "id": 528580900,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1752465771
    },
    {
        "content": "<p>I think maybe my current benchmark is too small</p>",
        "id": 528581715,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752466559
    },
    {
        "content": "<p>I finally figured out how to an almost-fully-vectorized version of _most_ of the tokenizer (in particular, excluding comments and strings)</p>",
        "id": 529392838,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816562
    },
    {
        "content": "<p><a href=\"https://github.com/joshuawarner32/roc/blob/improve-tokenize/tokenize_experimental.zig\">https://github.com/joshuawarner32/roc/blob/improve-tokenize/tokenize_experimental.zig</a></p>",
        "id": 529392926,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816625
    },
    {
        "content": "<p>For a baseline, on my machine the current tokenizer does about 250 megabytes a second</p>",
        "id": 529392962,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816658
    },
    {
        "content": "<p>If I don't try to _store_ the tokenized results - just leave them in the computed bitsets, this one gets ~700 mbps</p>",
        "id": 529393017,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816695
    },
    {
        "content": "<p>... but when I do store, the perf tanks :/</p>",
        "id": 529393035,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816710
    },
    {
        "content": "<p>It only gets ~140 mbps</p>",
        "id": 529393053,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816721
    },
    {
        "content": "<p>I have a suspicion avx512 instructions may be more conducive to this than neon</p>",
        "id": 529393101,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816760
    },
    {
        "content": "<p>If someone can figure out how to do <a href=\"https://github.com/joshuawarner32/roc/blob/improve-tokenize/tokenize_experimental.zig#L250\">this</a> faster... that's the main bottleneck.</p>",
        "id": 529393184,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816827
    },
    {
        "content": "<p>Also note that this is not capturing any info about idents/nums/etc - and for example is completely omitting ident interning for instance.</p>",
        "id": 529393283,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816900
    },
    {
        "content": "<p>Ident interning is the slowest part of the current tokenizer, and removing that brings its perf up to ~375 mbps or so</p>",
        "id": 529393319,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816934
    },
    {
        "content": "<p>Oh and this one is missing keyword checking too</p>",
        "id": 529393399,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752816993
    },
    {
        "content": "<p>Fun experiment. <span aria-label=\"racecar\" class=\"emoji emoji-1f3ce\" role=\"img\" title=\"racecar\">:racecar:</span></p>",
        "id": 529393482,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1752817044
    },
    {
        "content": "<p>Yep, and I learned some things!</p>",
        "id": 529393525,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752817074
    },
    {
        "content": "<p>I think the actual answer is to do substantially less simd stuff and break out quicker into regular code</p>",
        "id": 529393696,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752817185
    },
    {
        "content": "<p>It's unclear as of yet whether this idea of processing things in chunks, 64 bytes at a time has any legs.</p>",
        "id": 529393788,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752817244
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"453336\">Joshua Warner</span> <a href=\"#narrow/channel/395097-compiler-development/topic/zig.20compiler.20-.20tokenizer/near/529393035\">said</a>:</p>\n<blockquote>\n<p>If I don't try to _store_ the tokenized results - just leave them in the computed bitsets, this one gets ~700 mbps<br>\n... but when I do store, the perf tanks :/</p>\n</blockquote>\n<p>can't we turn them into parse IR nodes and not store the tokens at all?</p>",
        "id": 529495308,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752856862
    },
    {
        "content": "<p>in other words, we materialize parse IR nodes but we never actually construct a full list of tokens; they only exist emphemerally in these 64B chunks (give or take 1 extra node for lookahead or something if necessary)</p>",
        "id": 529495398,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752856895
    },
    {
        "content": "<p>this would also mean we could just keep a running total of \"current region\" and only actually store <code>Region</code> nodes in memory when it's time to create an actual AST nodes</p>",
        "id": 529495514,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752856954
    },
    {
        "content": "<p>Ah - so the parser is directly reading from this bitset representation? <img alt=\":think-spin:\" class=\"emoji\" src=\"https://avatars.zulip.com/22008/emoji/images/8dd6d877.gif\" title=\"think-spin\"></p>",
        "id": 529495752,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752857062
    },
    {
        "content": "<p>yep!</p>",
        "id": 529495807,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752857089
    },
    {
        "content": "<p>basically have the parser be a function that's called like \"chomp token\" and it takes the current parser state, the current byte position in the source code, the byte length of the token, and maybe optionally the next token if we need to lookahead</p>",
        "id": 529496066,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752857193
    },
    {
        "content": "<p>so we only ever have one 64B bitset worth of tokens in memory at a time (again give or take an extra token for lookahead)</p>",
        "id": 529496165,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752857233
    },
    {
        "content": "<p>Hmm, why invert the control of the parser like that?</p>",
        "id": 529496220,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752857254
    },
    {
        "content": "<p>I think this could be done with the parser pulling from the tokenizer rather than the tokenizer pushing to the parser</p>",
        "id": 529496288,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752857284
    },
    {
        "content": "<p>Given the complex recursion going on in the parser, it'll be much better from a code perspective to have that be driving things</p>",
        "id": 529496335,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752857305
    },
    {
        "content": "<p>I think we will need at least two tokens of lookahead actually materialized</p>",
        "id": 529496823,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752857512
    },
    {
        "content": "<p>(not in the bitset)</p>",
        "id": 529496852,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752857522
    },
    {
        "content": "<p>Otherwise lookahead becomes very complicated</p>",
        "id": 529496888,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752857535
    },
    {
        "content": "<p>There are cases where we need to check what's after the immediate next token, and we may need to do that repeatedly so we don't want to do linear-time search thru the bitset repeatedly.</p>",
        "id": 529496976,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1752857579
    },
    {
        "content": "<p>sure, either way</p>",
        "id": 529497276,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752857727
    },
    {
        "content": "<p>I mean another way to think of \"lookahead\" is like \"I'm not ready to proceed yet, so just write down the token temporarily and give me the next one\"</p>",
        "id": 529497364,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752857772
    },
    {
        "content": "<p>so when you need to lookahead multiple tokens, what that means in practice is that you start building up a list of tokens in memory - but just the ones you actually need, not materializing the entire token list - and then after you're ready to go back and process the original one, then you continue going through that list until it's exhausted, and then you're done and ready to go back to the non-materialized token stream</p>",
        "id": 529497508,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752857855
    },
    {
        "content": "<p>so in practice I assume you'd end up materializing way way less than today</p>",
        "id": 529497545,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752857879
    },
    {
        "content": "<p>this is also relevant to:</p>\n<p><span class=\"user-mention silent\" data-user-id=\"584248\">Kiryl Dziamura</span> <a href=\"#narrow/channel/316715-contributing/topic/Optimizing.20Tokenization.20vs.20Canonicalization/near/529437987\">said</a>:</p>\n<blockquote>\n<p>I don't feel good about replacing region info with numeric data in <code>extra</code>. the other options are always pushing this data to a separate collection (as with interned), or extending token size which of course is a terrible idea.</p>\n</blockquote>\n<p>because it would mean we could store extra info that AST nodes want more directly and not have to move them around so much</p>",
        "id": 529500419,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752859216
    },
    {
        "content": "<p>separately, I really want to get regions out of our string interner so we can just directly compare interned indices to know for sure whether the underlying strings are equal; that really comes up a lot in later stages of the compiler!</p>",
        "id": 529508128,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1752862665
    },
    {
        "content": "<p>Hi, I was looking to start contributing to the zig compiler, and looked through the tests to see what each part is doing. In the tokenizer I saw the following test and was confused:</p>\n<div class=\"codehilite\"><pre><span></span><code>try testTokenization(\n        gpa,\n        \\\\&quot;&quot;&quot;abc\n        \\\\&quot;&quot;&quot;def\n    ,\n        &amp;[_]Token.Tag{ .MultilineStringStart, .StringPart, .Newline, .MultilineStringStart, .StringPart },\n    );\n</code></pre></div>\n<p>I would have guessed this would tokenize to </p>\n<div class=\"codehilite\"><pre><span></span><code>{ .MultilineStringStart, .StringPart, .MultilineStringEnd, .LowerIdent }\n</code></pre></div>\n<p>Is this just me not understanding, or is this a bug? I could implement a fix.</p>",
        "id": 534627534,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755251795
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"453336\">@Joshua Warner</span></p>",
        "id": 534627988,
        "sender_full_name": "Anton",
        "timestamp": 1755252017
    },
    {
        "content": "<p>I think the new syntax for multi line strings is each line starts with <code>\"\"\"</code></p>",
        "id": 534633332,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755254840
    },
    {
        "content": "<p>I can't find any good examples though</p>",
        "id": 534633345,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755254847
    },
    {
        "content": "<p><a class=\"message-link\" href=\"/#narrow/channel/304641-ideas/topic/multiline.20string.20syntax/near/499130632\">#ideas &gt; multiline string syntax @ ðŸ’¬</a></p>",
        "id": 534634092,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755255208
    },
    {
        "content": "<p>I wouldn't say we came to a completely solid position... but my recollection wasn't too far off. <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 534634128,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755255229
    },
    {
        "content": "<p>I guess we just haven't implemented it yet. I'm sure Anthony would probably remember where we got to with that.</p>",
        "id": 534634379,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755255362
    },
    {
        "content": "<p>Thanks for link to the discussion, I could not find it earlier. Reading that discussion, it kind of makes sense to use \"\"\" on each line.</p>",
        "id": 534634873,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755255638
    },
    {
        "content": "<p>yeah I think <code>\"\"\"</code> at the start of each like is what we should do</p>",
        "id": 534642861,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1755260145
    },
    {
        "content": "<p>seems to have the best tradeoffs of all the options we discussed</p>",
        "id": 534642892,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1755260159
    },
    {
        "content": "<p>Yep, I think i just forgot to add multiline strings to the parser</p>",
        "id": 534654241,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1755264999
    },
    {
        "content": "<p>It's an easy add though</p>",
        "id": 534654276,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1755265008
    },
    {
        "content": "<p>I could try to add it.</p>",
        "id": 534656609,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755265857
    },
    {
        "content": "<p>Should there be an additional multiline_string for the AST or should the string be reused?</p>",
        "id": 534660608,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755267319
    },
    {
        "content": "<p>I think we want a separate AST node</p>",
        "id": 534664961,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1755269052
    },
    {
        "content": "<p>i agree</p>",
        "id": 534668381,
        "sender_full_name": "Anthony Bullard",
        "timestamp": 1755270397
    },
    {
        "content": "<p><a href=\"https://github.com/roc-lang/roc/issues/8200\">#8200</a> Multiline string parsing seems to work, format has bugs I think, but I could probably fix those myself. But I would like to know what to do in Can. That's probably the point where it gets combined with normal strings?</p>",
        "id": 534706262,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755288132
    },
    {
        "content": "<p>So my PR <a href=\"https://github.com/roc-lang/roc/issues/8200\">#8200</a> introduced a bug (that fuzzer is crazy cool!):</p>\n<div class=\"codehilite\"><pre><span></span><code>$ zig build repro-parse -- -b bW9kdWxlW11sPSIiIiI= -v\nUsing bytes as base64 encoded repro: bW9kdWxlW11sPSIiIiI=\nOriginal:\n==========\nmodule[]l=&quot;&quot;&quot;&quot;\n==========\n\nFormatted:\n==========\nmodule []\nl = &quot;&quot;&quot;&quot;&quot;&quot;&quot;\n==========\n</code></pre></div>\n<p>the original gets tokenized as <code>MultilineStringStart, StringPart(\")</code>.<br>\nBut since this is a single line, the formatter adds <code>\"\"\"</code> as an <code>MultilineStringEnd</code>.<br>\nBut this then get's tokenized as <code>MultilineStringStart, MultilineStringEnd, StringStart</code>, which is obviously a problem.</p>\n<p>So how should this be fixed?</p>\n<ol>\n<li>Improve the formatter to not add <code>\"\"\"</code> at the end, if it wasn`t there already?</li>\n<li>Change the tokenizer to tokenize <code>\"\"\"\"\"\"\"</code> into  <code>MultilineStringStart, StringPart(\"),MultilineStringEnd</code>?</li>\n<li>Both 1. and 2. ?</li>\n<li>Remove the MultilineStringEnd feature all together?</li>\n</ol>\n<p>I think 2. would be good anyway, because if  <code>\"\"\"\"quotes\" I want to escape\"\"\"</code> works, why shouldn't <code>\"\"\"I want to escape \"quotes\"\"\"\"</code>?</p>",
        "id": 535315616,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755696913
    },
    {
        "content": "<p>To me, the existence of <code>MultilineStringEnd</code> is kind of confusing, because it ends up being optional.</p>",
        "id": 535332114,
        "sender_full_name": "JRI98",
        "timestamp": 1755701506
    },
    {
        "content": "<p>I think it might be useful for not having to escape quotes like <code>some_fn(\"\"\"some \"quotes \" in \"this\" string\"\"\", other_var)</code>. However I have no idea how useful that is in practice. But to be honest, it's quite a nice feature in Python to be able to switch between double and single quotes to not have to escape the other, so people might miss it.</p>",
        "id": 535380835,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755719433
    },
    {
        "content": "<p>You don't have to escape quotes already - except insofar as they don't come exactly at the end of the multiline string.</p>",
        "id": 535381199,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755719594
    },
    {
        "content": "<p>I feel we likely should just not allow single line multiline strings. I feel it is more confusing...but just a rough opinion.</p>",
        "id": 535386159,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1755722078
    },
    {
        "content": "<p>It's not just single-line ones - it's how you indicate you don't want your string terminated by a newline</p>",
        "id": 535386722,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755722353
    },
    {
        "content": "<p>e.g.</p>\n<div class=\"codehilite\"><pre><span></span><code>foo = &quot;&quot;&quot;line one\n      &quot;&quot;&quot;line two, with trailing newline\n\nbar = &quot;&quot;&quot;line one\n      &quot;&quot;&quot;line two, without trailing newline&quot;&quot;&quot;\n</code></pre></div>",
        "id": 535386829,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755722402
    },
    {
        "content": "<p>I suppose we could adopt a different syntax for that - perhaps a trailing backslash instead?</p>",
        "id": 535386885,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755722432
    },
    {
        "content": "<p>e.g. </p>\n<div class=\"codehilite\"><pre><span></span><code>bar = &quot;&quot;&quot;line one\n      &quot;&quot;&quot;line two, without trailing newline\\\n</code></pre></div>",
        "id": 535386900,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755722446
    },
    {
        "content": "<p>That's more generalizable to any line in the string, so seems maybe better?</p>",
        "id": 535386941,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755722466
    },
    {
        "content": "<p>e.g. you could maybe do:</p>\n<div class=\"codehilite\"><pre><span></span><code>bar = &quot;&quot;&quot;line one \\\n      &quot;&quot;&quot;,still the same line!\n</code></pre></div>",
        "id": 535387032,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755722514
    },
    {
        "content": "<p>In Zig, for example, the newline is added as part of starting the next line in a multiline string, as opposed to including the one at the end of the line <a href=\"https://ziglang.org/documentation/master/#Multiline-String-Literals\">https://ziglang.org/documentation/master/#Multiline-String-Literals</a></p>",
        "id": 535387500,
        "sender_full_name": "JRI98",
        "timestamp": 1755722744
    },
    {
        "content": "<p>Ahhh interesting, so if you want a newline, you put a \"\"\" (with nothing after) on the next line. <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> I could get behind that.</p>",
        "id": 535387582,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755722784
    },
    {
        "content": "<p>Yeah, exactly that</p>",
        "id": 535388833,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1755723413
    },
    {
        "content": "<p>Also, I guess single line is technically fine, I guess I more suggest no termination.</p>\n<p>So this is fine by me</p>\n<div class=\"codehilite\"><pre><span></span><code>foo = &quot;&quot;&quot;Single line multiline string\n</code></pre></div>\n<p>But this is not</p>\n<div class=\"codehilite\"><pre><span></span><code>bar(&quot;&quot;&quot;single line terminated multiline string&quot;&quot;&quot;)\n</code></pre></div>",
        "id": 535388988,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1755723495
    },
    {
        "content": "<p>I guess that is my default preference</p>",
        "id": 535389012,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1755723509
    },
    {
        "content": "<p>I like using single line multi line strings so that I donâ€™t have to escape quotes. Very convenient sometimes</p>",
        "id": 535410177,
        "sender_full_name": "Isaac Van Doren",
        "timestamp": 1755737625
    },
    {
        "content": "<p>Maybe better to have a proper raw string syntax, to avoid escaping all together? e.g. with something like rust's <code>r#\"foo\"#</code> (with a variable number of #'s), lua's <code>[=[foo]=]</code> (with a variable number of ='s), etc.</p>",
        "id": 535426063,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755749783
    },
    {
        "content": "<p>What is a single line multi line string?</p>",
        "id": 535427052,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755750570
    },
    {
        "content": "<p>I guess the idea is that you include a string verbatim and the <code>\"</code> don't need escaping</p>",
        "id": 535427189,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755750628
    },
    {
        "content": "<p>Right, except it does need to be escaped if it's at the end of the string, which seems like a significant foot-gun. (in fact, that's the foot gun that started this convo!)</p>",
        "id": 535427328,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755750672
    },
    {
        "content": "<p>Does the Zig approach with an extra <code>\"\"\"</code> solve this for us?</p>",
        "id": 535427523,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755750733
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>foo = &quot;&quot;&quot;single line followed by a newline\n      &quot;&quot;&quot;\n</code></pre></div>",
        "id": 535427590,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1755750773
    },
    {
        "content": "<p>Yes and no. It removes the footgun, but it doesn't  solve <span class=\"user-mention\" data-user-id=\"611722\">@Isaac Van Doren</span> 's desire for a way to have a single-line string they don't need to escape quotes in.</p>",
        "id": 535427642,
        "sender_full_name": "Joshua Warner",
        "timestamp": 1755750807
    },
    {
        "content": "<p>You can have single line \"multiline\" strings even without the MultilineStringEnd. You just cannot have anything after it in the same line, because it will be considered part of the line. </p>\n<p>So declarations work, which is the main use case.</p>\n<p>I think removing MultilineStringEnd is the way to go, and if I understand correctly this is the consensus here. I will do that when I get time.</p>",
        "id": 535439931,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755758907
    },
    {
        "content": "<p>Yeah it doesnâ€™t come up that often to need one on a single line with code after, just convenient every now and then. It doesnâ€™t seem worth adding a new raw string syntax just to support that</p>",
        "id": 535484363,
        "sender_full_name": "Isaac Van Doren",
        "timestamp": 1755775968
    },
    {
        "content": "<p>That fuzzer finds everything. So the next problem with the multiline strings is if they are inside any type of collection. The formatter adds a <code>,</code> at the end of every entry at the end of a line, which then becomes part of the string.</p>\n<div class=\"codehilite\"><pre><span></span><code>(\n    &quot;&quot;&quot;Hello\n    , &quot;there&quot;\n)\n</code></pre></div>\n<p>formats to </p>\n<div class=\"codehilite\"><pre><span></span><code>(\n    &quot;&quot;&quot;Hello,\n    &quot;there&quot;,\n)\n</code></pre></div>\n<p>which is a parser error.</p>\n<p>Solution could be to allow multiline strings only in top level assignments, or have a special multiline string rule in the collection formatter.</p>",
        "id": 535659730,
        "sender_full_name": "Fabian Schmalzried",
        "timestamp": 1755860449
    },
    {
        "content": "<p>special rule makes sense to me - probably put the commas on their own line</p>",
        "id": 535662091,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1755861453
    },
    {
        "content": "<p>Small aside, the fuzzer found other crashes <a href=\"https://roc-lang.github.io/roc-compiler-fuzz\">https://roc-lang.github.io/roc-compiler-fuzz</a></p>",
        "id": 535662607,
        "sender_full_name": "JRI98",
        "timestamp": 1755861663
    }
]