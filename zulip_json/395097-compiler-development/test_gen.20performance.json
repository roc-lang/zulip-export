[
    {
        "content": "<p>so, I'm looking at our <code>test_gen</code> crate with some of the rust internal tooling and, wth?</p>\n<div class=\"codehilite\"><pre><span></span><code>time:   1.480; rss:  881MB -&gt; 1178MB ( +297MB)  codegen_to_LLVM_IR\ntime:   2.771; rss:  786MB -&gt; 1178MB ( +392MB)  codegen_crate\ntime:   0.163; rss: 1178MB -&gt; 1204MB (  +26MB)  encode_query_results\ntime:   0.206; rss: 1178MB -&gt; 1222MB (  +44MB)  incr_comp_serialize_result_cache\ntime:   0.206; rss: 1178MB -&gt; 1222MB (  +44MB)  incr_comp_persist_result_cache\ntime:   0.206; rss: 1178MB -&gt; 1222MB (  +44MB)  serialize_dep_graph\ntime:   0.054; rss: 1222MB -&gt;  976MB ( -246MB)  free_global_ctxt\ntime:   2.366; rss:  909MB -&gt;  879MB (  -30MB)  LLVM_passes\ntime:   0.000; rss:  869MB -&gt;  857MB (  -13MB)  join_worker_thread\ntime:   0.001; rss:  857MB -&gt;  834MB (  -23MB)  copy_all_cgu_workproducts_to_incr_comp_cache_dir\ntime:   0.209; rss:  976MB -&gt;  834MB ( -142MB)  finish_ongoing_codegen\ntime:   0.000; rss:  834MB -&gt;  831MB (   -3MB)  serialize_work_products\ntime:   0.000; rss:  774MB -&gt;  770MB (   -4MB)  link_binary_check_files_are_writeable\ntime:  10.027; rss:  770MB -&gt;  771MB (   +0MB)  run_linker\ntime:  10.032; rss:  774MB -&gt;  771MB (   -3MB)  link_binary\ntime:  10.032; rss:  774MB -&gt;  771MB (   -3MB)  link_crate\ntime:  10.242; rss:  976MB -&gt;  771MB ( -205MB)  link\ntime:  20.540; rss:   26MB -&gt;   92MB (  +66MB)  total\n</code></pre></div>\n<p>hard to interpret this, but those linking times are just crazy. also why is the memory residency almost 1GB here? what is happening?</p>",
        "id": 396754389,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697376670
    },
    {
        "content": "<p>is that trace different than what it is when you try to build the cli binary?</p>",
        "id": 396756989,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1697378552
    },
    {
        "content": "<p>well, yes? different crates get built if you do that?</p>",
        "id": 396758971,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697380326
    },
    {
        "content": "<p>I also compared this with the test suite of ntpd-rs and our numbers are just absolutely crazy here</p>",
        "id": 396758991,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697380363
    },
    {
        "content": "<p>for linking,  it might be </p>\n<ul>\n<li>we just have a lot of tests in this crate, and that causes a linear amount of work</li>\n<li>we have a lot of crates in the graph, all of them need to be joined together (which just might be exponential work?)</li>\n</ul>",
        "id": 396759043,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697380423
    },
    {
        "content": "<p>interesting re our ealier discussion: macro expansion does not seem to be a big problem (though it's not great)</p>\n<div class=\"codehilite\"><pre><span></span><code>time:   0.164; rss:   26MB -&gt;   64MB (  +37MB)  total\ntime:   0.000; rss:   33MB -&gt;   35MB (   +2MB)  parse_crate\ntime:   0.708; rss:   39MB -&gt;  313MB ( +274MB)  expand_crate\ntime:   0.708; rss:   39MB -&gt;  313MB ( +274MB)  macro_expand_crate\ntime:   0.024; rss:  313MB -&gt;  313MB (   +0MB)  maybe_building_test_harness\ntime:   0.014; rss:  313MB -&gt;  313MB (   +0MB)  AST_validation\ntime:   0.007; rss:  313MB -&gt;  313MB (   +0MB)  finalize_imports\ntime:   0.017; rss:  313MB -&gt;  313MB (   +1MB)  finalize_macro_resolutions\ntime:   0.127; rss:  313MB -&gt;  352MB (  +38MB)  late_resolve_crate\n</code></pre></div>",
        "id": 396759118,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697380470
    },
    {
        "content": "<p>Is memory just a cumulative thing where we have so much running in parallel or the linker loading so many crates at once?</p>",
        "id": 396759173,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1697380530
    },
    {
        "content": "<p>I don't know and I cannot find the docs on it. I've asked on the rust zullip what these numbers really mean</p>",
        "id": 396759242,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697380567
    },
    {
        "content": "<p>well, so it turns out that a big part of the problem here is debug info. the binary is ~450mb, but after stripping only 50mb remains</p>",
        "id": 396762560,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697383085
    },
    {
        "content": "<p>yay for debug info</p>",
        "id": 396764130,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1697384154
    },
    {
        "content": "<p>this is something we should think about when we start wanting to generate debug info in Roc dev builds</p>",
        "id": 396764773,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697384735
    },
    {
        "content": "<p>I wonder if there's some way to like cache it in a way where the surgical linker can staple it in without it having to be regenerated from scratch every time</p>",
        "id": 396764872,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697384782
    },
    {
        "content": "<p>like cache it on a per module basis or something, give or take specializations maybe needing special treatment somehow</p>",
        "id": 396764921,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1697384827
    },
    {
        "content": "<p>Yeah, I have not even though about linking debug info at all...not sure how stapling dwarf together works</p>",
        "id": 396765119,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1697385001
    },
    {
        "content": "<p>Re different traces Folkert-what I mean is, are the times for specialization/linking significantly different for the test binary vs cli binary?</p>",
        "id": 396765422,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1697385257
    },
    {
        "content": "<p>I remember looking into this about a year ago and the large number of tests have a big part in it. if you comment out a bunch of them, or break them up into test crates, each crate is much faster to compile and link. Not sure why this was though</p>",
        "id": 396765471,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1697385328
    },
    {
        "content": "<p>did Jack provide any insights?</p>",
        "id": 396765486,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1697385341
    },
    {
        "content": "<p>no so this is what I want to figure out right. also those numbers are wrong because mold does not end up getting used ...</p>",
        "id": 396765755,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697385601
    },
    {
        "content": "<p>because the rustflags are overwritten when you enable the <code>-Ztime-passes</code>.  these are more real numbers</p>\n<div class=\"codehilite\"><pre><span></span><code>time:   0.344; rss:  664MB -&gt;  677MB (  +13MB)  serialize_dep_graph\ntime:   0.038; rss:  677MB -&gt;  449MB ( -227MB)  free_global_ctxt\ntime:   0.010; rss:  411MB -&gt;  411MB (   +0MB)  incr_comp_finalize_session_directory\ntime:   0.466; rss:  411MB -&gt;  411MB (   +0MB)  run_linker\ntime:   0.472; rss:  411MB -&gt;  409MB (   -2MB)  link_binary\ntime:   0.472; rss:  411MB -&gt;  409MB (   -2MB)  link_crate\ntime:   0.488; rss:  449MB -&gt;  409MB (  -40MB)  link\ntime:   2.927; rss:   26MB -&gt;   75MB (  +49MB)  total\n</code></pre></div>\n<p>af which point the macro expansion from before actually becomes relevant again</p>",
        "id": 396765873,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697385657
    },
    {
        "content": "<p>total time is off here because cargo clean is weird in this scenario, but link time should always be constant. So here it generates simpler debug info (only lines) and uses mold</p>",
        "id": 396765930,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697385710
    },
    {
        "content": "<p>I did some more tests and chatted with Jack. I think we should remove our use of <code>indoc!</code>. it is a proc macro and therefore cannot be cached. We can use a <code>thread_local!</code> <code>String</code> to perform the stripping of the whitespace at runtime. We only run the test once so whether this work happens at comptime or runtime for test_gen is not really relevant</p>",
        "id": 397763707,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697829374
    },
    {
        "content": "<p>you know what would make it really fast? if we discovered and loaded the tests from disk like we do like for UItest. Then we would only need to compile one thing, the test runner</p>",
        "id": 397764375,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1697829726
    },
    {
        "content": "<p>but it's annoying with all the small tests we have</p>",
        "id": 397764506,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697829808
    },
    {
        "content": "<p>and also the output here can't be captured nicely in a string generally</p>",
        "id": 397764631,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697829866
    },
    {
        "content": "<p>I think the Zig compiler tests use a big .zig file with a bunch of test functions in it. The test runner just calls them all. I wonder if we could do something similar.</p>",
        "id": 397768391,
        "sender_full_name": "Brian Carroll",
        "timestamp": 1697831752
    },
    {
        "content": "<p>well we'd need to be able to have multiple mains</p>",
        "id": 397768519,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697831801
    },
    {
        "content": "<p>but that is an interesting direction to explore</p>",
        "id": 397768530,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1697831811
    },
    {
        "content": "<p>One main could call them all.<br>\nThey could take an empty record and return a Boolean?<br>\nMaybe we make a list of Booleans and check they're all true?</p>",
        "id": 397768834,
        "sender_full_name": "Brian Carroll",
        "timestamp": 1697831997
    }
]