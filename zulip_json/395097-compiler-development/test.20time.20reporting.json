[
    {
        "content": "<p>Currently on main, test reports are as follows: <code>1 failed and 13 passed in 77 ms.</code> this 77ms includes <code>load_and_monomorphize</code>, <code>expect_mono_module_to_dylib</code> and executing the tests. Now in <a href=\"https://github.com/roc-lang/roc/pull/6567\">PR#6567</a> we want to report failures and passes per module but this leaves us with the question; what should we do with the timing of <code>load_and_monomorphize</code> and <code>expect_mono_module_to_dylib</code>? Because we're still only executing those once for all modules combined.</p>\n<p>I'm thinking we should report that before running tests as <code>Compiled in X ms.</code>. What do you think?</p>",
        "id": 426187328,
        "sender_full_name": "Anton",
        "timestamp": 1710267504
    },
    {
        "content": "<p>personally what I care about by default is noticing when my tests are taking a long time, so the number I'm really interested in is the total end-to-end time</p>",
        "id": 426187530,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710267593
    },
    {
        "content": "<p>if I want to debug why tests are taking a long time, I want to pass a flag of some sort (e.g. <code>--verbose</code>) to get per-test timings, including for successes</p>",
        "id": 426187651,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710267632
    },
    {
        "content": "<p>and I think when a flag like that is enabled, it would make sense to distinguish between compile times and test times</p>",
        "id": 426187693,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710267652
    },
    {
        "content": "<p>but in the default case I like it being concise and focused on the number that matters most <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 426187725,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710267666
    },
    {
        "content": "<p>Yeah, makes sense <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 426188408,
        "sender_full_name": "Anton",
        "timestamp": 1710267917
    },
    {
        "content": "<p>So the behavior here would be:</p>\n<ul>\n<li>Keep the default behavior the same as what it is now: only display the total number of tests that passed/failed, and the total runtime</li>\n<li>Add a <code>--verbose</code> flag that would report, separately: a) compilation time for all of the tests, and b) the runtime and number of passed/failed tests per module</li>\n</ul>\n<p>I like that -- keep the default case terse, but make it easy to drill down and find problematic tests (at least by module, for now). How does that sound?</p>",
        "id": 426373135,
        "sender_full_name": "Jonathan Schear",
        "timestamp": 1710345465
    },
    {
        "content": "<p>I would still report tests passed/failed tests per module by default. You can argue that performance is a detail but for multiple modules I would definitely want to see fail/pass count per module.</p>",
        "id": 426375750,
        "sender_full_name": "Anton",
        "timestamp": 1710346142
    },
    {
        "content": "<p>I'm making the change like that now, will push in a bit...</p>",
        "id": 426375840,
        "sender_full_name": "Anton",
        "timestamp": 1710346169
    },
    {
        "content": "<p>hm, so personally I am a big proponent of \"only show me what's relevant\" for test output</p>",
        "id": 426376520,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710346361
    },
    {
        "content": "<p>and one of the things I dislike about test runners in big projects is that 99% of the output on my screen is \"all the tests passed for this module I have never heard of and will never touch in my entire life\"</p>",
        "id": 426376631,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710346393
    },
    {
        "content": "<p>I think the best way to combat that and keep the output relevant is to have the output be constant rather than linear in the number of modules, and only linear in the number of failed tests (because those are all actionable; I need to address all of those failures!)</p>",
        "id": 426376810,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710346442
    },
    {
        "content": "<p>at least by default</p>",
        "id": 426376888,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710346453
    },
    {
        "content": "<p>this is also why I don't like to print passed tests by default, except as a single number in the summary line</p>",
        "id": 426377057,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710346501
    },
    {
        "content": "<blockquote>\n<p>\"all the tests passed for this module I have never heard of and will never touch in my entire life\"</p>\n</blockquote>\n<p>I get that but I also value transparency, if you have 5+ modules it can be easy for one to fly under the radar untested because you never see its name when running the tests.</p>",
        "id": 426377609,
        "sender_full_name": "Anton",
        "timestamp": 1710346647
    },
    {
        "content": "<p>Do you know of any popular test tools for a popular language that don't print a module name if all tests passed for it?</p>",
        "id": 426377866,
        "sender_full_name": "Anton",
        "timestamp": 1710346716
    },
    {
        "content": "<p>hm, pretty much all of those have separate test files rather than inline tests in the modules where the code lives. (Rust would be a notable exception.)</p>",
        "id": 426383793,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710348416
    },
    {
        "content": "<p>so I don't think any popular test runners attempt to solve the problem of \"module was untested by mistake\" <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span></p>",
        "id": 426383912,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710348454
    },
    {
        "content": "<p>Ok fair, so do we go with this:</p>\n<blockquote>\n<ul>\n<li>Keep the default behavior the same as what it is now: only display the total number of tests that passed/failed, and the total runtime</li>\n<li>Add a --verbose flag that would report, separately: a) compilation time for all of the tests, and b) the runtime and number of passed/failed tests per module</li>\n</ul>\n</blockquote>",
        "id": 426395448,
        "sender_full_name": "Anton",
        "timestamp": 1710351868
    },
    {
        "content": "<p>sounds good to me! <span aria-label=\"100\" class=\"emoji emoji-1f4af\" role=\"img\" title=\"100\">:100:</span></p>",
        "id": 426397208,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1710352429
    }
]