[
    {
        "content": "<p>The <code>Great SIMD ergonomics</code> section of <a href=\"https://www.modular.com/blog/mojo-vs-rust-is-mojo-faster-than-rust\">Mojo vs. Rust: is Mojo ðŸ”¥ faster than Rust ðŸ¦€ ?</a> is quite interesting.</p>\n<p>This is a very interesting idea</p>\n<blockquote>\n<p>Mojo's primitives are natively designed to be SIMD-first: <code>UInt8</code> is actually a <code>SIMD[DType.uint8, 1]</code> which is a SIMD of 1 element. There is no performance overhead to represent it this way, but it allows the programmer to easily use it for SIMD optimizations.</p>\n</blockquote>",
        "id": 421714050,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708021131
    },
    {
        "content": "<p>unrelated: I really hope they give up on this \"Mojo<span aria-label=\"fire\" class=\"emoji emoji-1f525\" role=\"img\" title=\"fire\">:fire:</span>\" \"Rust<span aria-label=\"crab\" class=\"emoji emoji-1f980\" role=\"img\" title=\"crab\">:crab:</span>\" style of writing, it bothers me every time I see it <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 421731576,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708027496
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"343810\">Brendan Hansknecht</span> <a href=\"#narrow/stream/395097-compiler-development/topic/Casual.20Conversation/near/421714050\">said</a>:</p>\n<blockquote>\n<p>This is a very interesting idea</p>\n<blockquote>\n<p>Mojo's primitives are natively designed to be SIMD-first: <code>UInt8</code> is actually a <code>SIMD[DType.uint8, 1]</code> which is a SIMD of 1 element. There is no performance overhead to represent it this way, but it allows the programmer to easily use it for SIMD optimizations.</p>\n</blockquote>\n</blockquote>\n<p>I think I'm missing something here, because there certainly is performance overhead if you put some of these into a struct, because there will be way more alignment padding <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>",
        "id": 421731938,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708027624
    },
    {
        "content": "<p>Yeah... No idea<span aria-label=\"light bulb\" class=\"emoji emoji-1f4a1\" role=\"img\" title=\"light bulb\">:light_bulb:</span> why they tripled<span aria-label=\"three\" class=\"emoji emoji-0033-20e3\" role=\"img\" title=\"three\">:three:</span> down<span aria-label=\"point down\" class=\"emoji emoji-1f447\" role=\"img\" title=\"point down\">:point_down:</span> on emojis <span aria-label=\"stuck out tongue wink\" class=\"emoji emoji-1f61c\" role=\"img\" title=\"stuck out tongue wink\">:stuck_out_tongue_wink:</span></p>",
        "id": 421732018,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708027661
    },
    {
        "content": "<p>exclusively <span aria-label=\"ring\" class=\"emoji emoji-1f48d\" role=\"img\" title=\"ring\">:ring:</span> redundant <span aria-label=\"women with bunny ears\" class=\"emoji emoji-1f46f-200d-2640\" role=\"img\" title=\"women with bunny ears\">:women_with_bunny_ears:</span> ones <span aria-label=\"one\" class=\"emoji emoji-0031-20e3\" role=\"img\" title=\"one\">:one:</span><span aria-label=\"one\" class=\"emoji emoji-0031-20e3\" role=\"img\" title=\"one\">:one:</span> too <span aria-label=\"two\" class=\"emoji emoji-0032-20e3\" role=\"img\" title=\"two\">:two:</span></p>",
        "id": 421732272,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708027756
    },
    {
        "content": "<blockquote>\n<p>because there will be way more alignment padding</p>\n</blockquote>\n<p>I think what they are really saying is that they type will implicitly promote to simd if wanted. Not that it is stored in simd alignment.</p>\n<p><code>SIMD[DType.uint8, 1]</code> -&gt; size 1 byte, alignment 1 byte. Since it is a simd type though, it can be used with other simd types.<br>\nSo you can do <code>8 * SIMD[DType.uint8, 8](2, 4, 6, 8, 16, 32, 64, 128)</code>.</p>",
        "id": 421732842,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708028004
    },
    {
        "content": "<p>I also think that the simd numbers automatically figure out how to map to the widest simd hardware that they match</p>",
        "id": 421732993,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708028053
    },
    {
        "content": "<p>So <code>SIMD[DType.uint8, 1]</code> won't actually use simd hardware if used alone. I think only if used with other simd units.</p>",
        "id": 421733035,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708028076
    },
    {
        "content": "<p>Also, I have seen some kernel code that has helpers that deal with the simd alignment mapping while also dealing with any extra elements that don't align.</p>",
        "id": 421733124,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708028119
    },
    {
        "content": "<p>It can all be automatic/run the same code, cause for most of the function, it can run with <code>SIMD[DType.uint8, 8]</code>, but for the remainder elements, it can automatically switch to running with <code>SIMD[DType.uint8, 1]</code>.</p>",
        "id": 421733253,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708028166
    },
    {
        "content": "<p>So I think it all boils down to smarter duck typing (at least it feels like duck typing). Though technically all the types are known at compile time.</p>",
        "id": 421733331,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708028208
    },
    {
        "content": "<p>ahh gotcha!</p>",
        "id": 421733850,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708028431
    },
    {
        "content": "<p>yeah I've thought about how, for example, if you have a <code>List Foo</code> in Roc, and <code>Foo</code> happens to be 32 bits in size, then we can automatically implement certain <code>List</code> operations in terms of SIMD (e.g. equals or <code>contains</code>, or if we had an <code>indexOf</code>, it could use it too)</p>",
        "id": 421734445,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708028650
    },
    {
        "content": "<blockquote>\n<p>equals or contains</p>\n</blockquote>\n<p>I don't think this is true anymore cause we have custom Eq. That said, it could be an optimization for types that don't have custom eq.</p>",
        "id": 421734607,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708028739
    },
    {
        "content": "<p>oh sure, I mean for if you're just using the default</p>",
        "id": 421734752,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708028794
    },
    {
        "content": "<p>or like if <code>Foo</code> is a type alias</p>",
        "id": 421734761,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708028799
    },
    {
        "content": "<p>Yeah. Definitely sounds like it could be useful. Of course with the minor concerns of avx512 intermixed with other code issues. Though probably we just need to follow whatever glibc memcpy does. It is highly optimized and uses some simd</p>",
        "id": 421735981,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708029271
    },
    {
        "content": "<p>17 messages were moved here from <a class=\"stream-topic\" data-stream-id=\"395097\" href=\"/#narrow/stream/395097-compiler-development/topic/Casual.20Conversation\">#compiler development &gt; Casual Conversation</a> by <span class=\"user-mention silent\" data-user-id=\"281383\">Richard Feldman</span>.</p>",
        "id": 421736652,
        "sender_full_name": "Notification Bot",
        "timestamp": 1708029561
    },
    {
        "content": "<p>regarding AVX512, I kinda assume we'll end up on the lowest common denominator of 16B SIMD but maybe not?</p>",
        "id": 421736698,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708029591
    },
    {
        "content": "<p>Many libraries do a dynamic dispatch on the supported simd.</p>",
        "id": 421736885,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708029650
    },
    {
        "content": "<p>Either at first load or at first run, update some pointers based on the simd that is available on the pc..</p>",
        "id": 421736993,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708029699
    },
    {
        "content": "<p>Not actually sure what memcpy does for glibc. They may just use the lowest common denominator.</p>",
        "id": 421737035,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708029718
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"343810\">Brendan Hansknecht</span> <a href=\"#narrow/stream/395097-compiler-development/topic/SIMD/near/421736993\">said</a>:</p>\n<blockquote>\n<p>Either at first load or at first run, update some pointers based on the simd that is available on the pc..</p>\n</blockquote>\n<p>right, I just wonder about the costs of this in practice (hopefully minimal, but maybe not?) and the \"processor dials back clock speed because avx512 runs hot\" concern we talked about in some other thread</p>",
        "id": 421737436,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708029871
    },
    {
        "content": "<p>like 16B SIMD seems like an obvious win compared to doing things 8B (or smaller) at a time, and it's widely supported, but beyond that it's not as obvious that it would consistently be a win</p>",
        "id": 421737515,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708029914
    },
    {
        "content": "<p>maybe so though!</p>",
        "id": 421737520,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1708029917
    },
    {
        "content": "<p>true</p>",
        "id": 421751362,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708035920
    },
    {
        "content": "<p>May be a case of 16B is low hanging fruit, 32B is probably good, 64B maybe is a not yet but maybe one day.</p>",
        "id": 421751673,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1708036082
    }
]