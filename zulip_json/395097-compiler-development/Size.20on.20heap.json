[
    {
        "content": "<p>For the change to put the size of a list (number of elements) on the heap, the size is only put on the heap for lists that actually have refcounted elements. So if it is a string (list u8), there will be no size on the heap. As such, I was thinking that this would be modeled directly and piped around through the bitcode.</p>\n<p>This is a base commit of just changing the zig bitcode to see what that would look like (obviously a lot more pipelining is needed in all of the backends). Does this approach seam reasonable? Is there a better way I should do this?</p>\n<p><a href=\"https://github.com/roc-lang/roc/commit/638cc7780c46b94239af90d431b1e84c806921d6\">https://github.com/roc-lang/roc/commit/638cc7780c46b94239af90d431b1e84c806921d6</a></p>\n<p>Note: the zig in this change is definitly not fully converted. I also need to go through and remove a bunch of recursive refcount changes that will no longer happen. Now, recursive increments should only happen on creating a new unique copy of a list and recursive decrements should only happen on deallocation. All other increments and decrements should only happen to the outer list non-recursively.</p>",
        "id": 407161704,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702271880
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281543\">@Folkert de Vries</span> I assume you are most likely to have input here. Though the input may just be that I am gonna have a <em>really</em> fun time updating every single location that can call the bitcode paths.</p>\n<p>On the rust side, this variable will be initialized as <code>interner.contains_refcounted(element_layout)</code></p>",
        "id": 407161866,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702272002
    },
    {
        "content": "<p>And for types like unions and strings that are allocated with these helpers but don't have an element type, it will just be set to false.</p>",
        "id": 407161947,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702272036
    },
    {
        "content": "<p>One extra piece that I am realizing that will be kinda inconvenient to pipeline through is specifically for list incref. If a list has refcounted elements and is incrementing from a refcount of 1 to 2, we need to save it's size to the heap. This means that we either need to pass all of this information to all incref functions, or we need to make a custom incref function for list and distinguish this in all cases (so like dispatching correctly when we have a struct that has a union in it that has a list of refcounted data in that).</p>",
        "id": 407166739,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702274683
    },
    {
        "content": "<p>Although may be best to overall reduce the footprint of all of these versions and just make a list specific version of incref and decref that is exposed to the backends. Then each backend has to code gen based on if something is a list or not and only for lists they would pass in whether or not an element is refcount. Probably will be easier to follow and a bit more performant than if these variables are pervasive to literally all recounting functions.</p>\n<p>.... Just trying to brainstorm what will end up being the nicest way to do this.</p>",
        "id": 407172781,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702277370
    },
    {
        "content": "<p>did I miss something? why do we want this?</p>",
        "id": 407186971,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1702282570
    },
    {
        "content": "<p>This is to fix the reverse list refcounting.</p>",
        "id": 407264234,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702308526
    },
    {
        "content": "<p>When list recount is normally incremented or decremented it will just be the main list from now on</p>",
        "id": 407264377,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702308562
    },
    {
        "content": "<p>Only on making a new unique copy of a list or fully deallocating a list with the recursive refcount need to happen.</p>",
        "id": 407264643,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702308629
    },
    {
        "content": "<p>Since a seamless slice does not know the size of the original list, it is unable to free all of the elements if it is the last reference to the list.</p>",
        "id": 407264909,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702308709
    },
    {
        "content": "<p>So we have to put the size on the heap to enable this feature.</p>",
        "id": 407265000,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702308727
    },
    {
        "content": "<p>When chatting with Richard about this, he suggested that to avoid adding the size before all strings and lists even ones where it isn't really needed, we can decided to added it or not and do this extra logic based on if the element is refcounted or not. If the element is not refcounted, then it never has recursive refocounts anyway.</p>",
        "id": 407265369,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702308832
    },
    {
        "content": "<p>Main goal is to fix perf bugs like this:</p>\n<p><span class=\"user-mention silent\" data-user-id=\"343810\">Brendan Hansknecht</span> <a href=\"#narrow/stream/231634-beginners/topic/Profiling.20an.20AoC.20app/near/406961712\">said</a>:</p>\n<blockquote>\n<p>Purple is refcounting. It is 98.6% of the program execution: <br>\n<a href=\"/user_uploads/22008/I1tRBIHi3RfmhPQ2GMDFdpwj/Screenshot-2023-12-09-at-10.30.06AM.png\">Screenshot-2023-12-09-at-10.30.06AM.png</a></p>\n</blockquote>",
        "id": 407266238,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702309092
    },
    {
        "content": "<p>ah, sure</p>",
        "id": 407514182,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1702398076
    },
    {
        "content": "<p>that makes sense</p>",
        "id": 407514235,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1702398100
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281543\">@Folkert de Vries</span>, One other question on this. If I pull all the list refcounting into it's own function. So Lists always call <code>roc_builtins.list.incref</code> or something like that, do you see any issue with building the dispatch? I assume that all of the generation for our refcounting functions will have all the information needed to be able to at compile time pick which version to call (generic refcount vs list refcount), correct?</p>",
        "id": 407812824,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702502699
    },
    {
        "content": "<p>we generate specific functions to inc/dec a list. you'll need to adjust those functions (and only those functions) I think?</p>",
        "id": 407817425,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1702504719
    },
    {
        "content": "<p>Ok</p>",
        "id": 407817548,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1702504780
    },
    {
        "content": "<p>I am starting to look at this a bit more and realizing that tons more list functions now need to take an element <code>incref</code> and element <code>decref</code> function.  Cause anything that might free a list (even a potentially empty one) now needs an element decref function. And anything that might make a new allocation of a list now needs an element incref function.</p>\n<p>So instead of having one main location for incref and decref, it is much more distributed. Just so many args to pass around then pipe through all calling functions. Not hard, just a lot of work and a good chance that I will mess something up and create some mem leaks or other issues.</p>",
        "id": 408982221,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703006196
    },
    {
        "content": "<p>yes (that is why this never happened). in valgrind we trust I suppose</p>",
        "id": 408982465,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1703006276
    },
    {
        "content": "<p>yeah, if this wasn't so important for performance, I definitely wouldn't want to take on the complexity.</p>\n<p>Like I guess we could try the borrowing idea first and see if this is still needed. With the borrowing idea, functions that just read would be saved from the horrid recursive refcounts. Functions that might modify hopefully would take a unique list anyway. So they would take ownership of the list and no refcount changes would be needed.</p>",
        "id": 408983062,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703006511
    },
    {
        "content": "<p>Borrowing would just be analysis of the mono ir. Starting at the leaf node functions and working back to the root. For any function that a list could be modified or return, we label it as owning. For all other functions, borrowing. Then for borrowing functions, we skip all the refcount inc and dec. Not sure how hard that analysis would be in practice, but seems like it would mostly be a matter of walking the ir and tracking variables.</p>",
        "id": 408983632,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703006731
    },
    {
        "content": "<p>I think the biggest concern for borrowing will be records. Cause we would probably check for borrowing of the record as a whole rather than for borrowing of each field in a record. Thus a function that changes one field in a record, but doesn't touch a refcounted list field would also need to increment the refcount of that list.</p>",
        "id": 408983987,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703006870
    },
    {
        "content": "<p>Just debating the effort, gain, and complexity trade off. Especially considering this is a big pain point hit by many many people working on AOC currently, so would be nice to fix them sooner (even if not a complete fix but more a workaround).</p>",
        "id": 408985800,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703007558
    },
    {
        "content": "<p>yeah my overall thoughts on this are:</p>\n<ol>\n<li>In general I'm very much in favor of trying out more aggressive borrowing strategies. I know there's a concern about potentially blowing up the number of specializations (and therefore binary size and compile times), but that seems like one of those things where we can't really know how big (or little) of a problem it is without actually trying it. It seems very hard to predict how often it would come up in real-world programs. Like maybe in practice it's totally fine because—much like how <code>let</code> inference has theoretically abysmal worst-case performance, in practice it just turns out people don't write programs in the way that would trigger the pathological case.</li>\n<li>Regarding borrowing of record fields, I assume that could be treated as a separate project, right? Like it wouldn't have to block trying out a borrowing design that didn't treat records differently (at least at first).</li>\n<li>The upside potential on borrowing inference seems clearly higher in the sense that there would presumably be a lot of refcounts eliminated across programs even in other scenarios than this one.</li>\n</ol>",
        "id": 408987443,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1703008212
    },
    {
        "content": "<blockquote>\n<ol start=\"2\">\n<li>Regarding borrowing of record fields, I assume that could be treated as a separate project, right? Like it wouldn't have to block trying out a borrowing design that didn't treat records differently (at least at first).</li>\n</ol>\n</blockquote>\n<p>100%</p>",
        "id": 408987604,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703008293
    },
    {
        "content": "<p>Do you think it is likely that borrow inference could remove the need for these other changes that deal with recursive refcounts? Or do you think we would likely need both?</p>",
        "id": 408987794,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703008372
    },
    {
        "content": "<p>personally I have no idea; others would have a better idea about that than I would <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span></p>",
        "id": 408988096,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1703008520
    },
    {
        "content": "<p>fair enough. I think it would fix all of the cases getting hit by the AOC currently.</p>",
        "id": 408988177,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703008554
    },
    {
        "content": "<p>So. I decided to do a manual MVC of borrowing. The borrowing is just hardcoded for <a href=\"https://github.com/lindskogen/advent-of-code-2023/blob/a0c49f6c6061f20619fcb05a8f855ac4bf6c05ce/day16/main.roc\">an example AOC app that recently hit big perf issues the other day</a>.</p>\n<p>Changes here: <a href=\"https://github.com/roc-lang/roc/compare/main...borrowing-hacks\">https://github.com/roc-lang/roc/compare/main...borrowing-hacks</a></p>\n<p>At least for this arbitrary app, this 100% fixes the perf issue. Comparing the borrowing hack branch to a manual workaround of using <code>U8</code>s instead of strings:</p>\n<div class=\"codehilite\"><pre><span></span><code>Benchmark 1: /tmp/aoc-borrowing\n  Time (mean ± σ):     259.1 ms ±   1.8 ms    [User: 255.9 ms, System: 1.3 ms]\n  Range (min … max):   256.8 ms … 263.0 ms    11 runs\n\nBenchmark 2: /tmp/aoc-workaround\n  Time (mean ± σ):     253.7 ms ±   4.5 ms    [User: 249.8 ms, System: 1.5 ms]\n  Range (min … max):   247.7 ms … 262.5 ms    11 runs\n\nSummary\n  &#39;/tmp/aoc-workaround&#39; ran\n    1.02 ± 0.02 times faster than &#39;/tmp/aoc-borrowing&#39;\n</code></pre></div>\n<p>Without the fix, this app takes ~70 seconds on my M1 mac. So borrowing is definitely very promising. Still not sure how often borrowing will fail to help. I guess the cases where we will still need size on heap will be cases where the same value is passed to multiple different functions that each might modify it. So none of those function can borrow it and we need to increment and decrements refcounts around each function. Of course, if the function modifies, the refcounting was needed anyway and is not cost. So it would only matter if the functions are unlikely to modify the value. So long term we may still want both, but maybe there is another better optimization for situations like those.</p>",
        "id": 409028791,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703026164
    },
    {
        "content": "<p>wow, 70 seconds to 250ms is...quite a difference <span aria-label=\"laughing\" class=\"emoji emoji-1f606\" role=\"img\" title=\"laughing\">:laughing:</span></p>",
        "id": 409029202,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1703026364
    },
    {
        "content": "<p>how does the borrowing inference algorithm work here?</p>",
        "id": 409029237,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1703026382
    },
    {
        "content": "<p>incrementing and decrementing <code>12100</code> refcounts in a hot loop is slow....who would have guessed.</p>",
        "id": 409029401,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703026456
    },
    {
        "content": "<p>In this case there is no inference algorithm, I just manually labeled some functions and joinpoints.</p>",
        "id": 409030263,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703026914
    },
    {
        "content": "<p>Then updated the refcount insertion algorithm to obey those new annotations.</p>",
        "id": 409030423,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703026951
    },
    {
        "content": "<p>The manual labeling is at the bottom of the code changes.</p>",
        "id": 409030677,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703027046
    },
    {
        "content": "<p>gotcha... <span class=\"user-mention\" data-user-id=\"281543\">@Folkert de Vries</span> <span class=\"user-mention\" data-user-id=\"454654\">@Ayaz Hafiz</span> I know you've both talked about thoughts around borrow inference in the past - what do you think of the idea of trying it out and seeing if there's an explosion of specializations in practice vs not? (Maybe there's some way we could answer that question without implementing the whole thing?)</p>",
        "id": 409032124,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1703027894
    },
    {
        "content": "<p>Why would it explode specialization?</p>",
        "id": 409032219,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703027980
    },
    {
        "content": "<p>In my mind, each function has exactly one borrowing signature based on its implementation.</p>",
        "id": 409032261,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703028004
    },
    {
        "content": "<p>Don't we already have a borrow inference algorithm?</p>",
        "id": 409065297,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1703038849
    },
    {
        "content": "<p>At least Morphic definitely specializes based on borrows</p>",
        "id": 409065345,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1703038864
    },
    {
        "content": "<p>The specialization is because you can you specialize a function to take its arguments as owned, and one to take arguments as borrowed (so potentially 2^N in the number of arguments)</p>",
        "id": 409065480,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1703038896
    },
    {
        "content": "<p>Sure, but if you can take as borrowed, why would you ever take as owned?</p>",
        "id": 409070991,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703040494
    },
    {
        "content": "<p>Because it could avoid a ref count if the borrowed version needs a ref<br>\ncount in some branch</p>",
        "id": 409073872,
        "sender_full_name": "Ayaz Hafiz",
        "timestamp": 1703041336
    },
    {
        "content": "<p>Hmm....I guess I need to see an example. Cause in my mind if a function borrows, all functions it calls must also borrow, so it just fully avoids refocounts.</p>\n<p>With branches we have:</p>\n<div class=\"codehilite\"><pre><span></span><code># this is called from a function that owns a.\n# it has to own a cause it calls another owning function\nif ... then\n   owningFn a\nelse\n    # references a to generate some new value\n    borrowingFn a\n</code></pre></div>\n<p>The first one has to be owning cause it mutates. The second one we have the choice, of borrowing or owning. That said, it is always fine to borrow (sometime minor delay in freeing memory) and depending on the exact use borrowing will be better.</p>\n<p>The second branch is one of these two:</p>\n<div class=\"codehilite\"><pre><span></span><code># borrow\nelse\n    borrowingFn a\n    dec a\n\n# own\nelse\n    # will Dec at some point inside of the function.\n    borrowingForceOwningFn a\n</code></pre></div>\n<p>Those two are essentially the same, both have one decref, but owning frees memory potentially earlier. That said, it is the only case where borrowing is a disadvantage. If the borrowing function returns a value and then we use a, it will be strictly better for the function to borrow. Would look something like this:</p>\n<div class=\"codehilite\"><pre><span></span><code># borrow\nelse\n    someVal = borrowingFn a\n    # use some val and a\n\n# own\nelse\n    inc a\n    # will Dec at some point inside of the function.\n    someVal = borrowingForceOwningFn a\n    # use some val and a\n</code></pre></div>\n<p>Am I missing something. Besides the chance of a delayed free, I see no disadvantage of always borrowing when possible.</p>",
        "id": 409079620,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703043673
    },
    {
        "content": "<p>yeah I think with the simple heuristic (any mutation opportunity -&gt; owned, otherwise borrowed) you don't get excess specializations. There is just the risk of keeping allocations around for much longer than needed if something gets borrowed but is not actually used in practice</p>",
        "id": 409138158,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1703066984
    },
    {
        "content": "<p>maybe there should be some mechanism to force ownership regardless, a fake mutation</p>",
        "id": 409138622,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1703067075
    },
    {
        "content": "<p>also, the \"can it be mutated\" value is not that easy to determine precisely for tag unions: we determine reuse based on drops, but drops are of course inserted differently for owned/borrowed values</p>",
        "id": 409138921,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1703067134
    },
    {
        "content": "<p>you can statically know that there are no reuse opportunities at all in a function, but once there are, you must pass the value as owned even if in practice the value is never updated because the structure of the function does not allow it</p>",
        "id": 409139268,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1703067209
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281543\">Folkert de Vries</span> <a href=\"#narrow/stream/395097-compiler-development/topic/Size.20on.20heap/near/409138158\">said</a>:</p>\n<blockquote>\n<p>yeah I think with the simple heuristic (any mutation opportunity -&gt; owned, otherwise borrowed) you don't get excess specializations. There is just the risk of keeping allocations around for much longer than needed if something gets borrowed but is not actually used in practice</p>\n</blockquote>\n<p>I could be wrong, but I suspect this would be fine in Roc's case because things are always given to the host as owned, so if they did go longer than necessary without being deallocated, it would only be until the next io operation</p>",
        "id": 409221678,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1703090083
    },
    {
        "content": "<p>I think the heuristic would be in practices:</p>\n<p>potentially passed to an owning function or returned from the function -&gt; owned<br>\notherwise -&gt; borrow</p>\n<p>Also, borrowing is the default in rust for cases like this, and it tends not to be a memory probably. So I bet it would be fine in Roc.</p>",
        "id": 409226707,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703091732
    },
    {
        "content": "<p>I know this is jumping back some, but I decided to attempt to update the entire bitcode for size on heap (just to see what it would look like in practice). I'm sure it has bugs, but I think this is the full bitcode updated (wish we had more zig tests cause they can all catch memory issues). Well, also need to remove our eager element decrementing in various functions.<br>\n<a href=\"https://github.com/roc-lang/roc/compare/main...list-size-on-heap\">https://github.com/roc-lang/roc/compare/main...list-size-on-heap</a></p>\n<p>Changes the api for essentially every list function and the utils refcounting functions. So that would need to be wired through to every calling location in the compiler. Would be a matter of generating and passing more element increment and decrement functions to these various locations. Would also require ensuring all list refcounting goes through the new zig exposed list refcounting functions.</p>\n<p>So I think it would be a slog with a lot of bugs to work through once wired up, but definitely doable. Should be a lot of the same at least with a similar pattern of changes for all of the functions.</p>\n<p>I still think the borrowing changes will be a fundamental need, but as I was manually testing borrowing and thinking about edge cases, I get more and more the feeling that both of these changes will be needed.</p>",
        "id": 409229933,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703092747
    },
    {
        "content": "<p>I buy that! Does anyone think we shouldn't at least <em>try</em> both and see what we run into in practice? (Especially <span class=\"user-mention\" data-user-id=\"281543\">@Folkert de Vries</span> or <span class=\"user-mention\" data-user-id=\"454654\">@Ayaz Hafiz</span> <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span>)</p>",
        "id": 409233688,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1703094240
    },
    {
        "content": "<p>yes that sounds like a good idea</p>",
        "id": 409233920,
        "sender_full_name": "Folkert de Vries",
        "timestamp": 1703094344
    },
    {
        "content": "<blockquote>\n<p>(wish we had more zig tests cause they can all catch memory issues)</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"343810\">@Brendan Hansknecht</span> I just remembered you saying this :p could you make an issue for it? This definitely sounds like something we should do.</p>",
        "id": 409596990,
        "sender_full_name": "Anton",
        "timestamp": 1703257417
    },
    {
        "content": "<p><a href=\"https://github.com/roc-lang/roc/issues/6301\">#6301</a></p>",
        "id": 409600962,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1703259044
    }
]