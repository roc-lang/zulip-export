[
    {
        "content": "<p>Hi everyone,</p>\n<p>I’ve been following the development of the language over the past few years and recently noticed in some comments that a few of you are using AI tools (like Claude) during the development process. I’d love to hear your thoughts and experiences on this.</p>\n<p>What do you see as the main advantages, and what limitations or risks have you encountered (design choices, consistency, long-term maintainability, etc.)?</p>\n<p>I’m genuinely curious to learn from your perspectives. Thanks in advance for sharing — and Merry Christmas <span aria-label=\"holiday tree\" class=\"emoji emoji-1f384\" role=\"img\" title=\"holiday tree\">:holiday_tree:</span>!</p>\n<p>(Feel free to move this discussion out of “compiler development” if this isn’t the right place.)</p>",
        "id": 565302461,
        "sender_full_name": "Ghislain",
        "timestamp": 1766596223
    },
    {
        "content": "<p>since Sonnet 4.5 came out, and even more so with Opus 4.5, my workflow has pretty much changed to \"write English, review Zig code\"</p>",
        "id": 565304091,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766597480
    },
    {
        "content": "<p>I'm a lot faster that way than before (despite 30 years of handwriting code!) plus it's much more conducive to making progress in tiny chunks of time</p>",
        "id": 565304152,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766597529
    },
    {
        "content": "<p>like right now I'm on the way to the gym and I have 5ish agents running on my laptop on different branches, and I can review what they did when I get back</p>",
        "id": 565304202,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766597569
    },
    {
        "content": "<p>I really struggled with lack of continuous hours prior to this workflow existing</p>",
        "id": 565304226,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766597601
    },
    {
        "content": "<p>since having a kid, since Roc is not my day job, I just would not have \"work on Roc for several hours in a row\" except for maybe a handful of times per year</p>",
        "id": 565304264,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766597633
    },
    {
        "content": "<p>that's not really a problem anymore because I don't need to load as many code-level details into my brain to make progress now</p>",
        "id": 565304320,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766597671
    },
    {
        "content": "<p>so I can't speak for others, but for me it's become totally transformative in a really positive way! <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 565304439,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766597786
    },
    {
        "content": "<p>Thanks for sharing!</p>\n<p>I’m curious: do you find that the AI is able to maintain a sufficiently high-level, global understanding of the project on its own, or do you usually have to guide it quite explicitly (e.g. which parts of the codebase to touch, which files to modify, architectural constraints, etc.)?</p>\n<p>In other words, how much of the “big picture” can you delegate to the AI today, and where do you still need to step in?</p>",
        "id": 565304660,
        "sender_full_name": "Ghislain",
        "timestamp": 1766597993
    },
    {
        "content": "<p>none of the current tools are good at big picture in my experience</p>",
        "id": 565304873,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766598218
    },
    {
        "content": "<p>I can't just be like \"hey Claude, draw the owl\" - that will end in disaster</p>",
        "id": 565304922,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766598276
    },
    {
        "content": "<p>however for small bugfixes I actually can be like \"hey Claude, here's a boilerplate script you can follow to reproduce the bug in a test, then track down the root cause, and apply a fix and then push a draft PR for me to review\"</p>",
        "id": 565305001,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766598354
    },
    {
        "content": "<p>sometimes that's enough bc there's no \"big picture understanding\" necessary - just surrounding context clues like the bug report and Claude being able to poke around the code case is enough to figure out how to repro it and then find a fix (again, for small bugs!)</p>",
        "id": 565305080,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766598441
    },
    {
        "content": "<p>so usually the diffs for these PRs are very small and easy to review. I'd guess more than 50% don't need changes, but a common failure mode is \"Claude made the test pass using a bandaid fix that doesn't actually address the root cause\"</p>",
        "id": 565305150,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766598516
    },
    {
        "content": "<p>and when I spot that in review it's often enough for me to go back and be like \"hey this looks like a bandaid, try digging deeper to find the actual root cause\"</p>",
        "id": 565305224,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766598569
    },
    {
        "content": "<p>for bigger projects they need to be chopped up into smaller pieces, can't just be like \"draw the owl of this whole feature\" and there is usually way more iterating back and forth on my reviewing it, finding something unacceptable, describing the necessary revisions, etc</p>",
        "id": 565305338,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766598687
    },
    {
        "content": "<p>but again for me personally it's huge to be able to have each of those interactions be on and arbitrary schedule. I don't need to sit down and spend 10 minutes reorienting myself in the code to be able to make progress like I do when writing code by hand</p>",
        "id": 565305445,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766598778
    },
    {
        "content": "<p>this thread made me try opus and damn its a nice model lol</p>",
        "id": 565310014,
        "sender_full_name": "nandi",
        "timestamp": 1766602532
    },
    {
        "content": "<p>I also find it really valuable, I can contribute while working around other meetings and different things. I tend to spend a fair bit of time in \"plan mode\" until I'm convinced Claude has identified a good root cause and understands the issue, or the scope of the next step isn't too large.</p>",
        "id": 565312776,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1766605069
    },
    {
        "content": "<p>Ai tools take tons of context to work well currently, but they can do a lot.</p>",
        "id": 565328350,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766622317
    },
    {
        "content": "<p>One of my coworkers who is an extreme ai power users describes current AI as \"a neurodivergent intern who is exceptionally passionate and types really really fast\". I think that is a relatively fair way to describe it today. If you can give enough details, guidance, and measurable tasks, it can do great things. But it also can generate gigantic messes and releasing the enthusiasm without bounds is a catastrophic mistake.</p>",
        "id": 565328450,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766622471
    },
    {
        "content": "<p>I find for mych of my work, it requires very detailed prompting. Lots of asking targeted questions to get the AI to think about the problem in the right way and a lot of planning mode with thinking on and the \"ultrathink\" keyword. (This is for Claude opus 4.5)</p>",
        "id": 565328507,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766622551
    },
    {
        "content": "<p>It works rather well, but still constantly falls short especially if I am not careful enough</p>",
        "id": 565328518,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766622570
    },
    {
        "content": "<p>Note, this is from my generally work on not much roc work</p>",
        "id": 565328524,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766622580
    },
    {
        "content": "<p>Thank you for your answers, I find this workflow really impressive.</p>\n<p>One concern I still have, though, is how well this approach holds up for building a programming language, where a lot of value comes from deep optimization, careful design trade-offs, and long-term refinement.</p>\n<p>Do you feel the AI can meaningfully contribute at that level, or does it mostly help with implementation once those decisions are already very well defined?</p>",
        "id": 565330273,
        "sender_full_name": "Ghislain",
        "timestamp": 1766625428
    },
    {
        "content": "<p>I think the work that my coworker does (infrastructure and core abstractions for high performance and maintable GPU kernels) qualifies as requiring \"deep optimization, careful design trade-offs, and long-term refinement\".</p>",
        "id": 565330363,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766625622
    },
    {
        "content": "<p>And I think it can...but you have to be way more careful of it currently.</p>\n<p>A huge part of it is not giving basic answers to the ai, but instead asking it questions that cause it to think through the design. Then when it gets to implementation, it has that design discussion as reference.</p>",
        "id": 565330427,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766625756
    },
    {
        "content": "<p>That said, I currently find  it better to explore design separate from code. Use the ai to educate myself to inform better design rather than let it create the design.</p>",
        "id": 565330463,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766625828
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"343810\">Brendan Hansknecht</span> <a href=\"#narrow/channel/395097-compiler-development/topic/Thoughts.20on.20Using.20AI.20in.20the.20Language.20Development.20Process.3F/near/565330427\">said</a>:</p>\n<blockquote>\n<p>And I think it can...but you have to be way more careful of it currently.</p>\n<p>A huge part of it is not giving basic answers to the ai, but instead asking it questions that cause it to think through the design. Then when it gets to implementation, it has that design discussion as reference.</p>\n</blockquote>\n<p>That part</p>",
        "id": 565330478,
        "sender_full_name": "nandi",
        "timestamp": 1766625856
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"343810\">Brendan Hansknecht</span> <a href=\"#narrow/channel/395097-compiler-development/topic/Thoughts.20on.20Using.20AI.20in.20the.20Language.20Development.20Process.3F/near/565330463\">said</a>:</p>\n<blockquote>\n<p>I currently find  it better to explore design separate from code. Use the ai to educate myself to inform better design rather than let it create the design.</p>\n</blockquote>\n<p>yeah, same here!</p>",
        "id": 565331913,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766628014
    },
    {
        "content": "<p><a href=\"/user_uploads/22008/VCFT3lTl6CuwYpj56Hp5kl5B/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/22008/VCFT3lTl6CuwYpj56Hp5kl5B/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1024x1024\" src=\"/user_uploads/thumbnail/22008/VCFT3lTl6CuwYpj56Hp5kl5B/image.png/840x560.webp\"></a></div>",
        "id": 565464392,
        "sender_full_name": "nandi",
        "timestamp": 1766775296
    },
    {
        "content": "<p>Yes, relevant context <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 565464420,
        "sender_full_name": "Anton",
        "timestamp": 1766775327
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"528453\">Ghislain</span> <a href=\"#narrow/channel/395097-compiler-development/topic/Thoughts.20on.20Using.20AI.20in.20the.20Language.20Development.20Process.3F/near/565330273\">said</a>:</p>\n<blockquote>\n<p>One concern I still have, though, is how well this approach holds up for building a programming language, where a lot of value comes from deep optimization, careful design trade-offs, and long-term refinement.</p>\n<p>Do you feel the AI can meaningfully contribute at that level, or does it mostly help with implementation once those decisions are already very well defined?</p>\n</blockquote>\n<p>so far I think the only way LLMs have contributed to Roc's design is in researching what other languages do - e.g. it's way faster now to say \"hey <a href=\"https://aistudio.google.com/prompts/new_chat\">Gemini</a> [which is the model I usually use for research] how do various different programming languages do _____?\" than it used to be to try to find exactly the right part of documentation before, especially if I don't know what I'm searching for - e.g. one of my searches was \"what names do different languages use for flat_map?\" and if I do like \"what does [specific language] call flat_map?\" then if the language uses a different name, I had to hope someone asked a StackOverflow question like that or else I'd be running different searches guessing different names <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 565473967,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766786512
    },
    {
        "content": "<p>but at least in Roc's case I haven't done any like \"hey [model] help me solve this design problem\" stuff - it's really mostly been for research, debugging, or writing/editing code</p>",
        "id": 565474012,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766786562
    },
    {
        "content": "<p>On a more philosophical note — and as a relatively younger developer — this is something I find myself thinking about more and more as AI plays such a large role in implementation and even design.</p>",
        "id": 565475169,
        "sender_full_name": "Ghislain",
        "timestamp": 1766788319
    },
    {
        "content": "<p>I’ll admit there’s also a bit of personal tension for me: seeing AI not only write code much faster, but now also <em>reason and design</em> at such speed can feel slightly discouraging, especially when my own motivation has always been to deeply understand things in order to do them as well as possible.</p>",
        "id": 565475178,
        "sender_full_name": "Ghislain",
        "timestamp": 1766788335
    },
    {
        "content": "<p>How do you still find personal meaning or interest in the project itself — especially a programming language, in a context where we may be expected to use them less and less — and where does that meaning come from today?</p>",
        "id": 565475181,
        "sender_full_name": "Ghislain",
        "timestamp": 1766788346
    },
    {
        "content": "<p>I ask myself this question a lot. like i can potentially see a future where we just write everything in assembly via agent</p>",
        "id": 565475296,
        "sender_full_name": "nandi",
        "timestamp": 1766788500
    },
    {
        "content": "<p>I guess writing in a higher-level language like C/Zig would already be sufficient, given the level of optimizations modern compilers are able to perform (thank you Advent of Compiler <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span>).</p>",
        "id": 565475509,
        "sender_full_name": "Ghislain",
        "timestamp": 1766788807
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281383\">Richard Feldman</span> <a href=\"#narrow/channel/395097-compiler-development/topic/Thoughts.20on.20Using.20AI.20in.20the.20Language.20Development.20Process.3F/near/565473967\">said</a>:</p>\n<blockquote>\n<p>e.g. it's way faster now to say \"hey <a href=\"https://aistudio.google.com/prompts/new_chat\">Gemini</a> [which is the model I usually use for research] how do various different programming languages do _____?\"</p>\n</blockquote>\n<p>I'm curious what you use Gemini for, since from context, it looks like you use claude for code. Is gemini better for you regarding research?</p>",
        "id": 565475551,
        "sender_full_name": "nandi",
        "timestamp": 1766788880
    },
    {
        "content": "<p>at least right at this moment it's force of habit. There was some point where Gemini 2.5 Pro was giving me better answers than Claude 4 was and I haven't done a revised comparison since then <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 565476073,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766789676
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"528453\">Ghislain</span> <a href=\"#narrow/channel/395097-compiler-development/topic/Thoughts.20on.20Using.20AI.20in.20the.20Language.20Development.20Process.3F/near/565475181\">said</a>:</p>\n<blockquote>\n<p>How do you still find personal meaning or interest in the project itself — especially a programming language, in a context where we may be expected to use them less and less — and where does that meaning come from today?</p>\n</blockquote>\n<p>It honestly never occurred to me to think about it in these terms. </p>\n<p>Like I use Rust at work and Zig on Roc, I use the same models on both, and the languages feel very noticeably different. I assume the same would be true of like Go or TypeScript too, so I don't see why Roc would be any different in that regard! <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 565476359,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766789986
    },
    {
        "content": "<p>like I'm still spending a lot of time reading and revising code, and build times are a major contribution to how long it takes llms to get to a point where code is reviewable.</p>",
        "id": 565476595,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1766790117
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"528453\">Ghislain</span> <a href=\"#narrow/channel/395097-compiler-development/topic/Thoughts.20on.20Using.20AI.20in.20the.20Language.20Development.20Process.3F/near/565475178\">said</a>:</p>\n<blockquote>\n<p>I’ll admit there’s also a bit of personal tension for me: seeing AI not only write code much faster, but now also <em>reason and design</em> at such speed can feel slightly discouraging, especially when my own motivation has always been to deeply understand things in order to do them as well as possible.</p>\n</blockquote>\n<p>I think this is still where the most value is. AI may be fast but understanding the depth to enable it to build robust and extensionable solutions is an important skill. Also for many areas of significant depth AI falls quite flat. So being someone who wants to dive deep and really grok things, you are in the best place to take advantage of AI.</p>",
        "id": 565494070,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766818444
    },
    {
        "content": "<p>I think the people who are getting hurt the most by AI right now are the people who are outsourcing too much to AI. As a result, they are no longer learning and growing. Instead they become stagnant and dependent. People who use AI to learn and deal with only a subset of tasks are able to focus on the most important work, grow, and generally accelerate their work.</p>",
        "id": 565494128,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1766818563
    },
    {
        "content": "<blockquote>\n<p>People ... are able to focus on the most important work, grow, and generally accelerate their work.</p>\n</blockquote>\n<p>I agree with this sentiment.</p>",
        "id": 565502375,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1766830421
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"528453\">Ghislain</span> <a href=\"#narrow/channel/395097-compiler-development/topic/Thoughts.20on.20Using.20AI.20in.20the.20Language.20Development.20Process.3F/near/565475181\">said</a>:</p>\n<blockquote>\n<p>How do you still find personal meaning or interest in the project itself — especially a programming language, in a context where we may be expected to use them less and less — and where does that meaning come from today?</p>\n</blockquote>\n<p>I think there is still demand for a programming language that:</p>\n<ul>\n<li>builds fast</li>\n<li>tests fast: because it will not re-run tests whose behavior could not have changed</li>\n<li>can easily work with access permissions</li>\n<li>is easy to read by humans</li>\n<li>encourages handling of a wide range of errors</li>\n<li>is less likely to experience runtime problems because of static type checking</li>\n</ul>\n<p>It's actually an exciting opportunity to be able to make a programming language for this new age because we can design it with the capabilities of modern LLMs in mind. Making big changes like that seems a lot harder for established programming languages.</p>",
        "id": 565646255,
        "sender_full_name": "Anton",
        "timestamp": 1767004084
    },
    {
        "content": "<p>yeah another way to think about it: if language doesn't matter anymore, what's the one language all AI-programming enthusiasts have converged on using for all greenfield programming tasks?</p>",
        "id": 565911550,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767197575
    },
    {
        "content": "<p>(answer: whichever one they feel happiest using or which their job demands, just like always)</p>",
        "id": 565911604,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767197615
    },
    {
        "content": "<p>so I don't think the tradeoffs about languages have changed at a fundamental level, it's more that some tradeoffs matter more than other</p>",
        "id": 565911652,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767197649
    },
    {
        "content": "<p>for example, it's wild to me that about a year ago we were discussing how static dispatch enabling <code>.</code> autocomplete in IDEs was a big selling point, and today I do manual editing so infrequently I basically value that selling point at zero <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 565911754,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767197720
    },
    {
        "content": "<p>and it feels like the incentives around automated tests have changed a lot when doing a ton with agents; the tests are way cheaper to write, and have added value because they not only catch regressions, they give agents a feedback mechanism to self-correct without programmer review.</p>",
        "id": 565911989,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767197884
    },
    {
        "content": "<p>so in that world, like Anton noted, I think the \"tests can be auto-skipped when they're all pure functions and the code didn't change\" is a way bigger deal, because bigger test suites (currently) unavoidably slow the agents down, and yet are important for feedback loop reasons.</p>",
        "id": 565912125,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767197969
    },
    {
        "content": "<p>another example: the \"what color is your function?\" tradeoff of effectfulness needing to propagate all the way through a call chain - used to be a big downside because you'd need to do that propagation yourself. Now it's trivial; I'll just notice in the review that the agent did it.</p>",
        "id": 565912274,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767198077
    },
    {
        "content": "<p>and the upside of names ending in <code>!</code> making it more obvious where effects are happening is more valuable than before, because I'm spending proportionately more of my time reading diffs compared to before</p>",
        "id": 565912397,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767198163
    },
    {
        "content": "<p>An interesting benchmark for <strong>programming languages</strong> would be: How fast can Opus 4.5 build a specific set of diverse applications with language X, what's the perf of the application and how many tests does the app pass of a very thorough <strong>hidden</strong> test suite.</p>",
        "id": 565968720,
        "sender_full_name": "Anton",
        "timestamp": 1767263861
    },
    {
        "content": "<p>Other interesting metrics: total number of errors and warnings encountered, number of times the application was run during development, time spent debugging</p>",
        "id": 565968973,
        "sender_full_name": "Anton",
        "timestamp": 1767264193
    },
    {
        "content": "<p>Would be interesting if you added extra constraints to see how it copes. For example, it might start with naive python. You should also be able to ask it to optimize the code to reach a certain performance... Might then use numpy in python for example</p>",
        "id": 565986896,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1767283506
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"343810\">Brendan Hansknecht</span> <a href=\"#narrow/channel/395097-compiler-development/topic/Thoughts.20on.20Using.20AI.20in.20the.20Language.20Development.20Process.3F/near/565986896\">said</a>:</p>\n<blockquote>\n<p>Might then use numpy in python for example</p>\n</blockquote>\n<p>yesterday I learned numPy is implemented in fortran</p>",
        "id": 565992576,
        "sender_full_name": "nandi",
        "timestamp": 1767291114
    },
    {
        "content": "<p>Hmm, only a tiny bit seems to be implemented in Fortran based on the \"Languages\" breakdown on <a href=\"https://github.com/numpy/numpy\">https://github.com/numpy/numpy</a></p>",
        "id": 565992666,
        "sender_full_name": "Anton",
        "timestamp": 1767291249
    },
    {
        "content": "<p>I think I learned it from an LLM so yeah that checks out lol</p>",
        "id": 565992758,
        "sender_full_name": "nandi",
        "timestamp": 1767291385
    },
    {
        "content": "<p>Fortran can optimize better than c for this kind of code due to assuming that pointers won't alias by default.</p>\n<p>Not sure how relevant it is in the modern day, but it was part of the reason for its early growth. Was better for high performance scientific code and would run faster.</p>",
        "id": 565994078,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1767292932
    },
    {
        "content": "<p>But that would be part of my guess for the origin here</p>",
        "id": 565994082,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1767292942
    },
    {
        "content": "<p>If you click on Fortran in that repo to see the files and scroll through them, they are all just documentation and test data for a thing called \"f2py\", which seems to be a tool for integrating user-defined Fortran code into Python apps. But it doesn't seem like numpy itself actually implements any algorithms in Fortran.</p>",
        "id": 566174615,
        "sender_full_name": "Brian Carroll",
        "timestamp": 1767472483
    },
    {
        "content": "<p>What do you think about <a href=\"https://simonwillison.net/2025/Dec/31/the-year-in-llms/#the-year-of-conformance-suites\">Simon’s take</a> ?</p>\n<blockquote>\n<p>If you’re introducing a new protocol or even a new programming language to the world in 2026 I strongly recommend including a language-agnostic conformance suite as part of your project.</p>\n</blockquote>",
        "id": 566186560,
        "sender_full_name": "Ghislain",
        "timestamp": 1767486388
    },
    {
        "content": "<p>I don't understand what he's saying there <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 566188069,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767488318
    },
    {
        "content": "<p>maybe he blogged about it in more detail somewhere else?</p>",
        "id": 566188081,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767488328
    },
    {
        "content": "<p>Isn't that basically what we are developing in our suite of snapshot tests? we are building up a collection of examples which demonstrate the syntax and semantics</p>",
        "id": 566188722,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1767489088
    },
    {
        "content": "<p>that's certainly one thing he might mean <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 566190973,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1767491926
    },
    {
        "content": "<p>I think it is the snapshot tests but also taken a level further. You need to make sure not only that you generate correct parsing/errors and what not, but also that you execute correctly. That is fundamental for programming language correctness. (I don't think snapshot tests run the interpretter, but maybe they do)</p>\n<p>I think the theory being proposed here is that eventually I should be able to write a language implementation in python that covers all the errors and full intepretter setup. Build a conformance test suite that tests everything. Then ask AI to build me a fully working interpretter in Zig by implementing the tests one by one with a little extra guidance. After that I should theoretically even be able to ask for an llvm backend and just need to ask the ai to have it generate the exact same output as the intepretter when used.</p>",
        "id": 566194215,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1767497314
    },
    {
        "content": "<blockquote>\n<p>I don't think snapshot tests run the interpretter</p>\n</blockquote>\n<p>Yeah they do in the \"REPL\" snapshots <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 566217316,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1767527206
    },
    {
        "content": "<blockquote>\n<p>theoretically even be able to ask for an llvm backend and just need to ask the ai to have it generate the exact same output as the intepretter when used.</p>\n</blockquote>\n<p>I think this is the approach (or something similar) we're currently using building out the LLVM backend for Roc. </p>\n<p>I am not sure how complete the LLVM backend is already, but from skim reading some of the PR's it looks like Richard has been using our tests with both the interpreter and LLVM backend and confirming they evaluate to the same thing -- and this being of the key methods of feedback for Claude and friends to work with as a source of truth.</p>",
        "id": 566218167,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1767528124
    },
    {
        "content": "<p>See <a href=\"https://github.com/roc-lang/roc/pull/8810\">https://github.com/roc-lang/roc/pull/8810</a></p>",
        "id": 566218340,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1767528286
    },
    {
        "content": "<p>Ah yeah, then I think we have the core of what they talk about here.</p>",
        "id": 566250161,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1767560677
    },
    {
        "content": "<p>I'm curious which Claude plan are you using when working on the Roc compiler? I'm new at AI coding, just tried Opus 4.5 today and found it promising. Unfortunately it was only able to write a few hundreds lines of code on an extremely well defined task (well documented, there's another implementation already in the same project etc.) before melting my pro plan quota.. It looks like the pro plan can maybe generate one PR/day at this rate. (or maybe I'm using it wrong?)</p>",
        "id": 567830047,
        "sender_full_name": "osa1",
        "timestamp": 1768327635
    },
    {
        "content": "<p>Yeah, it depends what you are doing but with opus 4.5 you will quickly go through your pro limit. I am using the lowest tier max plan.</p>",
        "id": 567831230,
        "sender_full_name": "Anton",
        "timestamp": 1768328042
    },
    {
        "content": "<p>I use the $200/month Claude Max plan and I have to ration my weekly usage or else I run out way before the week is over. I've thought about getting a second $200/month plan but decided instead to just do other things while I wait for the weekly limit to reset.</p>",
        "id": 567832855,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1768328649
    },
    {
        "content": "<p>and all I use on it is Opus 4.5 via Claude Code</p>",
        "id": 567832958,
        "sender_full_name": "Richard Feldman",
        "timestamp": 1768328682
    },
    {
        "content": "<p>Thanks. I guess I'm not doing anything too too stupid <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 567837527,
        "sender_full_name": "osa1",
        "timestamp": 1768330332
    },
    {
        "content": "<p>You have a few contributors using Claude but no CLAUDE.md.. Is there a reason for this? Wouldn't that file help with Claude discovering certain things, like how to run tests? Or are you reusing the same thread with Claude for multiple PRs?</p>",
        "id": 567863324,
        "sender_full_name": "osa1",
        "timestamp": 1768340512
    },
    {
        "content": "<p>I'm relatively new to this stuff, but I think the AGENTS.md / .rules file is basically a no-vendor-lock-in version of CLAUDE.md</p>",
        "id": 567871525,
        "sender_full_name": "Dan G Knutson",
        "timestamp": 1768343953
    },
    {
        "content": "<p>it does seem to help to have a working .md file for the plan for a specific high-level feature, though (in addition to whatever internal plan file claude code makes)</p>",
        "id": 567871666,
        "sender_full_name": "Dan G Knutson",
        "timestamp": 1768344025
    },
    {
        "content": "<p>Yeah we have <a href=\"https://github.com/roc-lang/roc/blob/main/.rules\">https://github.com/roc-lang/roc/blob/main/.rules</a> which effectively does the same thing</p>",
        "id": 567876890,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1768346878
    },
    {
        "content": "<p>We try to catch the really common mistakes the LLM's make without this guidance, but not too much more</p>",
        "id": 567877246,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1768347028
    },
    {
        "content": "<p>I find I can be quite productive on Claude's Pro subscription... but I usually time out the 5hr limit in 45mins or so. I've upgraded to the lower Max tier which gives me the ability to run an agent pretty much all day without breaks.</p>",
        "id": 567877416,
        "sender_full_name": "Luke Boswell",
        "timestamp": 1768347140
    },
    {
        "content": "<p>I've heard a lot of talk online recently that they really reduced the usage people get in the past few months. I signed up to the pro plan and was kind of shocked how quickly I ran out. <br>\nParticularly when my github copilot plan which is cheaper (well actually free, thanks roc <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span>) gives me 100 prompts regardless of token usage.</p>\n<p>I think github copilot makes or whatever they call it is basically the best deal around. It gives you like 500 prompts. Opus costs 3 prompts, but all other decent models are just one. </p>\n<p>Github does give you only half the context limit though. I've also heard the Google sntigravity plan is also now a better deal than claude pro.<br>\n(You can use all these providers inside opencode, and maybe zed or zed via ACP)</p>\n<p>Lastly I actually tried exactly this, getting a totally fine coded attempt at adding compeltion to the roc language server...... It didn't go well. <br>\nProbably didn't give it enough planning stages or whatever, but the result was just really cooked.<br>\nIt did manage to have completion of top level locals and builtins though.  But it was just kind of shitty and broke all the time.</p>\n<p>I was thinking it might be easier to give it the existing rust lang server and tell it to replicate the architecture. The hard part is mostly the caching and the visitor.</p>",
        "id": 568710101,
        "sender_full_name": "Eli Dowling",
        "timestamp": 1768788047
    },
    {
        "content": "<p>I think I might give it another crack at some point.</p>\n<p>On a personal level, I think I enjoy coding less, post AI, and that's a little sad. My motivation to tackle hard problems by hand and produce very high quality code in my free time is just so much lower when I know I can likely get the same result with less effort using AI. </p>\n<p>But the productivity gain is huge, so it's hard to argue with it.... But I do sometimes miss the days before</p>",
        "id": 568710431,
        "sender_full_name": "Eli Dowling",
        "timestamp": 1768788396
    },
    {
        "content": "<blockquote>\n<p>I do sometimes miss the days before</p>\n</blockquote>\n<p>I miss it a bit too, the problem solving using raw brain power was intrinsically rewarding.</p>",
        "id": 568734565,
        "sender_full_name": "Anton",
        "timestamp": 1768807651
    },
    {
        "content": "<p>I feel for most of the harder problems I am interested in, it is about the same. I still have to figure out how to fundamental solve the problem and how I want things implemented such that perf is not awful. If AI gets better and writing performant and organzied code when considering the whole system. My opinions may change.</p>",
        "id": 570469046,
        "sender_full_name": "Brendan Hansknecht",
        "timestamp": 1769576131
    }
]